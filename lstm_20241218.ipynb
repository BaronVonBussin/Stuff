{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM46sQTtw1tOBXS4QeBhKlJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/Stuff/blob/main/lstm_20241218.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance pandas numpy matplotlib seaborn tensorflow plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3POpIdZnEgn",
        "outputId": "f912dc9b-6dba-4236-89d8-3465bee106a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.50)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUIbctBcnfGW",
        "outputId": "1ff56cb3-781f-4fed-91aa-204a70e55c5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J1p_YEzNoDE1",
        "outputId": "6c08fa67-5781-4021-9bbe-03ddd263895a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.17.1\n",
            "Uninstalling tensorflow-2.17.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.17.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tensorflow\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorboard-2.18.0 tensorflow-2.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              },
              "id": "a8500c6e17684ed1b62a431a2d3578cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "zz8CHIBIm3vY",
        "outputId": "642dc7be-e03a-4755-c4e2-c2fde75d4ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"385ad6a5-9124-477b-b4d0-c018aa054a2b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"385ad6a5-9124-477b-b4d0-c018aa054a2b\")) {                    Plotly.newPlot(                        \"385ad6a5-9124-477b-b4d0-c018aa054a2b\",                        [{\"line\":{\"color\":\"blue\"},\"name\":\"Actual Price\",\"opacity\":0.7,\"x\":[\"2017-03-29T00:00:00\",\"2017-03-30T00:00:00\",\"2017-03-31T00:00:00\",\"2017-04-03T00:00:00\",\"2017-04-04T00:00:00\",\"2017-04-05T00:00:00\",\"2017-04-06T00:00:00\",\"2017-04-07T00:00:00\",\"2017-04-10T00:00:00\",\"2017-04-11T00:00:00\",\"2017-04-12T00:00:00\",\"2017-04-13T00:00:00\",\"2017-04-17T00:00:00\",\"2017-04-18T00:00:00\",\"2017-04-19T00:00:00\",\"2017-04-20T00:00:00\",\"2017-04-21T00:00:00\",\"2017-04-24T00:00:00\",\"2017-04-25T00:00:00\",\"2017-04-26T00:00:00\",\"2017-04-27T00:00:00\",\"2017-04-28T00:00:00\",\"2017-05-01T00:00:00\",\"2017-05-02T00:00:00\",\"2017-05-03T00:00:00\",\"2017-05-04T00:00:00\",\"2017-05-05T00:00:00\",\"2017-05-08T00:00:00\",\"2017-05-09T00:00:00\",\"2017-05-10T00:00:00\",\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"y\":[235.5399932861328,236.28999328613284,235.7400054931641,235.3300018310547,235.47999572753906,234.77999877929688,235.44000244140625,235.1999969482422,235.3399963378906,235.05999755859375,234.0299987792969,232.50999450683597,234.57000732421875,233.86999511718747,233.44000244140625,235.3399963378906,234.58999633789062,237.1699981689453,238.55000305175784,238.39999389648438,238.60000610351565,238.0800018310547,238.67999267578128,238.77000427246094,238.47999572753906,238.75999450683597,239.69999694824216,239.66000366210938,239.44000244140622,239.8699951171875,239.3800048828125,238.97999572753906,240.3000030517578,240.0800018310547,235.82000732421875,236.77000427246094,238.30999755859372,239.52000427246097,240.0500030517578,240.61000061035156,241.75999450683594,241.7100067138672,241.5,241.44000244140628,243.36000061035156,244.16999816894534,243.99000549316406,243.2100067138672,243.66000366210938,243.77999877929688,243.4100036621094,243.36000061035156,244.5500030517578,244.24000549316406,243.7700042724609,242.63999938964844,244.66000366210938,243.0099945068359,242.9499969482422,242.83999633789062,243.1300048828125,243.2899932861328,241.33000183105466,243.49000549316406,241.35000610351562,241.80000305175778,242.2100067138672,242.77000427246094,240.5500030517578,242.11000061035156,242.3699951171875,242.19000244140625,244.0099945068359,244.4199981689453,245.55999755859378,245.52999877929685,245.66000366210938,246.99000549316406,247.10000610351562,246.8800048828125,246.82000732421872,247.4199981689453,247.42999267578125,247.1999969482422,246.91000366210938,246.77000427246097,247.32000732421878,247.44000244140625,246.9600067138672,247.41000366210938,247.86999511718747,247.25999450683594,247.25,243.75999450683594,244.1199951171875,246.5399932861328,246.50999450683594,246.94000244140625,243.0899963378906,242.7100067138672,242.89999389648438,245.44000244140625,244.55999755859372,243.99000549316406,244.55999755859372,244.57000732421875,244.8500061035156,246.00999450683597,247.49000549316406,247.83999633789062,246.05999755859378,246.8999938964844,246.86999511718747,246.58000183105466,249.21000671386716,250.05000305175778,250.1699981689453,250.08999633789062,249.19000244140625,249.72000122070312,249.9700012207031,250.05999755859375,249.38999938964844,249.44000244140625,248.92999267578125,249.08000183105472,250.05000305175778,250.35000610351562,251.22999572753903,252.32000732421875,252.86000061035153,253.16000366210938,254.66000366210938,254.3699951171875,253.9499969482422,254.61999511718747,255.02000427246094,254.63999938964844,254.9499969482422,255.2899932861328,255.47000122070312,255.72000122070312,255.7899932861328,257.1099853515625,256.1099853515625,256.55999755859375,255.2899932861328,255.61999511718753,257.7099914550781,256.75,257.1499938964844,257.489990234375,257.5899963378906,258.45001220703125,258.8500061035156,258.6700134277344,259.1099853515625,258.1700134277344,258.0899963378906,258.3299865722656,257.7300109863281,256.44000244140625,258.6199951171875,257.8599853515625,258.29998779296875,259.989990234375,259.760009765625,260.3599853515625,260.2300109863281,262.8699951171875,262.7099914550781,265.010009765625,264.4599914550781,264.1400146484375,263.19000244140625,263.239990234375,264.07000732421875,265.510009765625,266.30999755859375,266.7799987792969,266.75,265.6600036621094,266.510009765625,268.20001220703125,267.1700134277344,267.0299987792969,267.5799865722656,267.510009765625,267.19000244140625,267.32000732421875,267.8699951171875,266.8599853515625],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"name\":\"LSTM Prediction\",\"opacity\":0.7,\"x\":[\"2017-03-29T00:00:00\",\"2017-03-30T00:00:00\",\"2017-03-31T00:00:00\",\"2017-04-03T00:00:00\",\"2017-04-04T00:00:00\",\"2017-04-05T00:00:00\",\"2017-04-06T00:00:00\",\"2017-04-07T00:00:00\",\"2017-04-10T00:00:00\",\"2017-04-11T00:00:00\",\"2017-04-12T00:00:00\",\"2017-04-13T00:00:00\",\"2017-04-17T00:00:00\",\"2017-04-18T00:00:00\",\"2017-04-19T00:00:00\",\"2017-04-20T00:00:00\",\"2017-04-21T00:00:00\",\"2017-04-24T00:00:00\",\"2017-04-25T00:00:00\",\"2017-04-26T00:00:00\",\"2017-04-27T00:00:00\",\"2017-04-28T00:00:00\",\"2017-05-01T00:00:00\",\"2017-05-02T00:00:00\",\"2017-05-03T00:00:00\",\"2017-05-04T00:00:00\",\"2017-05-05T00:00:00\",\"2017-05-08T00:00:00\",\"2017-05-09T00:00:00\",\"2017-05-10T00:00:00\",\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"y\":[236.05318,236.77206,237.5804,237.82805,237.67514,237.51825,237.05792,237.0028,236.91151,236.93578,236.85638,236.3519,235.31691,235.50316,235.48904,235.33467,236.06883,236.32085,237.56326,239.04482,239.9197,240.40698,240.31853,240.35916,240.37488,240.23521,240.25137,240.70706,241.05016,241.16968,241.39848,241.31949,241.04443,241.42767,241.65752,239.89996,238.97134,239.16583,240.05771,241.03723,241.94904,242.99532,243.5773,243.70728,243.61124,244.31801,245.19485,245.6807,245.54784,245.53545,245.55513,245.4011,245.26996,245.74477,245.99878,245.93884,245.3387,245.80415,245.48213,245.19308,244.9646,244.98122,245.12231,244.3621,244.76656,244.19351,243.95648,244.03268,244.40042,243.68489,243.81152,244.0938,244.2346,245.13098,245.95554,246.96097,247.5382,247.82881,248.4938,248.93805,249.04288,248.9886,249.17316,249.30995,249.2892,249.12509,248.94386,249.09431,249.30719,249.25151,249.39842,249.72443,249.67296,249.58537,247.9044,246.83131,247.3702,247.99469,248.69055,247.37697,246.10277,245.35667,246.1671,246.55318,246.552,246.74498,246.85886,247.02528,247.6401,248.73479,249.6139,249.26593,249.19565,249.09193,248.87584,249.94092,251.16475,252.01689,252.41003,252.08994,251.96758,251.98778,252.06708,251.83177,251.68643,251.38481,251.27525,251.70992,252.22032,252.97568,253.96695,254.82501,255.41727,256.36874,256.78384,256.7052,256.83517,257.0874,257.07462,257.1805,257.42087,257.6811,257.96863,258.17953,258.9148,258.94693,259.07373,258.5259,258.25082,259.11078,259.36627,259.66272,259.9825,260.20444,260.71198,261.22458,261.4299,261.6897,261.36975,261.0399,260.94165,260.64883,259.86676,260.39624,260.56723,260.88858,261.9057,262.49197,263.04553,263.2438,264.51486,265.29367,266.7598,267.38614,267.41147,266.78036,266.27277,266.3782,267.26758,268.35242,269.27982,269.7636,269.39417,269.39923,270.234,270.35803,270.27673,270.44125,270.5333,270.43402,270.419,270.69858],\"type\":\"scatter\"},{\"fill\":\"tozeroy\",\"line\":{\"color\":\"rgba(0,255,0,0.2)\"},\"name\":\"Prediction Error\",\"opacity\":0.3,\"x\":[\"2017-03-29T00:00:00\",\"2017-03-30T00:00:00\",\"2017-03-31T00:00:00\",\"2017-04-03T00:00:00\",\"2017-04-04T00:00:00\",\"2017-04-05T00:00:00\",\"2017-04-06T00:00:00\",\"2017-04-07T00:00:00\",\"2017-04-10T00:00:00\",\"2017-04-11T00:00:00\",\"2017-04-12T00:00:00\",\"2017-04-13T00:00:00\",\"2017-04-17T00:00:00\",\"2017-04-18T00:00:00\",\"2017-04-19T00:00:00\",\"2017-04-20T00:00:00\",\"2017-04-21T00:00:00\",\"2017-04-24T00:00:00\",\"2017-04-25T00:00:00\",\"2017-04-26T00:00:00\",\"2017-04-27T00:00:00\",\"2017-04-28T00:00:00\",\"2017-05-01T00:00:00\",\"2017-05-02T00:00:00\",\"2017-05-03T00:00:00\",\"2017-05-04T00:00:00\",\"2017-05-05T00:00:00\",\"2017-05-08T00:00:00\",\"2017-05-09T00:00:00\",\"2017-05-10T00:00:00\",\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"y\":[0.26335740089416504,0.23239237465892973,3.387046638876095,6.240238189697266,4.818660049000755,7.498017073608935,2.617664873600006,3.250126308063045,2.46966864936994,3.5185438490007073,7.988454983569521,14.760223936522161,0.5578632934484631,2.6672228614334945,4.198572085238993,0.000028359005227382265,2.186956091085449,0.7210584590211511,0.9736560492311234,0.41579433740116656,1.7415734867098922,5.414838670054451,2.6847954581025055,2.5254203027579933,3.590578560018912,2.1762732416390533,0.3040158713702426,1.096330676227808,2.5925933218096366,1.6891749054193497,4.074255025247112,5.473226551199332,0.554176831850782,1.8162184956017882,34.0765131379012,9.796644008019939,0.43737910781059447,0.12543763057330773,0.0000593776348978281,0.18252618634141982,0.0357365517411381,1.652018808759749,4.315179550088942,5.14052662625896,0.06311950855888426,0.02190703526138418,1.4516616987530142,6.104298532241955,3.5639120826963335,3.081595530966297,4.601567026460422,4.166056221583858,0.5183358418289572,2.264304891228676,4.967438109452032,10.882367670768872,0.4606278243009001,7.8073241570966045,6.411707707680762,5.537024918943644,3.365737810730934,2.8602357245981693,14.381635023514024,0.7605598578229547,11.672811733791605,5.728884907672318,3.0501756931189448,1.594360918039456,14.82571947411634,2.480278942734003,2.0780038982629776,3.6244290622416884,0.05044937133790339,0.5054972192738205,0.15645057056096928,2.047672960907302,3.52759424620308,0.7035957612097263,1.9426751732826233,4.235546890646219,4.941150472499556,2.4605169892311096,3.038620948791504,4.4519094014540315,5.660574401030317,5.546436097705603,2.636906979838294,2.736748636001721,5.5092691036406904,3.3911478763911873,2.3360894734506434,6.073423912981525,5.8707272822503,33.9350337125361,14.321748219663277,0.08486780896782875,0.7399422759190202,1.11236572265625,31.36622101161661,21.780531228519976,10.257761601591483,0.006943596759811044,2.582775039831268,6.56984755769372,3.968081507831925,4.730505524436012,4.03547871485364,1.0308123761787433,0.022530222544446588,0.8006503062788397,12.6302713251205,5.597654477693006,5.408662230707837,6.309804246761048,0.11166790500281341,0.011899555334815144,0.9895295053720474,3.7129248867277056,10.368604395538568,5.616587553173304,3.990301296347866,3.7163363120052963,7.166747940937057,5.720560906687751,7.597957112826407,5.312147155403959,1.501238160766731,1.849352644989267,0.9807454431430068,0.42990336660295725,1.22533576213761,2.7722534546628594,0.5734475292265415,3.994996682740748,8.030689079547301,4.3480802178384055,3.2948431747499853,5.989781219745055,4.514003899181262,3.5740590209607035,3.805880878120661,3.8458743328228593,4.74644891009666,1.1439362624660134,7.866956725716591,5.697446153499186,14.316667067119852,8.4443379575385,0.2924998141825199,5.573276583105326,4.911888510920107,4.720753446221352,5.7241380251944065,3.078007251955569,3.466928535141051,6.5258045345544815,5.382009186781943,12.38817431870848,10.756790489889681,7.343557480722666,10.314627663232386,17.714265012182295,1.5544233061373234,6.432588830590248,5.140388243831694,0.8074641460552812,4.603989515453577,4.545375072397292,7.927159854210913,0.13973377738147974,3.257557902485132,0.08046349976211786,5.289101600646973,10.537322760559618,17.820775733329356,12.53425341192633,4.852146282792091,0.7537618288770318,0.9169605411589146,2.472499036230147,6.39996734354645,16.839591869153082,8.31835164129734,1.4381256103515625,9.388067574240267,11.07580662611872,7.272443444468081,8.592190780676901,11.177602977491915,9.69708114862442,6.497458253055811,14.73479260597378],\"yaxis\":\"y2\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis2\":{\"title\":{\"text\":\"Prediction Error\"},\"overlaying\":\"y\",\"side\":\"right\",\"showgrid\":false},\"legend\":{\"yanchor\":\"top\",\"y\":0.99,\"xanchor\":\"left\",\"x\":0.01},\"title\":{\"text\":\"SPY Price Prediction Analysis with LSTM (50-day lookback)\"},\"xaxis\":{\"title\":{\"text\":\"Date\"}},\"yaxis\":{\"title\":{\"text\":\"Price ($)\"}},\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('385ad6a5-9124-477b-b4d0-c018aa054a2b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LSTM Model Analysis Results:\n",
            "--------------------------------------------------\n",
            "Mean Absolute Error: $1.97\n",
            "Root Mean Square Error: $2.25\n",
            "Mean Prediction Error %: 0.79%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import plotly.express as px\n",
        "\n",
        "# Fetch SPY data\n",
        "def get_spy_data(start_date, end_date):\n",
        "    df = yf.download('SPY', start=start_date, end=end_date)\n",
        "    df = df[df.index.dayofweek < 5]  # Remove weekends\n",
        "    return df\n",
        "\n",
        "# Prepare data for LSTM\n",
        "def prepare_lstm_data(data, lookback):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(lookback, len(scaled_data)):\n",
        "        X.append(scaled_data[i-lookback:i])\n",
        "        y.append(scaled_data[i])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    train_size = int(len(X) * 0.8)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, scaler\n",
        "\n",
        "# Create and train LSTM model\n",
        "def create_lstm_model(lookback):\n",
        "    model = Sequential([\n",
        "        LSTM(50, input_shape=(lookback, 1), return_sequences=False),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Create visualization with prediction analysis\n",
        "def create_analysis_plot(dates, actual_values, predictions, mse_values):\n",
        "    # Create figure with secondary y-axis\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add actual prices\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=dates, y=actual_values,\n",
        "                  name=\"Actual Price\",\n",
        "                  line=dict(color='blue'),\n",
        "                  opacity=0.7)\n",
        "    )\n",
        "\n",
        "    # Add predictions\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=dates, y=predictions,\n",
        "                  name=\"LSTM Prediction\",\n",
        "                  line=dict(color='red'),\n",
        "                  opacity=0.7)\n",
        "    )\n",
        "\n",
        "    # Add MSE as area plot on secondary axis\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=dates, y=mse_values,\n",
        "                  name=\"Prediction Error\",\n",
        "                  fill='tozeroy',\n",
        "                  yaxis='y2',\n",
        "                  line=dict(color='rgba(0,255,0,0.2)'),\n",
        "                  opacity=0.3)\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title=\"SPY Price Prediction Analysis with LSTM (50-day lookback)\",\n",
        "        xaxis_title=\"Date\",\n",
        "        yaxis_title=\"Price ($)\",\n",
        "        yaxis2=dict(\n",
        "            title=\"Prediction Error\",\n",
        "            overlaying=\"y\",\n",
        "            side=\"right\",\n",
        "            showgrid=False\n",
        "        ),\n",
        "        hovermode='x unified',\n",
        "        legend=dict(\n",
        "            yanchor=\"top\",\n",
        "            y=0.99,\n",
        "            xanchor=\"left\",\n",
        "            x=0.01\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def main():\n",
        "    # Parameters\n",
        "    start_date = '2014-01-01'\n",
        "    end_date = '2017-12-31'\n",
        "    lookback = 50\n",
        "\n",
        "    # Get data\n",
        "    df = get_spy_data(start_date, end_date)\n",
        "\n",
        "    # Prepare data\n",
        "    X_train, X_test, y_train, y_test, scaler = prepare_lstm_data(df, lookback)\n",
        "\n",
        "    # Create and train model\n",
        "    model = create_lstm_model(lookback)\n",
        "    history = model.fit(X_train, y_train,\n",
        "                       epochs=50,\n",
        "                       batch_size=32,\n",
        "                       validation_split=0.1,\n",
        "                       verbose=0)\n",
        "\n",
        "    # Generate predictions\n",
        "    test_predictions = model.predict(X_test)\n",
        "\n",
        "    # Transform predictions back to original scale\n",
        "    test_predictions = scaler.inverse_transform(test_predictions)\n",
        "    actual_values = scaler.inverse_transform(y_test)\n",
        "\n",
        "    # Calculate MSE for each prediction\n",
        "    mse_values = np.square(test_predictions - actual_values)\n",
        "\n",
        "    # Get dates for test period\n",
        "    test_dates = df.index[-(len(test_predictions)):]\n",
        "\n",
        "    # Create and show visualization\n",
        "    fig = create_analysis_plot(\n",
        "        test_dates,\n",
        "        actual_values.flatten(),\n",
        "        test_predictions.flatten(),\n",
        "        mse_values.flatten()\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "    # Print performance metrics\n",
        "    print(\"\\nLSTM Model Analysis Results:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Mean Absolute Error: ${np.mean(np.abs(test_predictions - actual_values)):.2f}\")\n",
        "    print(f\"Root Mean Square Error: ${np.sqrt(np.mean(np.square(test_predictions - actual_values))):.2f}\")\n",
        "    print(f\"Mean Prediction Error %: {np.mean(np.abs(test_predictions - actual_values) / actual_values) * 100:.2f}%\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch SPY data\n",
        "def get_spy_data(start_date, end_date):\n",
        "    df = yf.download('SPY', start=start_date, end=end_date)\n",
        "    df = df[df.index.dayofweek < 5]  # Remove weekends\n",
        "    return df\n",
        "\n",
        "# Prepare data for LSTM\n",
        "def prepare_lstm_data(data, lookback):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(lookback, len(scaled_data)):\n",
        "        X.append(scaled_data[i-lookback:i])\n",
        "        y.append(scaled_data[i])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    train_size = int(len(X) * 0.8)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, scaler\n",
        "\n",
        "# Create and train LSTM model\n",
        "def create_lstm_model(lookback):\n",
        "    model = Sequential([\n",
        "        LSTM(50, input_shape=(lookback, 1), return_sequences=False),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Create visualization with prediction analysis\n",
        "def create_analysis_plot(dates, actual_values, predictions, mse_values):\n",
        "    # Create figure with secondary y-axis\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add actual prices\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=dates, y=actual_values,\n",
        "                  name=\"Actual Price\",\n",
        "                  line=dict(color='blue'),\n",
        "                  opacity=0.7)\n",
        "    )\n",
        "\n",
        "    # Add predictions\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=dates, y=predictions,\n",
        "                  name=\"LSTM Prediction\",\n",
        "                  line=dict(color='red'),\n",
        "                  opacity=0.7)\n",
        "    )\n",
        "\n",
        "    # Add MSE as area plot on secondary axis\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=dates, y=mse_values,\n",
        "                  name=\"Prediction Error\",\n",
        "                  fill='tozeroy',\n",
        "                  yaxis='y2',\n",
        "                  line=dict(color='rgba(0,255,0,0.2)'),\n",
        "                  opacity=0.3)\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title=\"SPY Price Prediction Analysis with LSTM (200-day lookback)\",\n",
        "        xaxis_title=\"Date\",\n",
        "        yaxis_title=\"Price ($)\",\n",
        "        yaxis2=dict(\n",
        "            title=\"Prediction Error\",\n",
        "            overlaying=\"y\",\n",
        "            side=\"right\",\n",
        "            showgrid=False\n",
        "        ),\n",
        "        hovermode='x unified',\n",
        "        legend=dict(\n",
        "            yanchor=\"top\",\n",
        "            y=0.99,\n",
        "            xanchor=\"left\",\n",
        "            x=0.01\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def main():\n",
        "    # Parameters\n",
        "    start_date = '2014-01-01'\n",
        "    end_date = '2017-12-31'\n",
        "    lookback = 200\n",
        "\n",
        "    # Get data\n",
        "    df = get_spy_data(start_date, end_date)\n",
        "\n",
        "    # Prepare data\n",
        "    X_train, X_test, y_train, y_test, scaler = prepare_lstm_data(df, lookback)\n",
        "\n",
        "    # Create and train model\n",
        "    model = create_lstm_model(lookback)\n",
        "    history = model.fit(X_train, y_train,\n",
        "                       epochs=50,\n",
        "                       batch_size=32,\n",
        "                       validation_split=0.1,\n",
        "                       verbose=0)\n",
        "\n",
        "    # Generate predictions\n",
        "    test_predictions = model.predict(X_test)\n",
        "\n",
        "    # Transform predictions back to original scale\n",
        "    test_predictions = scaler.inverse_transform(test_predictions)\n",
        "    actual_values = scaler.inverse_transform(y_test)\n",
        "\n",
        "    # Calculate MSE for each prediction\n",
        "    mse_values = np.square(test_predictions - actual_values)\n",
        "\n",
        "    # Get dates for test period\n",
        "    test_dates = df.index[-(len(test_predictions)):]\n",
        "\n",
        "    # Create and show visualization\n",
        "    fig = create_analysis_plot(\n",
        "        test_dates,\n",
        "        actual_values.flatten(),\n",
        "        test_predictions.flatten(),\n",
        "        mse_values.flatten()\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "    # Print performance metrics\n",
        "    print(\"\\nLSTM Model Analysis Results:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Mean Absolute Error: ${np.mean(np.abs(test_predictions - actual_values)):.2f}\")\n",
        "    print(f\"Root Mean Square Error: ${np.sqrt(np.mean(np.square(test_predictions - actual_values))):.2f}\")\n",
        "    print(f\"Mean Prediction Error %: {np.mean(np.abs(test_predictions - actual_values) / actual_values) * 100:.2f}%\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "6Eb2Su1Sm5d6",
        "outputId": "af4106bb-2bf1-4024-b43b-8150df0da5ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7cf6f1c8-2640-4f23-a528-50cde22cedee\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7cf6f1c8-2640-4f23-a528-50cde22cedee\")) {                    Plotly.newPlot(                        \"7cf6f1c8-2640-4f23-a528-50cde22cedee\",                        [{\"line\":{\"color\":\"blue\"},\"name\":\"Actual Price\",\"opacity\":0.7,\"x\":[\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"y\":[239.3800048828125,238.97999572753906,240.3000030517578,240.0800018310547,235.82000732421875,236.77000427246094,238.30999755859372,239.52000427246097,240.0500030517578,240.61000061035156,241.75999450683594,241.7100067138672,241.5,241.44000244140628,243.36000061035156,244.16999816894534,243.99000549316406,243.2100067138672,243.66000366210938,243.77999877929688,243.4100036621094,243.36000061035156,244.5500030517578,244.24000549316406,243.7700042724609,242.63999938964844,244.66000366210938,243.0099945068359,242.9499969482422,242.83999633789062,243.1300048828125,243.2899932861328,241.33000183105466,243.49000549316406,241.35000610351562,241.80000305175778,242.2100067138672,242.77000427246094,240.5500030517578,242.11000061035156,242.3699951171875,242.19000244140625,244.0099945068359,244.4199981689453,245.55999755859378,245.52999877929685,245.66000366210938,246.99000549316406,247.10000610351562,246.8800048828125,246.82000732421872,247.4199981689453,247.42999267578125,247.1999969482422,246.91000366210938,246.77000427246097,247.32000732421878,247.44000244140625,246.9600067138672,247.41000366210938,247.86999511718747,247.25999450683594,247.25,243.75999450683594,244.1199951171875,246.5399932861328,246.50999450683594,246.94000244140625,243.0899963378906,242.7100067138672,242.89999389648438,245.44000244140625,244.55999755859372,243.99000549316406,244.55999755859372,244.57000732421875,244.8500061035156,246.00999450683597,247.49000549316406,247.83999633789062,246.05999755859378,246.8999938964844,246.86999511718747,246.58000183105466,249.21000671386716,250.05000305175778,250.1699981689453,250.08999633789062,249.19000244140625,249.72000122070312,249.9700012207031,250.05999755859375,249.38999938964844,249.44000244140625,248.92999267578125,249.08000183105472,250.05000305175778,250.35000610351562,251.22999572753903,252.32000732421875,252.86000061035153,253.16000366210938,254.66000366210938,254.3699951171875,253.9499969482422,254.61999511718747,255.02000427246094,254.63999938964844,254.9499969482422,255.2899932861328,255.47000122070312,255.72000122070312,255.7899932861328,257.1099853515625,256.1099853515625,256.55999755859375,255.2899932861328,255.61999511718753,257.7099914550781,256.75,257.1499938964844,257.489990234375,257.5899963378906,258.45001220703125,258.8500061035156,258.6700134277344,259.1099853515625,258.1700134277344,258.0899963378906,258.3299865722656,257.7300109863281,256.44000244140625,258.6199951171875,257.8599853515625,258.29998779296875,259.989990234375,259.760009765625,260.3599853515625,260.2300109863281,262.8699951171875,262.7099914550781,265.010009765625,264.4599914550781,264.1400146484375,263.19000244140625,263.239990234375,264.07000732421875,265.510009765625,266.30999755859375,266.7799987792969,266.75,265.6600036621094,266.510009765625,268.20001220703125,267.1700134277344,267.0299987792969,267.5799865722656,267.510009765625,267.19000244140625,267.32000732421875,267.8699951171875,266.8599853515625],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"name\":\"LSTM Prediction\",\"opacity\":0.7,\"x\":[\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"y\":[241.2281,241.27745,241.1863,241.35666,241.48291,240.62672,239.9089,239.58835,239.67038,239.99213,240.49861,241.26437,241.97665,242.53818,242.9527,243.6785,244.50894,245.19954,245.57167,245.89247,246.1271,246.19035,246.17078,246.38252,246.51724,246.51784,246.21964,246.35374,246.13837,245.8994,245.64247,245.47961,245.39679,244.90096,244.90857,244.49297,244.19958,244.04842,244.08868,243.67216,243.6118,243.6627,243.71542,244.2012,244.80406,245.6419,246.40857,247.08698,247.93459,248.68425,249.2392,249.62709,250.01964,250.31462,250.46854,250.47737,250.39429,250.40723,250.4464,250.37344,250.39539,250.5286,250.52338,250.49701,249.63647,248.8172,248.62251,248.56839,248.71945,248.027,247.21371,246.47919,246.44337,246.36636,246.2421,246.28624,246.36609,246.52553,246.95673,247.73227,248.56699,248.90172,249.28127,249.5455,249.65477,250.30847,251.14429,251.95476,252.63406,252.95662,253.24954,253.49323,253.68085,253.64865,253.57106,253.34462,253.14268,253.1874,253.34329,253.72893,254.37503,255.1227,255.86823,256.85837,257.6608,258.20337,258.7357,259.22726,259.51328,259.76425,260.01352,260.24356,260.47958,260.68375,261.1566,261.35468,261.59094,261.46243,261.34955,261.71567,261.87076,262.09607,262.36902,262.6289,263.0503,263.5247,263.8975,264.29764,264.39474,264.388,264.3809,264.20255,263.69757,263.7158,263.60992,263.6445,264.1111,264.5441,265.09064,265.5461,266.55383,267.4515,268.78,269.8351,270.61734,270.95938,271.1232,271.35532,271.86105,272.51428,273.22025,273.8282,274.05667,274.36594,274.99463,275.3109,275.50577,275.74954,275.91476,275.9505,275.97278,276.0993],\"type\":\"scatter\"},{\"fill\":\"tozeroy\",\"line\":{\"color\":\"rgba(0,255,0,0.2)\"},\"name\":\"Prediction Error\",\"opacity\":0.3,\"x\":[\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"y\":[3.415469007799402,5.278298714198172,0.7855126298964024,1.6298533624503762,32.06846848502755,14.874288932420313,2.5565050998703556,0.004670918220650245,0.14411393576301634,0.38176845968700945,1.5910872155800462,0.19858871237374842,0.22719908598810434,1.2059884378685923,0.16589561686851084,0.24157308996657842,0.2692947352770716,3.958239451982081,3.654470222303644,4.462540207663551,7.38264355435952,8.010896877385676,2.6269061400089413,4.5903794802725315,7.547317503253154,15.037628599442542,2.4324499405920506,11.18066406250019,10.165701668942347,9.359943447867408,6.312487565213814,4.794439999619499,16.538762357319005,1.9907790757715702,12.663372279144824,7.252047815360282,3.9584216012153774,1.6343368971720338,12.522263434017077,2.4403573209419847,1.5420822168234736,2.1688512584660202,0.08677202858960444,0.047871591756120324,0.5714387355838401,0.012523391284054919,0.5603505680337548,0.00940310419537127,0.6965228880289942,3.25530000240542,5.852477610111374,4.871256355196238,6.706263223895803,9.700882807374,12.66315508261323,13.744569652713624,9.451196197420185,8.804418984800577,12.154909376055002,8.781976286321878,6.3775978088380345,10.683748992392793,10.714993480592966,45.38736801804043,30.431545987725258,5.185669083381072,4.462733612395823,2.6516456911340356,31.690769974142633,28.2703410172835,18.608186304569244,1.0799045711755753,3.547109207371357,5.6470774973277,2.8294549891726137,2.9454533068928868,2.2985069463030365,0.26577473524954964,0.2843869386706501,0.011605117470026016,6.284991466440118,4.006899945670625,5.814223695779356,8.79418952600116,0.19781428948047305,0.06680603162386993,0.9492389394436032,3.4773349019233137,11.861558095552027,10.475696349749342,10.755389273166843,11.78705133497715,18.41137465671636,17.71272372547537,21.539507584879175,18.18696600291854,9.564681240357634,8.050765469903126,4.46602213406016,1.9850563781801611,2.2953156197910127,3.852160910377279,1.4597990373149514,6.191999205388129,13.770037908339873,12.840569391846861,13.806300033116713,21.04300031461753,20.823507914552465,20.01898843445815,20.64355641975999,20.46259118616581,21.9922586272005,12.771767587400973,25.468175009824336,22.988934576511383,39.70195951894857,34.13407879415866,13.246374317444861,24.657855951227248,22.285614255815744,21.215964689850807,22.839053348638117,17.463155422359705,17.642409750260413,23.56787220016122,22.920214691199362,37.54778215661645,39.74985409155488,36.69953260663897,44.234190225601196,60.25706955138594,25.781774822622538,34.2904456788674,28.195425882935524,13.355446980334818,18.932112426497042,17.50679782126099,23.625687257386744,7.161601894535124,14.775117882527411,5.960911520756781,18.662463281303644,32.434151218272746,55.165344514884055,59.588995390571654,49.74751934502274,34.16760686878115,30.81422169599682,32.88200665358454,41.86407503578812,66.71920327935368,56.95209793839604,38.01861966494471,61.2246073866263,68.57354175392538,62.81800842285156,67.88989533577114,76.12147130910307,74.48541225492954,65.65509563684464,85.36501276865602],\"yaxis\":\"y2\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis2\":{\"title\":{\"text\":\"Prediction Error\"},\"overlaying\":\"y\",\"side\":\"right\",\"showgrid\":false},\"legend\":{\"yanchor\":\"top\",\"y\":0.99,\"xanchor\":\"left\",\"x\":0.01},\"title\":{\"text\":\"SPY Price Prediction Analysis with LSTM (200-day lookback)\"},\"xaxis\":{\"title\":{\"text\":\"Date\"}},\"yaxis\":{\"title\":{\"text\":\"Price ($)\"}},\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7cf6f1c8-2640-4f23-a528-50cde22cedee');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LSTM Model Analysis Results:\n",
            "--------------------------------------------------\n",
            "Mean Absolute Error: $3.44\n",
            "Root Mean Square Error: $4.08\n",
            "Mean Prediction Error %: 1.35%\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# Fetch SPY data\n",
        "def get_spy_data(start_date, end_date):\n",
        "    df = yf.download('SPY', start=start_date, end=end_date)\n",
        "    df = df[df.index.dayofweek < 5]  # Remove weekends\n",
        "    return df\n",
        "\n",
        "# Create LSTM model with attention tracking\n",
        "class AttentionLSTM(tf.keras.Model):\n",
        "    def __init__(self, lookback):\n",
        "        super(AttentionLSTM, self).__init__()\n",
        "        self.lstm = LSTM(50, return_sequences=True)\n",
        "        self.attention = Dense(1, activation='tanh')\n",
        "        self.dense = Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        lstm_out = self.lstm(inputs)\n",
        "        attention_weights = tf.nn.softmax(self.attention(lstm_out), axis=1)\n",
        "        context = attention_weights * lstm_out\n",
        "        context = tf.reduce_sum(context, axis=1)\n",
        "        output = self.dense(context)\n",
        "        return output, attention_weights\n",
        "\n",
        "# Prepare data for LSTM\n",
        "def prepare_data(data, lookback):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(lookback, len(scaled_data)):\n",
        "        X.append(scaled_data[i-lookback:i])\n",
        "        y.append(scaled_data[i])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    train_size = int(len(X) * 0.8)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, scaler\n",
        "\n",
        "def create_visualization(dates, prices, predictions, attention_weights, window_size=50):\n",
        "    # Create figure with secondary y-axis\n",
        "    fig = make_subplots(rows=2, cols=1,\n",
        "                       shared_xaxes=True,\n",
        "                       vertical_spacing=0.05,\n",
        "                       row_heights=[0.7, 0.3])\n",
        "\n",
        "    # Add price and prediction traces\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=dates, y=prices, name=\"Actual Price\",\n",
        "                  line=dict(color='blue')),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=dates, y=predictions, name=\"LSTM Prediction\",\n",
        "                  line=dict(color='red')),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Add attention heatmap\n",
        "    attention_weights = attention_weights.reshape(-1, window_size)\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(\n",
        "            z=attention_weights,\n",
        "            x=np.arange(window_size),\n",
        "            y=dates,\n",
        "            colorscale='Viridis',\n",
        "            name='Pattern Importance',\n",
        "            showscale=True,\n",
        "            colorbar=dict(title='Pattern Importance')\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title=\"SPY Price Prediction with Pattern Importance Analysis\",\n",
        "        xaxis_title=\"Date\",\n",
        "        yaxis_title=\"Price ($)\",\n",
        "        yaxis2_title=\"Lookback Days\",\n",
        "        height=800,\n",
        "        showlegend=True,\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def main():\n",
        "    # Parameters\n",
        "    start_date = '2014-01-01'\n",
        "    end_date = '2017-12-31'\n",
        "    lookback = 50\n",
        "\n",
        "    # Get data\n",
        "    df = get_spy_data(start_date, end_date)\n",
        "\n",
        "    # Prepare data\n",
        "    X_train, X_test, y_train, y_test, scaler = prepare_data(df, lookback)\n",
        "\n",
        "    # Create and train model\n",
        "    model = AttentionLSTM(lookback)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Reshape data for attention model\n",
        "    X_train_reshaped = X_train.reshape(-1, lookback, 1)\n",
        "    y_train_reshaped = y_train.reshape(-1, 1)\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train_reshaped, y_train_reshaped,\n",
        "             epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    # Generate predictions and get attention weights\n",
        "    X_test_reshaped = X_test.reshape(-1, lookback, 1)\n",
        "    predictions, attention_weights = model(X_test_reshaped)\n",
        "\n",
        "    # Transform predictions back to original scale\n",
        "    predictions = scaler.inverse_transform(predictions.numpy())\n",
        "    actual_values = scaler.inverse_transform(y_test)\n",
        "\n",
        "    # Get dates for test period\n",
        "    test_dates = df.index[-(len(predictions)):]\n",
        "\n",
        "    # Create visualization\n",
        "    fig = create_visualization(\n",
        "        test_dates,\n",
        "        actual_values.flatten(),\n",
        "        predictions.flatten(),\n",
        "        attention_weights.numpy(),\n",
        "        lookback\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "    # Print interpretation guide\n",
        "    print(\"\\nHow to Interpret the Visualization:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"1. Top Panel:\")\n",
        "    print(\"   - Blue line: Actual SPY price\")\n",
        "    print(\"   - Red line: LSTM predictions\")\n",
        "    print(\"\\n2. Bottom Panel (Heatmap):\")\n",
        "    print(\"   - Each row represents one prediction\")\n",
        "    print(\"   - Colors show which past days were most important\")\n",
        "    print(\"   - Brighter colors = More important for prediction\")\n",
        "    print(\"   - X-axis shows lookback days (0 = most recent)\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PdLmTZ91yD7V",
        "outputId": "52f3452d-77b4-4b07-819c-7b9c58d565d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"537ae865-d5fd-4102-8bd8-098fbab57e3f\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"537ae865-d5fd-4102-8bd8-098fbab57e3f\")) {                    Plotly.newPlot(                        \"537ae865-d5fd-4102-8bd8-098fbab57e3f\",                        [{\"line\":{\"color\":\"blue\"},\"name\":\"Actual Price\",\"x\":[\"2017-03-29T00:00:00\",\"2017-03-30T00:00:00\",\"2017-03-31T00:00:00\",\"2017-04-03T00:00:00\",\"2017-04-04T00:00:00\",\"2017-04-05T00:00:00\",\"2017-04-06T00:00:00\",\"2017-04-07T00:00:00\",\"2017-04-10T00:00:00\",\"2017-04-11T00:00:00\",\"2017-04-12T00:00:00\",\"2017-04-13T00:00:00\",\"2017-04-17T00:00:00\",\"2017-04-18T00:00:00\",\"2017-04-19T00:00:00\",\"2017-04-20T00:00:00\",\"2017-04-21T00:00:00\",\"2017-04-24T00:00:00\",\"2017-04-25T00:00:00\",\"2017-04-26T00:00:00\",\"2017-04-27T00:00:00\",\"2017-04-28T00:00:00\",\"2017-05-01T00:00:00\",\"2017-05-02T00:00:00\",\"2017-05-03T00:00:00\",\"2017-05-04T00:00:00\",\"2017-05-05T00:00:00\",\"2017-05-08T00:00:00\",\"2017-05-09T00:00:00\",\"2017-05-10T00:00:00\",\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"y\":[235.5399932861328,236.28999328613284,235.7400054931641,235.3300018310547,235.47999572753906,234.77999877929688,235.44000244140625,235.1999969482422,235.3399963378906,235.05999755859375,234.0299987792969,232.50999450683597,234.57000732421875,233.86999511718747,233.44000244140625,235.3399963378906,234.58999633789062,237.1699981689453,238.55000305175784,238.39999389648438,238.60000610351565,238.0800018310547,238.67999267578128,238.77000427246094,238.47999572753906,238.75999450683597,239.69999694824216,239.66000366210938,239.44000244140622,239.8699951171875,239.3800048828125,238.97999572753906,240.3000030517578,240.0800018310547,235.82000732421875,236.77000427246094,238.30999755859372,239.52000427246097,240.0500030517578,240.61000061035156,241.75999450683594,241.7100067138672,241.5,241.44000244140628,243.36000061035156,244.16999816894534,243.99000549316406,243.2100067138672,243.66000366210938,243.77999877929688,243.4100036621094,243.36000061035156,244.5500030517578,244.24000549316406,243.7700042724609,242.63999938964844,244.66000366210938,243.0099945068359,242.9499969482422,242.83999633789062,243.1300048828125,243.2899932861328,241.33000183105466,243.49000549316406,241.35000610351562,241.80000305175778,242.2100067138672,242.77000427246094,240.5500030517578,242.11000061035156,242.3699951171875,242.19000244140625,244.0099945068359,244.4199981689453,245.55999755859378,245.52999877929685,245.66000366210938,246.99000549316406,247.10000610351562,246.8800048828125,246.82000732421872,247.4199981689453,247.42999267578125,247.1999969482422,246.91000366210938,246.77000427246097,247.32000732421878,247.44000244140625,246.9600067138672,247.41000366210938,247.86999511718747,247.25999450683594,247.25,243.75999450683594,244.1199951171875,246.5399932861328,246.50999450683594,246.94000244140625,243.0899963378906,242.7100067138672,242.89999389648438,245.44000244140625,244.55999755859372,243.99000549316406,244.55999755859372,244.57000732421875,244.8500061035156,246.00999450683597,247.49000549316406,247.83999633789062,246.05999755859378,246.8999938964844,246.86999511718747,246.58000183105466,249.21000671386716,250.05000305175778,250.1699981689453,250.08999633789062,249.19000244140625,249.72000122070312,249.9700012207031,250.05999755859375,249.38999938964844,249.44000244140625,248.92999267578125,249.08000183105472,250.05000305175778,250.35000610351562,251.22999572753903,252.32000732421875,252.86000061035153,253.16000366210938,254.66000366210938,254.3699951171875,253.9499969482422,254.61999511718747,255.02000427246094,254.63999938964844,254.9499969482422,255.2899932861328,255.47000122070312,255.72000122070312,255.7899932861328,257.1099853515625,256.1099853515625,256.55999755859375,255.2899932861328,255.61999511718753,257.7099914550781,256.75,257.1499938964844,257.489990234375,257.5899963378906,258.45001220703125,258.8500061035156,258.6700134277344,259.1099853515625,258.1700134277344,258.0899963378906,258.3299865722656,257.7300109863281,256.44000244140625,258.6199951171875,257.8599853515625,258.29998779296875,259.989990234375,259.760009765625,260.3599853515625,260.2300109863281,262.8699951171875,262.7099914550781,265.010009765625,264.4599914550781,264.1400146484375,263.19000244140625,263.239990234375,264.07000732421875,265.510009765625,266.30999755859375,266.7799987792969,266.75,265.6600036621094,266.510009765625,268.20001220703125,267.1700134277344,267.0299987792969,267.5799865722656,267.510009765625,267.19000244140625,267.32000732421875,267.8699951171875,266.8599853515625],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\"},\"name\":\"LSTM Prediction\",\"x\":[\"2017-03-29T00:00:00\",\"2017-03-30T00:00:00\",\"2017-03-31T00:00:00\",\"2017-04-03T00:00:00\",\"2017-04-04T00:00:00\",\"2017-04-05T00:00:00\",\"2017-04-06T00:00:00\",\"2017-04-07T00:00:00\",\"2017-04-10T00:00:00\",\"2017-04-11T00:00:00\",\"2017-04-12T00:00:00\",\"2017-04-13T00:00:00\",\"2017-04-17T00:00:00\",\"2017-04-18T00:00:00\",\"2017-04-19T00:00:00\",\"2017-04-20T00:00:00\",\"2017-04-21T00:00:00\",\"2017-04-24T00:00:00\",\"2017-04-25T00:00:00\",\"2017-04-26T00:00:00\",\"2017-04-27T00:00:00\",\"2017-04-28T00:00:00\",\"2017-05-01T00:00:00\",\"2017-05-02T00:00:00\",\"2017-05-03T00:00:00\",\"2017-05-04T00:00:00\",\"2017-05-05T00:00:00\",\"2017-05-08T00:00:00\",\"2017-05-09T00:00:00\",\"2017-05-10T00:00:00\",\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"y\":[237.91905,237.63483,237.32283,237.03793,236.78123,236.60698,236.49532,236.44559,236.48251,236.5874,236.77025,236.98238,237.20326,237.43416,237.62665,237.83534,238.05371,238.26924,238.4713,238.69595,238.94643,239.24156,239.57043,239.96484,240.39125,240.80243,241.22644,241.64124,242.03136,242.38475,242.7191,242.92963,243.1323,243.27937,243.38495,243.41946,243.37502,243.24983,243.06108,242.8546,242.67618,242.50137,242.40536,242.41176,242.49321,242.69379,242.93054,243.20522,243.49474,243.7848,244.0281,244.24718,244.42638,244.59796,244.7616,244.91232,245.07016,245.22379,245.39178,245.5638,245.74106,245.93015,246.13057,246.25073,246.36072,246.4405,246.44334,246.4331,246.34927,246.22098,246.08786,245.94263,245.80121,245.65176,245.521,245.43683,245.40248,245.42169,245.53622,245.75375,246.05107,246.43427,246.88449,247.34009,247.82687,248.43265,248.98227,249.45428,249.85564,250.19873,250.48232,250.6968,250.87378,251.0175,251.10446,251.08954,251.0155,250.90823,250.78438,250.59987,250.36256,250.08667,249.78249,249.43268,249.08084,248.73907,248.43108,248.10063,247.85826,247.68399,247.59416,247.57727,247.64044,247.83215,248.02963,248.35773,248.73656,249.16241,249.62451,250.18741,250.72137,251.25462,251.78242,252.2296,252.62912,252.95103,253.22482,253.44785,253.59357,253.70604,253.8042,253.8937,253.97,254.0648,254.18576,254.32857,254.48672,254.6423,254.79843,254.95955,255.0955,255.20226,255.30489,255.39261,255.55453,255.69374,255.78032,255.87607,255.97083,256.16678,256.36615,256.55627,256.68924,256.8529,257.0427,257.23563,257.4473,257.67065,257.87503,258.04538,258.20175,258.38147,258.49622,258.57477,258.61902,258.56277,258.48145,258.41153,258.37787,258.41385,258.5041,258.6633,258.90817,259.2519,259.66116,260.1317,260.6253,261.10443,261.58182,262.0324,262.4459,262.83478,263.19595,263.49756,263.8007,264.09866,264.35535,264.57993,264.7921,264.9697,265.11453,265.2365],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"colorbar\":{\"title\":{\"text\":\"Pattern Importance\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"name\":\"Pattern Importance\",\"showscale\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[\"2017-03-29T00:00:00\",\"2017-03-30T00:00:00\",\"2017-03-31T00:00:00\",\"2017-04-03T00:00:00\",\"2017-04-04T00:00:00\",\"2017-04-05T00:00:00\",\"2017-04-06T00:00:00\",\"2017-04-07T00:00:00\",\"2017-04-10T00:00:00\",\"2017-04-11T00:00:00\",\"2017-04-12T00:00:00\",\"2017-04-13T00:00:00\",\"2017-04-17T00:00:00\",\"2017-04-18T00:00:00\",\"2017-04-19T00:00:00\",\"2017-04-20T00:00:00\",\"2017-04-21T00:00:00\",\"2017-04-24T00:00:00\",\"2017-04-25T00:00:00\",\"2017-04-26T00:00:00\",\"2017-04-27T00:00:00\",\"2017-04-28T00:00:00\",\"2017-05-01T00:00:00\",\"2017-05-02T00:00:00\",\"2017-05-03T00:00:00\",\"2017-05-04T00:00:00\",\"2017-05-05T00:00:00\",\"2017-05-08T00:00:00\",\"2017-05-09T00:00:00\",\"2017-05-10T00:00:00\",\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"z\":[[0.012638456,0.013280196,0.01400514,0.014882548,0.01594573,0.01730014,0.019010294,0.020986143,0.022996759,0.02462187,0.025562556,0.025677085,0.02496922,0.023614224,0.021953922,0.020601062,0.0198616,0.019653983,0.019681789,0.019722411,0.019680303,0.019561805,0.019371653,0.019129217,0.018836606,0.018467799,0.018037263,0.017571526,0.017108783,0.016679354,0.016354132,0.016112855,0.01598247,0.015967727,0.01607935,0.016335858,0.01677048,0.017427556,0.018346764,0.019568678,0.02119675,0.02312491,0.025082065,0.026671138,0.027514735,0.02761002,0.026958646,0.025619546,0.023795327,0.022071533],[0.012631255,0.013261996,0.013998441,0.014865374,0.01595612,0.017354898,0.019070003,0.021052796,0.023032282,0.024647323,0.025563486,0.025651563,0.02495866,0.023564966,0.02190103,0.020565266,0.0198688,0.019675877,0.019718884,0.019762972,0.01972931,0.01959678,0.01940587,0.019175652,0.018874472,0.0185037,0.018072965,0.017607646,0.017134951,0.01673295,0.016391017,0.016144479,0.016001998,0.015973706,0.016073894,0.016327381,0.016766146,0.01741609,0.018308278,0.019557672,0.021160422,0.023050413,0.025004057,0.02654428,0.027426317,0.027533943,0.02689875,0.02557223,0.023815295,0.022097474],[0.012609152,0.013249137,0.013975435,0.014864852,0.015992861,0.017394189,0.019116493,0.02107676,0.023058712,0.024660219,0.025556467,0.025659489,0.024928315,0.02352115,0.021862091,0.020568674,0.01988931,0.019714218,0.019760834,0.019814063,0.019765247,0.01963272,0.01945521,0.019215124,0.018912043,0.018541351,0.018111533,0.017636428,0.017192312,0.016772904,0.01642521,0.016166154,0.016009822,0.015969947,0.016066646,0.016323548,0.016755711,0.017381044,0.018298144,0.019524474,0.02108629,0.022962084,0.024849959,0.026423857,0.027323948,0.027458414,0.026847469,0.025594214,0.023859825,0.022165999],[0.0126037905,0.013236241,0.013984048,0.014908964,0.016042482,0.017454574,0.019163162,0.021135032,0.023109581,0.024686664,0.02558325,0.025632787,0.024869895,0.02344808,0.021826785,0.020563014,0.019917011,0.01975261,0.019809563,0.019844057,0.019794276,0.019675681,0.019485997,0.01924282,0.018938635,0.018567959,0.018127572,0.017683044,0.017221399,0.016798,0.01643965,0.01616902,0.016003655,0.015962746,0.0160653,0.016319461,0.016733155,0.017385904,0.018288974,0.019483134,0.021033168,0.02283274,0.024732051,0.02630375,0.027220542,0.027374953,0.02682813,0.025602547,0.023911934,0.022202145],[0.012583636,0.013233494,0.014010234,0.014936039,0.016073342,0.017467927,0.019187111,0.021162475,0.02313132,0.024726557,0.025583295,0.025611212,0.024835035,0.023438476,0.02183391,0.020598585,0.019960737,0.019805966,0.019841757,0.019876689,0.019844044,0.019713089,0.019521093,0.019277643,0.018974448,0.01859357,0.018186552,0.017722998,0.017257392,0.016822089,0.01645065,0.0161692,0.016000533,0.015962671,0.016060183,0.016294578,0.01672967,0.017366458,0.01823498,0.01941151,0.020878648,0.022672998,0.02455585,0.026145423,0.027100239,0.027337978,0.026841527,0.02568458,0.024008313,0.022283198],[0.012585241,0.013261295,0.014039357,0.01496858,0.016091049,0.01749763,0.019226646,0.021206347,0.02320172,0.024756482,0.025583968,0.02558738,0.024819722,0.023426846,0.021850089,0.020631509,0.020011513,0.019834854,0.01987086,0.019924078,0.019877555,0.019744372,0.01955174,0.019308643,0.018994024,0.01864879,0.018220948,0.017754933,0.017278267,0.016831046,0.016449904,0.016165966,0.016000794,0.015958948,0.01603898,0.016293563,0.01671597,0.017322695,0.018176747,0.019277455,0.020732975,0.022492075,0.024362959,0.025971698,0.027008383,0.02730158,0.0268799,0.025763249,0.024113838,0.022386828],[0.012596173,0.0132705495,0.014046591,0.014955883,0.016080482,0.017488042,0.019218035,0.021232598,0.023208944,0.02475922,0.025585165,0.02561387,0.024861373,0.023498204,0.021930927,0.02071707,0.020056969,0.019870006,0.019923756,0.019963987,0.019919407,0.019788628,0.019597758,0.019343551,0.019069219,0.018702894,0.01827551,0.01779952,0.017311042,0.016852712,0.016466232,0.016181735,0.01600835,0.015945345,0.016038269,0.016275818,0.016663862,0.017249322,0.018025339,0.019101892,0.020504411,0.022219487,0.024077266,0.0257666,0.026887052,0.027291292,0.026951574,0.025915971,0.024328561,0.022563567],[0.012587161,0.013256271,0.014009776,0.014913963,0.016030714,0.01742873,0.01918252,0.0211787,0.023163542,0.024736976,0.025615001,0.025683787,0.024984796,0.023655582,0.022100579,0.020824263,0.02012496,0.01993499,0.01996568,0.020010954,0.0199757,0.019851552,0.019649971,0.019440401,0.01914409,0.018782474,0.018348832,0.017864661,0.017366977,0.016902706,0.01651251,0.01621529,0.016016176,0.015958369,0.016029136,0.016227651,0.01658809,0.017094878,0.017838318,0.01885208,0.020184685,0.02183547,0.023716485,0.025470296,0.026731843,0.027266769,0.027060384,0.026159417,0.024640858,0.022885019],[0.012578286,0.01322838,0.013978702,0.014878407,0.015989546,0.017411124,0.019147115,0.021144468,0.023142839,0.024760233,0.025669288,0.025781127,0.025117334,0.023825161,0.022234611,0.02092222,0.020210844,0.01997719,0.020003024,0.020057699,0.02003364,0.019900685,0.019747058,0.019509401,0.019217357,0.01885013,0.018411882,0.017923843,0.017425722,0.016961731,0.016561154,0.016240004,0.016045466,0.01596715,0.016001727,0.01617534,0.016467065,0.016947877,0.017640842,0.018593265,0.019852053,0.021475488,0.023336608,0.025164563,0.026539655,0.027217349,0.027159542,0.02637633,0.024979357,0.023220208],[0.012558438,0.013206673,0.013955022,0.014852495,0.015987687,0.01739633,0.019133285,0.021139901,0.02317621,0.02481696,0.02575689,0.02588996,0.02525813,0.023950335,0.022345584,0.021028405,0.020263284,0.020010248,0.020037312,0.020103743,0.02007403,0.019997086,0.019810045,0.019574175,0.019273741,0.018902123,0.01846318,0.017980207,0.01748825,0.017018598,0.016597813,0.016282829,0.016070262,0.015959064,0.015971784,0.01608571,0.016357748,0.016800718,0.017447438,0.018340228,0.019567987,0.021133337,0.022986779,0.024847673,0.026330944,0.027152672,0.027216645,0.02657821,0.025276003,0.023547856],[0.012552307,0.0132013755,0.013951661,0.014875738,0.016006738,0.017423978,0.01917678,0.021223841,0.023279143,0.024934037,0.025867289,0.026000015,0.02533322,0.024010628,0.02241748,0.02105942,0.020282723,0.02002981,0.020065764,0.020125154,0.020158662,0.02004511,0.01985858,0.019609377,0.019300612,0.018926721,0.018494409,0.018021785,0.017529601,0.017045788,0.016636696,0.016309137,0.0160698,0.015942598,0.015906192,0.016008642,0.016256455,0.016670262,0.017279012,0.018160159,0.019343238,0.02088114,0.022702044,0.024586206,0.026155764,0.027068557,0.027250884,0.02670109,0.025484994,0.023779321],[0.0125478655,0.013198675,0.01397223,0.01489237,0.016030151,0.017461985,0.019256877,0.02133442,0.02341879,0.025072617,0.025997965,0.026085485,0.025393933,0.024076568,0.022440216,0.02106734,0.020290606,0.020045538,0.020072965,0.0202041,0.020200033,0.020090548,0.0198893,0.019628773,0.01931535,0.01894764,0.018527143,0.01805698,0.017554302,0.017086431,0.0166677,0.016316498,0.016063714,0.015893022,0.015848288,0.01593302,0.016159806,0.016546734,0.017154135,0.018004965,0.019166553,0.020658769,0.022455582,0.024364725,0.025984567,0.026998738,0.027259335,0.026792776,0.025637828,0.02393614],[0.01254457,0.013215536,0.013985097,0.014909822,0.01605921,0.017529191,0.019358484,0.021480137,0.02358316,0.02523701,0.026111709,0.026163377,0.025463026,0.024094898,0.022434423,0.021056743,0.020290002,0.020036254,0.020143813,0.02023505,0.020239677,0.020117478,0.019904314,0.019636733,0.0193275,0.018970745,0.018552907,0.018074095,0.017591655,0.01711707,0.016678052,0.016316313,0.016024811,0.015848596,0.015791222,0.01586094,0.016068844,0.016461493,0.017050756,0.017891094,0.019016191,0.020476423,0.022263313,0.024171121,0.025854895,0.02692862,0.027259134,0.026847178,0.02572042,0.024006898],[0.012556406,0.013223367,0.013995636,0.014928966,0.016110493,0.017611803,0.01948963,0.021649394,0.02377615,0.02538797,0.026220843,0.026249511,0.025488015,0.02408126,0.022401117,0.021028621,0.020255242,0.020094747,0.020159628,0.020263778,0.020258315,0.020126488,0.019906232,0.01964123,0.019340916,0.01898486,0.018557752,0.018102052,0.017614769,0.01712302,0.016676778,0.016280511,0.015986448,0.015801879,0.015734285,0.015791113,0.0160094,0.016392617,0.016979948,0.017795667,0.018896999,0.0203439,0.022105604,0.02403814,0.025747992,0.02687221,0.027243383,0.026852539,0.025726372,0.024095884],[0.012548401,0.013214895,0.013990522,0.014945991,0.01614731,0.017685117,0.019601012,0.021806639,0.023925945,0.025521953,0.026343187,0.026318751,0.025521407,0.024085602,0.02238906,0.020988367,0.020309955,0.02009811,0.020178756,0.020277062,0.020268008,0.02013393,0.019918153,0.01966148,0.01936,0.018993475,0.018591758,0.018131873,0.01762923,0.017132316,0.016653059,0.016254982,0.015953492,0.01575971,0.015680758,0.015747735,0.015958903,0.016341425,0.016907966,0.017702656,0.018789943,0.02020422,0.021968974,0.023900608,0.02564576,0.026810633,0.027210074,0.026832053,0.025796918,0.024161844],[0.012542926,0.013213016,0.014008973,0.014982988,0.016218076,0.017794315,0.019765051,0.021984657,0.024105255,0.025687227,0.026438711,0.026358772,0.025512319,0.024039939,0.022300964,0.021007381,0.02028461,0.020098774,0.020176422,0.020273061,0.020263782,0.020136155,0.019928657,0.019667769,0.01935187,0.019009942,0.01860159,0.018126419,0.01762127,0.017094528,0.016618138,0.016217362,0.015911743,0.015712202,0.0156477,0.01571418,0.01593086,0.016301991,0.016858017,0.01765008,0.018717488,0.020138897,0.021893071,0.023832627,0.025585923,0.026752314,0.02714552,0.026832534,0.025788497,0.02415532],[0.012538682,0.013226323,0.014037939,0.01504023,0.01630802,0.017936233,0.019933885,0.022182906,0.024315959,0.025831537,0.026516702,0.026373368,0.025471704,0.023930099,0.022278631,0.020938033,0.020254802,0.020076195,0.020159606,0.020260103,0.0202599,0.020141564,0.019928329,0.019650118,0.019358536,0.01900656,0.01858094,0.018103492,0.017568735,0.017047869,0.016571593,0.016170142,0.015862629,0.01568029,0.015619526,0.015694968,0.015905734,0.016272089,0.01683157,0.017612604,0.018693645,0.020110676,0.02187101,0.023807071,0.02554262,0.026684675,0.027123403,0.026789173,0.02573771,0.02416178],[0.012545652,0.013246151,0.0140806055,0.015108563,0.016419174,0.018072976,0.020113712,0.022409992,0.024507014,0.025963334,0.02657829,0.026369577,0.025384057,0.023893619,0.022169722,0.02086695,0.020200945,0.020041106,0.020138862,0.020254204,0.020265486,0.020140301,0.019907422,0.019654425,0.019349698,0.018978013,0.018549262,0.018040352,0.01751285,0.016992927,0.016517783,0.016116787,0.01582818,0.01565225,0.015602372,0.015675195,0.01588429,0.01625696,0.016810315,0.017607978,0.018690355,0.02011832,0.021879202,0.023795605,0.025496986,0.026672961,0.027079891,0.026729252,0.025717914,0.024112182],[0.012548539,0.013266118,0.014118121,0.01517618,0.01650042,0.01818853,0.02028825,0.022587102,0.024663702,0.026069734,0.026627304,0.026341915,0.025391307,0.023806946,0.022088053,0.02078731,0.020141238,0.020005358,0.020129416,0.020263575,0.020270472,0.020125058,0.019919634,0.019651335,0.01932536,0.018950582,0.01848852,0.017987952,0.0174608,0.016941804,0.01646703,0.016084433,0.015802134,0.015636347,0.015583991,0.015654825,0.01586919,0.016235752,0.016803045,0.017600806,0.018691618,0.020119816,0.021863542,0.023748603,0.025490183,0.026638318,0.027034663,0.026722385,0.025685286,0.024157386],[0.012555564,0.013286378,0.014160882,0.015225097,0.01657293,0.018313574,0.020430883,0.022742558,0.024798954,0.026159642,0.026645064,0.026384853,0.025338655,0.023734018,0.021989271,0.020698149,0.020080859,0.019983264,0.02013656,0.020270368,0.020257512,0.020142332,0.019919233,0.019627808,0.019298732,0.018888429,0.018435871,0.017934991,0.017408604,0.016889982,0.016433723,0.016057612,0.015785381,0.015617775,0.015563832,0.015639836,0.015849076,0.016228413,0.016796166,0.017601475,0.018692745,0.020105531,0.021819185,0.023746993,0.025461124,0.02659949,0.027031792,0.026696712,0.025728216,0.024233948],[0.0125604225,0.013308096,0.014183252,0.015261002,0.016647719,0.01840139,0.0205431,0.022865998,0.024907397,0.026212212,0.026725268,0.026379399,0.025308829,0.023657912,0.02189342,0.020617522,0.02004146,0.019982722,0.020142721,0.020260034,0.020282775,0.020148605,0.019900773,0.019606698,0.019240063,0.01884106,0.018387843,0.017887607,0.017361248,0.01686096,0.016410375,0.016043486,0.015769027,0.0155992955,0.015549531,0.015620297,0.015840262,0.016219165,0.016792145,0.017595973,0.018670809,0.020052722,0.021807462,0.023709865,0.025417462,0.026597232,0.027013717,0.026744017,0.025811778,0.024317821],[0.012569775,0.013315941,0.014199197,0.015305977,0.016698569,0.01847228,0.02063579,0.022969313,0.024976764,0.026319208,0.026752548,0.02638409,0.025265375,0.02357556,0.021801624,0.02055946,0.020027777,0.019982172,0.020129913,0.020289514,0.02029269,0.020132564,0.019882709,0.019548632,0.019195316,0.018795287,0.018342625,0.017842218,0.017334564,0.016839273,0.016397541,0.016028251,0.015751598,0.015585682,0.015531125,0.015611548,0.01583119,0.016214425,0.0167856,0.017573778,0.018619193,0.0200388,0.021768425,0.023661101,0.025410783,0.02657607,0.027055014,0.026817596,0.025892166,0.024413439],[0.012565089,0.013315789,0.014220458,0.015326602,0.016729552,0.01851915,0.020700686,0.023021085,0.02509168,0.026367493,0.02678689,0.026379399,0.025223413,0.023507273,0.021744642,0.020538842,0.020019578,0.019963084,0.020161496,0.020302312,0.020279994,0.020119792,0.019827707,0.019509602,0.019155266,0.018756019,0.018303297,0.017822433,0.017318988,0.01683205,0.016387092,0.016014948,0.01574121,0.015570214,0.015523802,0.015603361,0.015825914,0.016206363,0.016761873,0.017521577,0.01859969,0.019994333,0.021709707,0.023641763,0.025376922,0.026608687,0.02711986,0.026891485,0.025988312,0.024503391],[0.012565672,0.013335215,0.014239467,0.015354339,0.016771913,0.018581644,0.020759353,0.023158805,0.025166808,0.026423298,0.026795855,0.026344564,0.025150763,0.02342679,0.021692816,0.02050633,0.019984055,0.019991444,0.020171518,0.020284787,0.020262212,0.020056037,0.019782092,0.019462436,0.019108323,0.01870816,0.018275173,0.01779732,0.017302172,0.016812088,0.01636533,0.015997471,0.015720703,0.015559203,0.015514252,0.0155986175,0.015821109,0.016190149,0.016723417,0.01751748,0.018579286,0.01996459,0.021719117,0.023630591,0.02542343,0.026672712,0.027175885,0.026952324,0.026036585,0.024566224],[0.01257793,0.013346118,0.014255842,0.015380754,0.016813576,0.018619994,0.020885915,0.023242319,0.025243867,0.026455687,0.026785163,0.026295789,0.025083283,0.023366924,0.021639435,0.020449128,0.020004379,0.019997677,0.020151926,0.020266928,0.02019541,0.020009527,0.019733457,0.01941404,0.0190589,0.018679267,0.018247984,0.017777743,0.017278137,0.01678579,0.016343271,0.015972914,0.01570587,0.015546758,0.015507127,0.015592431,0.015805524,0.01615564,0.016721804,0.017504364,0.018560117,0.01998565,0.02172382,0.023696529,0.025507458,0.026740594,0.027235089,0.026986863,0.026074152,0.024591008],[0.012573816,0.013343785,0.014257735,0.015389461,0.016811134,0.018694464,0.020927213,0.02329753,0.025275739,0.026461331,0.026767753,0.026269976,0.025063716,0.023340039,0.021588545,0.020472419,0.020008676,0.019974744,0.020135146,0.02020137,0.020155707,0.01996829,0.019692702,0.019372739,0.01904013,0.018661935,0.018238485,0.017762603,0.017259635,0.016770214,0.016323777,0.015961586,0.015695702,0.015540343,0.015500375,0.015575697,0.015770115,0.016148565,0.016703475,0.017478248,0.018568773,0.019978054,0.021778258,0.023780786,0.025586737,0.02681516,0.027283562,0.027032472,0.026104027,0.024597233],[0.012572264,0.013346226,0.01426654,0.015389012,0.016880723,0.01873831,0.020991402,0.023346277,0.025298689,0.026456788,0.026749056,0.026249083,0.025026841,0.023268465,0.021591486,0.020462465,0.019975169,0.019953648,0.02006421,0.020160565,0.020112282,0.019923637,0.019646479,0.019350396,0.01901811,0.018647287,0.018216556,0.017736299,0.017235672,0.016742019,0.016304225,0.015944118,0.01568305,0.0155288465,0.015481215,0.015541202,0.015763577,0.016135251,0.016686069,0.017496372,0.018577358,0.020050855,0.021891098,0.023899283,0.025701482,0.026890125,0.027334394,0.027046788,0.026077567,0.024551164],[0.012571115,0.013350104,0.014261514,0.015444178,0.0169127,0.018789934,0.021036288,0.023375915,0.025306357,0.026451338,0.026739761,0.026222585,0.024961768,0.023262782,0.021567842,0.020414272,0.01994457,0.019873848,0.020023763,0.020119328,0.020069176,0.019877054,0.019624688,0.019328043,0.01900336,0.018624132,0.018188197,0.017709345,0.01720308,0.016717484,0.016281318,0.015925994,0.015666451,0.0155056575,0.015444565,0.015531044,0.015749006,0.016117904,0.01670218,0.017505836,0.018647784,0.020166216,0.022026716,0.024051746,0.025823403,0.02697954,0.027371075,0.0270275,0.026019447,0.024482101],[0.01257017,0.013340726,0.014303149,0.015463903,0.016946904,0.018818606,0.021056449,0.023383878,0.025308615,0.026452992,0.026726665,0.026175946,0.02496382,0.02323979,0.02151039,0.020373136,0.019849578,0.019829638,0.019984592,0.020080782,0.020026494,0.019859338,0.019604582,0.01931586,0.018982083,0.018597439,0.018162506,0.017676562,0.017177468,0.016692173,0.016260013,0.015905801,0.015639933,0.015466686,0.015430293,0.015513708,0.015729228,0.016128639,0.01670733,0.017565746,0.018750636,0.020294324,0.022189599,0.024211308,0.025965868,0.027063778,0.027387558,0.026991772,0.025951676,0.02437196],[0.012557529,0.013371347,0.01431341,0.015483456,0.016958727,0.018821493,0.021051113,0.023380766,0.025312744,0.026447445,0.026694808,0.026189387,0.024954833,0.023190292,0.02146679,0.020262955,0.01979593,0.019787705,0.019949347,0.020043729,0.020016005,0.019843819,0.019596495,0.019297792,0.01895882,0.01857549,0.018132577,0.017653381,0.017153041,0.016670594,0.016238553,0.015877645,0.0155997025,0.015449361,0.015410646,0.015491526,0.015734537,0.01612875,0.016755491,0.017651858,0.018859202,0.020441536,0.022355134,0.024392588,0.026106669,0.027133899,0.02739614,0.026955789,0.02585617,0.024232972],[0.012588489,0.013385673,0.014335988,0.015500554,0.01697004,0.018829117,0.021065814,0.023405408,0.025323216,0.026424577,0.026705462,0.02617246,0.02489406,0.0231254,0.021324955,0.020185703,0.019740405,0.019749682,0.019914586,0.02003762,0.020000681,0.019833125,0.019573353,0.01926914,0.018931668,0.01853931,0.01810278,0.01762077,0.017122377,0.016639529,0.016201211,0.015829695,0.015574858,0.015424414,0.015384901,0.015492689,0.015733141,0.016172148,0.016835062,0.01775286,0.018998744,0.020610217,0.022567414,0.024597498,0.026249934,0.027202195,0.027400304,0.026883205,0.025714085,0.02406342],[0.012570313,0.013367603,0.014302977,0.015447708,0.016895004,0.018741677,0.020980997,0.023323108,0.025245152,0.026425403,0.026722055,0.02618862,0.024933375,0.023085913,0.021313837,0.020158103,0.019708613,0.019716557,0.01991853,0.02003872,0.020012267,0.019833876,0.019570032,0.019269546,0.018924782,0.01854184,0.018103657,0.017623836,0.017123202,0.016630737,0.016177826,0.015823936,0.015564253,0.015407693,0.01538732,0.015486884,0.01576019,0.016222786,0.016892156,0.017828472,0.019084856,0.020732816,0.022707358,0.024725044,0.026347818,0.027265744,0.0274116,0.02684618,0.025649305,0.023959748],[0.012568407,0.013356109,0.014279444,0.015412442,0.016857704,0.01871204,0.020945912,0.023268456,0.025247216,0.026422357,0.026704026,0.026180299,0.02485075,0.02303474,0.021258896,0.020111887,0.01967007,0.019722648,0.019918416,0.02004503,0.02000234,0.019817468,0.01955698,0.019248012,0.01891275,0.01852678,0.018090168,0.017607668,0.017097805,0.01659239,0.016159356,0.015803544,0.015540945,0.01540526,0.015380878,0.01551342,0.015811924,0.016283361,0.01697216,0.017921653,0.01921837,0.020897899,0.022884635,0.024892144,0.026476333,0.02732101,0.027398013,0.026783142,0.02552155,0.023795202],[0.012556348,0.013333433,0.014246701,0.015378335,0.016830591,0.018677998,0.02088564,0.023259588,0.02523064,0.026392821,0.026687078,0.02610256,0.024801672,0.022978622,0.02120765,0.020067967,0.01967823,0.019725395,0.019927738,0.020034831,0.019983733,0.019801827,0.01953221,0.019234264,0.018895928,0.018511795,0.018072044,0.017579531,0.017056225,0.01657108,0.016136104,0.015777953,0.015535688,0.01539716,0.015403355,0.015559451,0.015865235,0.01635228,0.01705029,0.01803366,0.01936056,0.021063969,0.023070922,0.025072696,0.026593039,0.027363323,0.02738335,0.02669743,0.025376264,0.023664713],[0.012542547,0.013312554,0.014227531,0.015369589,0.016820656,0.018646091,0.020901293,0.023259567,0.025205119,0.026369711,0.026601635,0.026036395,0.024721073,0.022896007,0.02113561,0.02006598,0.019680431,0.019739646,0.019919107,0.020013422,0.019961854,0.0197677,0.019509802,0.019208597,0.018872315,0.018484293,0.018033208,0.017526107,0.017023649,0.016536327,0.016100237,0.015763368,0.015520534,0.0154123055,0.015442471,0.015606605,0.015927201,0.01642295,0.017151752,0.018164013,0.019518925,0.021260332,0.023296803,0.025262244,0.026707387,0.027404867,0.02734037,0.026579972,0.025236972,0.023492849],[0.012531614,0.01330473,0.014231434,0.015376118,0.016811661,0.018685715,0.020930335,0.023259435,0.025198804,0.026292607,0.026536077,0.025949923,0.024620106,0.02279061,0.021106077,0.020056723,0.019697268,0.019737948,0.019903809,0.019994149,0.019924887,0.019740645,0.019478425,0.019180067,0.018839892,0.018439515,0.017972302,0.017485954,0.01697931,0.016490655,0.016076153,0.015740016,0.015527331,0.015443383,0.015482241,0.01566055,0.01598941,0.016512908,0.01726781,0.01830652,0.01970398,0.021497691,0.02353898,0.025458513,0.0268297,0.02742783,0.027276386,0.02647229,0.025061006,0.023180328],[0.012528728,0.013312893,0.01424307,0.015375487,0.016856834,0.01872679,0.02094831,0.023273945,0.02513647,0.026238106,0.026458789,0.02585502,0.024507906,0.022735426,0.021072846,0.020065337,0.019695872,0.019729469,0.019892687,0.019961312,0.019898938,0.019706849,0.019447437,0.019145941,0.018793587,0.018376503,0.017930564,0.017437192,0.016927505,0.0164594,0.016045026,0.015738158,0.015549081,0.015473513,0.015525176,0.015710456,0.016063321,0.016608693,0.017384943,0.018461281,0.01991455,0.021739146,0.023779223,0.025657656,0.026931215,0.02743339,0.027226344,0.02634055,0.024761453,0.022917556],[0.012532337,0.013318752,0.014236749,0.015407293,0.016883845,0.018731944,0.020954067,0.023205865,0.025082106,0.026168007,0.026380925,0.025767345,0.024467012,0.02270408,0.02108089,0.0200649,0.019690558,0.019726431,0.019868331,0.019944236,0.01987093,0.019680131,0.019417686,0.019105004,0.018736975,0.01834371,0.017888995,0.017390927,0.01690001,0.016429247,0.016041748,0.015755853,0.015572881,0.015507007,0.015562537,0.015766494,0.016135143,0.016694082,0.017497433,0.018619122,0.020104038,0.021951374,0.023997141,0.02581464,0.02700438,0.027451959,0.027166575,0.026121236,0.024529576,0.022727532],[0.0125289215,0.013303024,0.01425135,0.015414129,0.016865576,0.018709349,0.020855853,0.023121916,0.024990661,0.02608498,0.026307615,0.025750844,0.024467608,0.022742666,0.02110473,0.020075046,0.019697241,0.01970915,0.01986079,0.019925747,0.019853791,0.019659441,0.019386051,0.019059109,0.018719247,0.018317325,0.01785815,0.01737856,0.016881933,0.016435368,0.016064912,0.015781296,0.01560357,0.015537126,0.015605066,0.015817959,0.01619183,0.016766354,0.017600294,0.018740637,0.020243969,0.022116113,0.02414288,0.0259147,0.02707155,0.02745556,0.02703877,0.025978463,0.024389274,0.02262337],[0.012513713,0.013313799,0.0142553,0.015394881,0.01684094,0.018611087,0.020761857,0.023009732,0.024883583,0.025995042,0.026281526,0.025751658,0.024516044,0.022789598,0.02114058,0.020101711,0.019689888,0.0197091,0.019847551,0.019914158,0.01983835,0.019632366,0.019344838,0.019050296,0.018701924,0.01829676,0.017857708,0.017370915,0.016897919,0.0164657,0.01609458,0.015812837,0.015631177,0.01557249,0.015644573,0.015857197,0.016239045,0.016833818,0.017675709,0.018823752,0.02034788,0.022215392,0.024226049,0.025994774,0.027105546,0.027381131,0.026962457,0.025902972,0.024323588,0.022576556],[0.012530892,0.01332683,0.01425001,0.0153879365,0.016772278,0.018546896,0.02067282,0.022907369,0.024782062,0.025949301,0.026258245,0.025772016,0.024544058,0.022823224,0.021177921,0.020104393,0.019698672,0.019699631,0.01983747,0.019898353,0.019809233,0.019588077,0.01933645,0.019032288,0.018681243,0.018298127,0.01785097,0.017389026,0.016929362,0.01649521,0.01612459,0.015837492,0.01566135,0.015604649,0.015674157,0.015891274,0.016288286,0.016886232,0.017730042,0.01889299,0.020413224,0.02227458,0.024301998,0.026039405,0.027051298,0.027333714,0.026919935,0.025866933,0.0242911,0.022566356],[0.012522712,0.013298494,0.014213961,0.015289607,0.01666606,0.018402984,0.020496858,0.022720447,0.02466509,0.02588596,0.026271494,0.025828782,0.024643393,0.022952825,0.021264005,0.020166384,0.019711604,0.019695297,0.01982429,0.01987573,0.019776838,0.019599648,0.01933866,0.019033467,0.018708644,0.018318981,0.017900882,0.017453017,0.016990043,0.016553285,0.016172435,0.015884453,0.015703237,0.015636416,0.015701497,0.01592287,0.016311496,0.016897153,0.017737586,0.018877858,0.020374237,0.022246711,0.024258867,0.02592714,0.026991006,0.02732021,0.026949894,0.025931317,0.02438987,0.022696313],[0.012502946,0.01327333,0.014137687,0.015210468,0.016558355,0.01826252,0.02032362,0.022582721,0.024557635,0.02584834,0.026277097,0.025881639,0.024748804,0.023058757,0.021371134,0.020215623,0.01972619,0.01968266,0.019792987,0.019833773,0.019786537,0.0196007,0.019338889,0.019061364,0.018728275,0.01837052,0.017967854,0.017518232,0.017054625,0.016608525,0.01622666,0.015932633,0.015740069,0.015666956,0.015733678,0.015945042,0.016319662,0.016899254,0.017715912,0.018829359,0.020328494,0.022173224,0.02409465,0.025811804,0.026934367,0.027321532,0.027000355,0.026035365,0.024555149,0.02285405],[0.012494803,0.013224317,0.014091608,0.015148609,0.016477212,0.018154869,0.020236108,0.022493478,0.024506943,0.025818419,0.026277073,0.025920255,0.024796987,0.02314222,0.021428216,0.020245608,0.019722542,0.019647159,0.019738497,0.019833656,0.019776301,0.01959051,0.019358188,0.019068781,0.018768236,0.018424802,0.018020155,0.017571846,0.017101316,0.016657108,0.0162715,0.015968267,0.015771125,0.015700888,0.015759956,0.01596016,0.016331583,0.016893182,0.017689819,0.018810537,0.020284712,0.022024032,0.023964504,0.025718354,0.026890386,0.02732339,0.027052833,0.026153637,0.024700915,0.022994466],[0.0124550555,0.013188071,0.014044535,0.015088267,0.016396733,0.01809206,0.020161612,0.022438757,0.024457699,0.025792018,0.02628392,0.025936114,0.024854593,0.02319961,0.021477293,0.020259017,0.01969299,0.019587142,0.019733936,0.01981639,0.019760652,0.01960868,0.019362282,0.01910674,0.01881893,0.018472118,0.018069414,0.017615339,0.017149013,0.016702766,0.016309356,0.016002389,0.015808262,0.015731102,0.015779875,0.015977336,0.016333202,0.016877817,0.01768307,0.018783195,0.020153593,0.02189386,0.023846343,0.02563275,0.026848271,0.02733408,0.027128497,0.02626918,0.024846267,0.023139736],[0.012450056,0.013179758,0.014033856,0.0150733,0.016414661,0.01811662,0.020210968,0.022477414,0.024482563,0.025805226,0.026262812,0.025914676,0.024808535,0.023148965,0.021419786,0.020188397,0.019611776,0.019577187,0.019706823,0.019784627,0.01975972,0.019587863,0.019375676,0.019129567,0.018833905,0.018485941,0.018075027,0.017625516,0.01715914,0.016709171,0.016317463,0.016019365,0.015825067,0.015744928,0.015798446,0.015990162,0.0163405,0.016905528,0.01770831,0.0187304,0.020115323,0.021868935,0.023830105,0.025619173,0.02684567,0.027355611,0.027154155,0.02630154,0.024886927,0.023232771],[0.012436387,0.013162945,0.014011819,0.015078,0.016423032,0.01814627,0.02023434,0.022496609,0.02450029,0.025794467,0.026254112,0.025884384,0.024771241,0.023096045,0.021341374,0.020091562,0.019596314,0.019546935,0.01967528,0.019787943,0.019740479,0.019605173,0.019401677,0.019146135,0.018848995,0.018491887,0.018085485,0.017635193,0.0171646,0.016716173,0.016333006,0.016034538,0.015837146,0.01576112,0.01580911,0.01599535,0.016364004,0.01692687,0.017658044,0.018692685,0.020092128,0.021854978,0.023817081,0.025615148,0.026863588,0.027373914,0.027175616,0.026330471,0.0249718,0.023328185],[0.012422765,0.013145313,0.014018313,0.01508904,0.016454328,0.018174944,0.020264484,0.0225323,0.024508335,0.025799682,0.02623125,0.025847165,0.024710204,0.022997633,0.021213723,0.020057656,0.019555075,0.019512476,0.019682027,0.019768434,0.01975824,0.019629302,0.019414019,0.01915655,0.018849108,0.018496163,0.018087752,0.017632298,0.01716312,0.016723523,0.016340615,0.016040154,0.015847798,0.015767964,0.015812235,0.016016893,0.016385784,0.016885685,0.017630976,0.018685335,0.020100199,0.021868132,0.023838129,0.025652003,0.026888257,0.027387384,0.027182262,0.026374938,0.025029015,0.023370957],[0.012407937,0.013151731,0.014029139,0.015117535,0.016480962,0.01820523,0.020307595,0.022557318,0.024535038,0.025795175,0.026207298,0.025794895,0.024612831,0.022850927,0.021152746,0.019994361,0.019509237,0.019521797,0.019665454,0.019791253,0.01978396,0.01963941,0.019421576,0.019153241,0.018850425,0.01849458,0.018079787,0.017624892,0.017163914,0.016724091,0.016339447,0.016044423,0.015849298,0.015766863,0.015829187,0.016035436,0.01634801,0.016862068,0.01762978,0.018703876,0.020130055,0.021912986,0.023905853,0.025706071,0.026920184,0.027397623,0.027209058,0.026399137,0.02503682,0.02334938],[0.0124142235,0.013162107,0.014054573,0.015140914,0.016507491,0.018246742,0.020340422,0.022603335,0.024554204,0.025791895,0.026171496,0.025711946,0.02447045,0.022767782,0.021057157,0.01992388,0.019511957,0.019505627,0.019695852,0.019821845,0.019793656,0.019644257,0.019414522,0.019151976,0.018846156,0.018483207,0.018068189,0.017620465,0.017157845,0.01671565,0.01633628,0.016038924,0.015841905,0.015777059,0.015841836,0.015997112,0.016323255,0.01686082,0.017650157,0.018739121,0.020186095,0.022003211,0.023995824,0.025776897,0.026958905,0.02743372,0.027223362,0.026382837,0.024982551,0.023300204],[0.012406593,0.013163984,0.014049031,0.015129808,0.016499816,0.018222941,0.020330418,0.022582049,0.024533771,0.025762709,0.026120096,0.025625883,0.024442364,0.02271339,0.021004539,0.019937247,0.019498171,0.019545142,0.019737026,0.019841386,0.019809015,0.01964773,0.019425975,0.01916199,0.018850563,0.018488973,0.018081887,0.017631447,0.017164629,0.016725186,0.016340429,0.01603798,0.015854144,0.015788011,0.015801592,0.015964547,0.016308567,0.01686112,0.017657753,0.018758735,0.02023409,0.022057835,0.024051646,0.025823232,0.027016275,0.027473886,0.0272374,0.026363928,0.024963034,0.023272056],[0.012405059,0.013155484,0.01403464,0.015117264,0.016471623,0.018205982,0.020302217,0.02255506,0.024499627,0.025710149,0.026041334,0.025602564,0.024396094,0.022663826,0.0210221,0.019925654,0.01954715,0.01959455,0.019760024,0.01985803,0.019812146,0.019660072,0.019437408,0.01916839,0.018859498,0.018506844,0.01809682,0.017641919,0.0171775,0.016731778,0.016341144,0.016050342,0.015864195,0.015749061,0.015768198,0.015947606,0.016305087,0.016863452,0.017669555,0.018795433,0.020278,0.02210929,0.024106396,0.025900781,0.02707532,0.027500505,0.027226852,0.026344178,0.024927521,0.023216156],[0.012389669,0.013133521,0.01401232,0.015078605,0.016439158,0.018158829,0.020251444,0.022495499,0.024425538,0.025621396,0.026016999,0.025569348,0.024368567,0.022705402,0.02103224,0.019997928,0.019613532,0.01962455,0.019779235,0.019861894,0.019827476,0.019675903,0.019449145,0.01918428,0.018886143,0.0185313,0.018117635,0.017665783,0.017194545,0.01674202,0.016361196,0.016065942,0.015831038,0.015718298,0.015751021,0.015940754,0.016300684,0.016863722,0.017687554,0.018814478,0.02029973,0.022137403,0.024174305,0.025967319,0.027116966,0.027508982,0.027226456,0.026327943,0.024887886,0.023168368],[0.012373803,0.013118471,0.013985074,0.01505958,0.01641078,0.018129122,0.020210357,0.02242906,0.02433147,0.025583962,0.025966743,0.025522714,0.024385927,0.02270271,0.021109894,0.020079665,0.019654505,0.019647146,0.019779172,0.01987166,0.019837203,0.019681895,0.01946036,0.019207183,0.018906567,0.018548341,0.01813865,0.017680414,0.01720323,0.016761243,0.01637607,0.016033886,0.01580104,0.015701665,0.015744492,0.015936686,0.016300697,0.016879436,0.01770353,0.01883152,0.020322572,0.022205574,0.024253646,0.026027462,0.027140124,0.0275154,0.027209759,0.02628222,0.024825273,0.023131946],[0.012362636,0.013097552,0.013972573,0.015041075,0.01639345,0.01810327,0.020157894,0.022339426,0.0242911,0.025524896,0.0259094,0.025521025,0.024368554,0.02277393,0.02120333,0.020135945,0.019687926,0.019648336,0.019786218,0.019876527,0.01983837,0.019690035,0.019481597,0.019225458,0.018921487,0.018568134,0.018152475,0.01768935,0.017224036,0.016777864,0.016346646,0.016006399,0.015786288,0.015696216,0.015740782,0.0159357,0.016312616,0.01688971,0.017711695,0.018841604,0.020375038,0.022277227,0.024320424,0.026065936,0.027162198,0.027511029,0.027174927,0.026226504,0.024783587,0.023071714],[0.01234154,0.01308348,0.013953183,0.015022255,0.0163665,0.018050205,0.020063609,0.022288853,0.024218677,0.025456956,0.025897698,0.025500601,0.024436811,0.022882596,0.02128792,0.0201943,0.019701237,0.01965808,0.019788174,0.019874172,0.019846002,0.019714117,0.019502943,0.019243333,0.018945102,0.018586325,0.018167268,0.017718269,0.017249418,0.016757399,0.016328236,0.015999354,0.015786642,0.015696239,0.015740773,0.01594443,0.016316138,0.01688616,0.017703492,0.018865617,0.020413483,0.02231504,0.024343465,0.02608841,0.027167533,0.027493343,0.02714299,0.026207743,0.02474485,0.02301894],[0.012334508,0.013073209,0.0139452815,0.015010125,0.016334679,0.017982552,0.020035869,0.02223122,0.024153631,0.025438195,0.025863238,0.025539793,0.024516642,0.022960193,0.021358456,0.0202208,0.019720217,0.01965985,0.019779515,0.019875182,0.019866068,0.019732554,0.019517826,0.019263638,0.018958833,0.018596897,0.018193994,0.017742712,0.017229132,0.016742121,0.016325317,0.01600409,0.015790993,0.015700005,0.015751751,0.01594961,0.016313182,0.016876973,0.017721353,0.018894846,0.020440532,0.02232923,0.02436444,0.026097937,0.027155718,0.027468294,0.027128149,0.026174594,0.024695856,0.022940116],[0.012317962,0.013057383,0.013923871,0.0149687175,0.016257547,0.017937187,0.01995731,0.022140058,0.02411251,0.02538956,0.025892273,0.025613388,0.02460483,0.02306492,0.021427201,0.020270973,0.01973588,0.01964955,0.01977399,0.019891782,0.019885127,0.019752024,0.019544672,0.019282874,0.018974874,0.018631281,0.018227572,0.017732598,0.017228121,0.016754681,0.01634504,0.016021745,0.015805408,0.015717758,0.015760288,0.015945924,0.016298361,0.0168802,0.017727273,0.018888578,0.020411197,0.022301668,0.02433236,0.02605995,0.027123148,0.02746087,0.02711885,0.026164498,0.024665046,0.02297098],[0.012305765,0.013040876,0.0138908485,0.014905894,0.016224878,0.017875489,0.019877365,0.022100298,0.024055902,0.025404928,0.025942972,0.025674544,0.024689952,0.023140032,0.021501945,0.02030773,0.019734604,0.019640854,0.019781748,0.019901171,0.019898359,0.01977737,0.019562561,0.019296067,0.019006303,0.018661097,0.018213185,0.017732555,0.017245393,0.016781954,0.016371902,0.0160459,0.01583222,0.015735,0.015764747,0.015938642,0.016305866,0.016888667,0.017721795,0.018857144,0.020374577,0.022251962,0.024268676,0.026002115,0.027097497,0.027441496,0.027107557,0.026145222,0.024711067,0.022965243],[0.012289692,0.013010351,0.013834562,0.014876599,0.016171005,0.017802585,0.019837404,0.022035807,0.024061019,0.025442744,0.025987484,0.025739396,0.024754502,0.023226013,0.021565568,0.02032626,0.019734437,0.019645816,0.019779947,0.01990334,0.019917963,0.019793663,0.019575477,0.019327223,0.019033216,0.018640883,0.018211413,0.017751636,0.017278213,0.01681744,0.01640662,0.016083702,0.015860502,0.015750203,0.015767794,0.015953802,0.016320743,0.016888812,0.017695336,0.018821621,0.020319678,0.02217007,0.024178507,0.02594298,0.027052283,0.027415212,0.027086657,0.02619206,0.024728741,0.02299307],[0.01226538,0.012964557,0.013813971,0.01483764,0.016117437,0.017780282,0.019788904,0.022050539,0.024103118,0.025482705,0.026035689,0.025778232,0.024812492,0.023279594,0.021590091,0.020332994,0.019743642,0.019638209,0.019768883,0.019909894,0.019923542,0.0198,0.019603001,0.01934753,0.01900072,0.018628495,0.018221145,0.017777698,0.017310552,0.016852928,0.016448263,0.016118132,0.015883742,0.015762985,0.01579262,0.015979674,0.016334193,0.016879274,0.017679233,0.018789472,0.020259183,0.022088073,0.024108417,0.025872773,0.026998851,0.027370974,0.02710507,0.026193902,0.024754072,0.02302124],[0.012234188,0.012957364,0.013794694,0.014810147,0.016123952,0.017769545,0.019842446,0.02213316,0.024174882,0.025543813,0.026064772,0.025802458,0.024819205,0.023261523,0.021567278,0.020326179,0.019726988,0.019617654,0.019763237,0.019900424,0.019915145,0.019816397,0.019611198,0.019296946,0.0189706,0.018619042,0.018227302,0.01779111,0.01733012,0.016882682,0.016474856,0.016137706,0.015896944,0.01579098,0.015825521,0.016005052,0.016343035,0.016887894,0.017681185,0.018773956,0.020228738,0.022064773,0.024064913,0.025821768,0.026939742,0.027358288,0.027069906,0.026174704,0.024742238,0.023023315],[0.012240137,0.012955606,0.013789298,0.014840174,0.016146779,0.017861664,0.019978693,0.022270879,0.024296327,0.02560836,0.026092617,0.025783295,0.024751332,0.023172937,0.021499295,0.020267256,0.01968339,0.019601,0.019743763,0.019880053,0.019919101,0.019809611,0.01954024,0.019248027,0.018940603,0.018601835,0.01821506,0.01778459,0.01733533,0.01688743,0.016476724,0.01613801,0.015916228,0.015820106,0.015852887,0.016022824,0.016367298,0.01691491,0.017703196,0.018795414,0.020271147,0.022094345,0.02407599,0.025798047,0.02693442,0.027307471,0.027013557,0.026108025,0.024678223,0.022966396],[0.012219602,0.012928026,0.013786799,0.014823156,0.016180443,0.017929621,0.020057064,0.022363419,0.024365405,0.025663253,0.02611494,0.025769535,0.024719302,0.023146812,0.021459505,0.020225162,0.019662622,0.01957545,0.019720506,0.019888157,0.019919898,0.01974517,0.019503029,0.019231074,0.018936116,0.018601818,0.018220942,0.017802779,0.01735283,0.016901782,0.016488709,0.016167006,0.015952619,0.015852218,0.015872922,0.016045252,0.016388498,0.016926965,0.017709428,0.018816058,0.020276643,0.02208216,0.024033466,0.025786823,0.026889157,0.027269877,0.026978377,0.026084092,0.0246629,0.022902602],[0.012200389,0.012931914,0.01378023,0.014863339,0.016255897,0.01802261,0.020178622,0.02247806,0.024468267,0.025718374,0.02611502,0.025731932,0.024665698,0.023063565,0.021369986,0.02017022,0.019617038,0.019542206,0.019724943,0.019883128,0.019843409,0.019698832,0.019477379,0.019216454,0.01892354,0.018592967,0.01822288,0.017802589,0.017349731,0.016897885,0.016504155,0.016192352,0.015976807,0.015868077,0.01589431,0.016069597,0.016409162,0.016948134,0.01775171,0.018854711,0.020309087,0.022090282,0.024070598,0.025771352,0.026861934,0.027227916,0.026931917,0.026032628,0.024558468,0.02286973],[0.012206573,0.012929697,0.013819027,0.0149340695,0.016343944,0.018144514,0.02031399,0.022627687,0.02457857,0.02576296,0.026106397,0.02568924,0.024573699,0.022938726,0.021266684,0.020085573,0.019561352,0.01954134,0.019719947,0.019802358,0.019795684,0.019670997,0.01945876,0.019198118,0.018907512,0.01858631,0.018211676,0.017786851,0.01733248,0.016900465,0.01651735,0.016206043,0.015984582,0.015883384,0.015915185,0.016090099,0.016433593,0.01699641,0.01780285,0.018907906,0.020349529,0.02217297,0.024105303,0.025785798,0.02684498,0.02719028,0.026875356,0.025916727,0.024489172,0.022737237],[0.01218656,0.012941436,0.013852649,0.014973221,0.016401878,0.018210037,0.020409264,0.022720704,0.024638833,0.025790438,0.026112696,0.025657821,0.024508782,0.022870254,0.021186654,0.020019857,0.01955303,0.019532537,0.01963636,0.019762551,0.019781051,0.019666415,0.019453717,0.019195361,0.018914748,0.018588476,0.01820895,0.017781941,0.017346697,0.016923124,0.016538179,0.0162187,0.016001895,0.015903337,0.015931817,0.016106913,0.01646837,0.017029274,0.017831778,0.018919447,0.020400612,0.022184534,0.02411108,0.025774745,0.026824905,0.027161626,0.026804289,0.02588976,0.024398785,0.022673924],[0.0122022405,0.012977329,0.013894041,0.015031828,0.016470069,0.018314881,0.020531876,0.02282963,0.024716204,0.025832409,0.026100932,0.025598,0.02442403,0.02275058,0.02107115,0.019978203,0.019526845,0.019436454,0.019597057,0.019751191,0.019777171,0.01965788,0.019445166,0.0191962,0.018908734,0.018575966,0.018192653,0.017784016,0.017355818,0.016930059,0.016537795,0.01622442,0.016012177,0.015912803,0.015943993,0.016138628,0.016501905,0.01706299,0.017854648,0.018987002,0.020441728,0.022230081,0.02414344,0.025789542,0.026815454,0.027098931,0.02676688,0.025785137,0.024301888,0.02259201],[0.01220902,0.01298327,0.0139057115,0.015038888,0.016494771,0.018347846,0.020563778,0.022864876,0.024754649,0.025847029,0.026093563,0.02558542,0.02438483,0.022694724,0.021058729,0.01995973,0.019418,0.019392127,0.019591207,0.01976032,0.019785356,0.01966759,0.019465398,0.019209431,0.018916221,0.01858074,0.018217376,0.017815128,0.017383045,0.016947428,0.01655802,0.01624517,0.016027834,0.015926287,0.015970483,0.016161004,0.016517114,0.017059669,0.017882604,0.018980866,0.020431776,0.02220924,0.024119968,0.025764145,0.026760718,0.027089152,0.02671819,0.025757357,0.024287397,0.022596788],[0.012202039,0.012978385,0.0138924625,0.015034787,0.016490825,0.018337395,0.020559741,0.022879845,0.024763983,0.025850188,0.026103592,0.025581554,0.024370754,0.022717511,0.021063829,0.019849466,0.019370273,0.019386735,0.019605005,0.019775813,0.01980455,0.019699208,0.019489594,0.019227682,0.018932,0.018617952,0.018260846,0.017854393,0.017411998,0.016978705,0.016588397,0.016268738,0.01604712,0.015955338,0.015993081,0.016173642,0.016509173,0.017076392,0.017864347,0.018953362,0.020388566,0.022158327,0.024065511,0.025684146,0.026739422,0.02704699,0.026709422,0.025773179,0.024330877,0.022582881],[0.012199072,0.01296854,0.013891033,0.015034461,0.016485598,0.01833916,0.02058257,0.022898834,0.02477522,0.025864061,0.026099827,0.025564775,0.024383752,0.022715453,0.020939149,0.019790115,0.019361097,0.0194017,0.019621817,0.019795224,0.01983579,0.019721432,0.019505227,0.019240502,0.018967047,0.018658137,0.018295804,0.017878613,0.017439216,0.01700557,0.016609302,0.016286314,0.016074803,0.015977785,0.016006878,0.016169421,0.016528936,0.017066892,0.01784851,0.018926194,0.02035525,0.022116387,0.023982182,0.02565104,0.026680857,0.02702084,0.026706345,0.02579784,0.024313109,0.022622399],[0.012188642,0.01296502,0.013888104,0.015026393,0.016482726,0.018356232,0.020599198,0.022912122,0.024794493,0.025865978,0.02608924,0.02557851,0.024383325,0.022591356,0.020870361,0.0197744,0.019375317,0.019420024,0.019642955,0.019827854,0.019857366,0.019735768,0.019516893,0.019276025,0.019006964,0.018691828,0.018318074,0.017904226,0.01746449,0.01702516,0.016626082,0.016313316,0.016097093,0.015992038,0.016004631,0.016189704,0.016523767,0.017056603,0.017829854,0.01890402,0.020325553,0.022038639,0.023945322,0.025577368,0.026638703,0.027002301,0.026714886,0.02577588,0.0243503,0.022664975],[0.012190002,0.01296794,0.013887925,0.01503277,0.01651022,0.018388204,0.020632854,0.022954423,0.024814107,0.025864547,0.026100036,0.025567535,0.024252634,0.02249743,0.020828292,0.019775089,0.019390285,0.019442923,0.019677958,0.019847628,0.019866686,0.019740945,0.01954732,0.019310169,0.019033708,0.01870606,0.018335499,0.017920738,0.017475227,0.017033812,0.01664598,0.01632988,0.016107412,0.015988499,0.016023953,0.016188383,0.016520146,0.017049296,0.01782436,0.01889748,0.020276424,0.022027863,0.023884175,0.025534345,0.02660927,0.026991505,0.026674343,0.025783943,0.024368143,0.022681644],[0.012186084,0.0129600335,0.013883674,0.01504433,0.016522842,0.018401043,0.02065948,0.022968315,0.024815347,0.02588279,0.026100436,0.025466504,0.024178142,0.02245804,0.0208248,0.019787528,0.019413542,0.019481113,0.01969945,0.019857416,0.019871954,0.01977336,0.019583289,0.019338336,0.019049255,0.0187257,0.018354187,0.017933343,0.017485589,0.017055165,0.016663302,0.016340492,0.016104143,0.016006066,0.016022034,0.016183248,0.016511219,0.017041685,0.01781564,0.018848337,0.020262396,0.021960014,0.023827719,0.025489032,0.026585152,0.02694586,0.026677184,0.02580139,0.0243931,0.022760956],[0.012177395,0.012954298,0.013891457,0.015052645,0.016530683,0.018422792,0.020672955,0.02297336,0.024840554,0.025888653,0.026014544,0.025403015,0.024138732,0.022445189,0.020828199,0.019808149,0.01945499,0.019505125,0.019709922,0.019861707,0.019904219,0.01980809,0.019609353,0.019351497,0.019067576,0.018743135,0.018365309,0.017942246,0.017505689,0.017070778,0.016672201,0.016335879,0.016119447,0.016003301,0.016016,0.016174091,0.01650382,0.01703415,0.017771875,0.01883799,0.020200899,0.021903746,0.023774065,0.02545077,0.026524328,0.026933298,0.026679853,0.025815265,0.024465702,0.02284108],[0.012173641,0.01296272,0.013900954,0.015062247,0.016554108,0.018441858,0.020688174,0.023013948,0.024859421,0.02581378,0.025958473,0.02536241,0.024114182,0.022430617,0.020834848,0.01984688,0.019480117,0.019517101,0.019714523,0.019894449,0.019936861,0.019829988,0.01961754,0.019366037,0.01908145,0.018750528,0.018370548,0.01795899,0.017517323,0.017075691,0.016663913,0.0163473,0.016113993,0.015994903,0.016005332,0.016165825,0.01649648,0.016994897,0.017764697,0.01878581,0.02015278,0.021854326,0.02373194,0.025375485,0.026495244,0.02691777,0.02667501,0.025863256,0.024531897,0.022939896],[0.012177198,0.0129664615,0.013903234,0.015074626,0.01656082,0.018444804,0.020722242,0.023035308,0.024788586,0.025767468,0.02592905,0.02534802,0.024107167,0.022440229,0.020877998,0.019877298,0.01949573,0.019523885,0.019751236,0.019929469,0.01995959,0.019838473,0.019633915,0.019382361,0.019091632,0.018759308,0.018391836,0.017974745,0.017526159,0.017070841,0.016678052,0.016343912,0.016106565,0.015984258,0.015995769,0.01615592,0.01645598,0.016981987,0.017709656,0.018731434,0.020093763,0.021796413,0.023630094,0.025319455,0.026457869,0.026898598,0.026709007,0.02592192,0.024636514,0.023043072],[0.012171257,0.012957239,0.013899674,0.015061781,0.016538957,0.018448444,0.020716775,0.022939628,0.02473019,0.025738755,0.025925567,0.025361365,0.024143768,0.022514269,0.020937603,0.01991236,0.019511981,0.019567113,0.019789247,0.0199542,0.019971272,0.019861607,0.019658644,0.01940148,0.019110413,0.018792428,0.018419921,0.017996727,0.017534625,0.017098285,0.01668631,0.016346132,0.016103107,0.015978884,0.015986895,0.01611541,0.016436568,0.016920531,0.017642962,0.01865421,0.020008331,0.021652298,0.023519317,0.025228549,0.026400533,0.026909664,0.0267582,0.026028983,0.024770344,0.02318728],[0.0121630225,0.012953982,0.013888621,0.015042944,0.016543493,0.018445732,0.020619586,0.022873208,0.024692355,0.025726672,0.025930818,0.02539024,0.024213944,0.022585269,0.020992002,0.019944012,0.019568292,0.019609848,0.019811528,0.019961003,0.019992132,0.019886654,0.019679213,0.01942223,0.019146476,0.018823156,0.01844535,0.018009663,0.01756874,0.017113296,0.01669573,0.016349463,0.016103545,0.015974687,0.015951889,0.016098037,0.016380131,0.016857462,0.017569302,0.018570347,0.01986022,0.021518229,0.023382133,0.025113104,0.026360154,0.026916618,0.02682676,0.026135553,0.024916138,0.0233769],[0.012161876,0.012946572,0.013875047,0.015051031,0.016547127,0.018359346,0.020555321,0.022831425,0.02467308,0.025723115,0.025948452,0.025444934,0.024277572,0.022648793,0.021041812,0.020020185,0.019624192,0.019634033,0.01981222,0.01997586,0.020013226,0.019906094,0.019700894,0.019460388,0.019178038,0.018849375,0.018459689,0.01804803,0.017588686,0.017129637,0.016706824,0.01635773,0.01610672,0.015947971,0.015940236,0.016050206,0.016325044,0.016792819,0.017495131,0.01843457,0.01972894,0.021365004,0.023221174,0.025012488,0.02630956,0.026934177,0.026887232,0.026242957,0.02509181,0.02356346],[0.012151771,0.012930353,0.013876582,0.015047365,0.016459262,0.018284598,0.020496085,0.022791654,0.024652518,0.025729908,0.025994446,0.025505353,0.024350898,0.02272682,0.021156205,0.020106489,0.019663554,0.01963421,0.019820245,0.019990342,0.020029746,0.019930435,0.019745942,0.019498028,0.019209526,0.018868845,0.018506082,0.018076757,0.017616864,0.017154485,0.016729668,0.016375072,0.016094096,0.015947402,0.015904553,0.016005332,0.016269935,0.016727354,0.017371256,0.01830979,0.019573672,0.021177858,0.023062775,0.024886934,0.026259664,0.026940757,0.026950056,0.026380172,0.025271835,0.023756536],[0.012142222,0.0129372105,0.013880728,0.01497946,0.01640399,0.018244285,0.02046914,0.022773976,0.024654368,0.025763202,0.026033944,0.025552442,0.024407685,0.022839053,0.021261381,0.020163972,0.019671481,0.019640328,0.019824218,0.019994251,0.02004425,0.019971471,0.019781062,0.019526212,0.019223675,0.018910963,0.018529411,0.018102244,0.017642105,0.017181113,0.01675346,0.016371371,0.016102886,0.015924191,0.015873125,0.01596589,0.016222825,0.016629659,0.017275155,0.01818861,0.019417953,0.021030433,0.022912484,0.024784073,0.026205035,0.02694262,0.02701991,0.026491722,0.025417877,0.023920944],[0.012151043,0.012944405,0.013826071,0.01493702,0.016378336,0.018232707,0.02046382,0.022782596,0.024688981,0.025795564,0.02606487,0.025585553,0.024491813,0.022936191,0.021329515,0.020180885,0.019682143,0.019640174,0.019815786,0.01999531,0.020075407,0.019999724,0.019804562,0.019534582,0.019260436,0.01892574,0.018547177,0.018121485,0.017665904,0.01720552,0.01675363,0.016386317,0.016089024,0.015903793,0.015847068,0.015934777,0.016148215,0.016559482,0.0171874,0.018072952,0.019308899,0.020904526,0.022803633,0.024694316,0.02615956,0.026958799,0.027069608,0.026570158,0.025525378,0.024059122],[0.01214481,0.012882257,0.013771019,0.014893519,0.01634217,0.018194959,0.020434193,0.022784399,0.024700936,0.02581843,0.026098825,0.025671141,0.024602227,0.023040907,0.021389727,0.020220492,0.019693503,0.019628154,0.019805027,0.020017227,0.020098476,0.020024737,0.019818341,0.01957986,0.01928013,0.018948419,0.018572135,0.018153444,0.017701572,0.017219644,0.01678502,0.016390033,0.01608605,0.015894625,0.015831992,0.015878603,0.016094636,0.016490009,0.01709187,0.017981365,0.019195216,0.02079006,0.022681035,0.024596902,0.026125874,0.026966354,0.027111018,0.026644424,0.025642294,0.024191923],[0.012092337,0.01283684,0.013738919,0.014871735,0.016322177,0.01818245,0.020448545,0.022802662,0.024722906,0.02584261,0.026159177,0.025743522,0.024671547,0.02308725,0.021434601,0.020239078,0.019682983,0.01961169,0.019814717,0.020023732,0.02010754,0.020026103,0.019857414,0.019590577,0.019292329,0.01896092,0.018591229,0.018177446,0.017706431,0.01724697,0.01678851,0.016390972,0.016084248,0.015890107,0.015792252,0.015844218,0.016050648,0.016427761,0.017039753,0.017916435,0.01913303,0.020712791,0.02260469,0.024557965,0.02610924,0.026970588,0.027134677,0.026695743,0.025708064,0.024261728],[0.0120879235,0.012852452,0.013776324,0.01492872,0.016409272,0.018320555,0.020606874,0.022951027,0.024825614,0.025918156,0.026184754,0.025714405,0.024583943,0.022988854,0.021339139,0.020158509,0.019633485,0.01961,0.019809326,0.02001238,0.020078426,0.020031046,0.01982798,0.01956082,0.0192596,0.018930988,0.018562498,0.018126829,0.017680537,0.017200252,0.016746657,0.016355213,0.016055873,0.015839325,0.01575797,0.01581475,0.01601948,0.01642352,0.01704565,0.017949965,0.019179571,0.020780424,0.022710543,0.024654904,0.026169797,0.026987655,0.02712074,0.026645485,0.02562305,0.024148714],[0.012090479,0.012871604,0.01380824,0.0149807595,0.016501598,0.01843642,0.02073839,0.023072297,0.024939962,0.025982501,0.026191847,0.025662633,0.024508974,0.022892965,0.021236243,0.02008304,0.019615574,0.019594684,0.01979373,0.019981552,0.020086262,0.020002373,0.019799503,0.019529073,0.019230396,0.018902298,0.018510329,0.0181005,0.017631715,0.017157014,0.016709663,0.01632593,0.01600572,0.015805578,0.015730124,0.015786394,0.016016802,0.016431289,0.01707899,0.017995704,0.019246737,0.02089423,0.02283739,0.024765052,0.026236773,0.027010776,0.027094943,0.02657479,0.02551097,0.024009114],[0.01209095,0.012879605,0.013827727,0.015027152,0.016560664,0.01851033,0.020823764,0.023188246,0.025029387,0.026023244,0.026180934,0.025630867,0.024451403,0.02280847,0.021155473,0.02005357,0.019588254,0.019570056,0.019757863,0.019991936,0.020060342,0.019979198,0.019773794,0.019506205,0.019207804,0.018854877,0.018490512,0.018056469,0.017594026,0.017125208,0.016685039,0.016280249,0.015975418,0.015780602,0.015704097,0.015783262,0.016022338,0.01645804,0.017114094,0.018046519,0.019339945,0.021008888,0.022959601,0.024869993,0.026305947,0.027026327,0.027061695,0.026497463,0.025396412,0.023885628],[0.012084965,0.012880786,0.013847724,0.015051741,0.016591523,0.018551776,0.02091402,0.02328111,0.025090149,0.026038792,0.0261782,0.025604188,0.024394937,0.022739654,0.021122906,0.020016607,0.019553391,0.01952477,0.019766768,0.019964295,0.020038776,0.019956846,0.019755231,0.019487813,0.019162832,0.018839443,0.018448854,0.018022155,0.01756558,0.017103909,0.016642464,0.016252946,0.015953174,0.015757183,0.015701693,0.015788527,0.016045796,0.016487254,0.017154565,0.01812299,0.019436497,0.021122063,0.023079956,0.024979156,0.026366413,0.027033076,0.027021125,0.026416758,0.02529421,0.023764363],[0.012079457,0.012890206,0.013858807,0.015064651,0.016610714,0.018620426,0.02100312,0.023357699,0.025128314,0.026057057,0.026169328,0.025563812,0.024334902,0.022701647,0.021072553,0.01996751,0.019495262,0.019530362,0.019735033,0.019941347,0.020016056,0.019938556,0.019736923,0.019440854,0.019147493,0.01879522,0.018412612,0.017991485,0.017542023,0.017058697,0.016613485,0.016229441,0.0159293,0.01575395,0.015706487,0.01581041,0.016072975,0.016523955,0.017223261,0.018209822,0.019541338,0.021246525,0.023219507,0.02508947,0.026421556,0.027031505,0.02697257,0.02633821,0.025182601,0.023621568],[0.01208071,0.012891485,0.013858999,0.015066795,0.016654866,0.018688941,0.02107558,0.023408828,0.025167113,0.026067527,0.026147535,0.025520481,0.024303298,0.022647806,0.021010833,0.01989347,0.019494552,0.019491911,0.019709982,0.019918408,0.019998696,0.019921055,0.01968857,0.019426668,0.019101636,0.018758152,0.018380778,0.017966453,0.017494226,0.017028034,0.016588131,0.016204096,0.015924316,0.015757104,0.01572573,0.01583447,0.016105002,0.016584134,0.017298602,0.018300181,0.019652708,0.021387707,0.023359738,0.02519402,0.026468359,0.027023552,0.026927905,0.026254788,0.025055388,0.023490738],[0.012069834,0.012877111,0.013842415,0.015081801,0.01668717,0.01872559,0.02110328,0.023444105,0.025187204,0.026062662,0.02612708,0.025511576,0.024273155,0.022600992,0.02093713,0.019891502,0.019448869,0.019462174,0.019685455,0.019902656,0.019984664,0.019875314,0.019680345,0.019383995,0.019069029,0.018730937,0.018360432,0.017922169,0.017468134,0.017006494,0.016566094,0.016201498,0.01592879,0.015775762,0.015747573,0.015861684,0.016155578,0.016645327,0.01736881,0.018385202,0.019766254,0.02151431,0.023478799,0.025277408,0.026502281,0.027019713,0.02688614,0.026171112,0.024955522,0.02338896],[0.012056743,0.012862254,0.013855243,0.015110585,0.016721116,0.018755326,0.021150526,0.023484329,0.025200607,0.026054721,0.026121907,0.025480928,0.024220359,0.022512829,0.020918962,0.01983045,0.019410646,0.019434154,0.019669838,0.019889057,0.0199366,0.019866772,0.019633457,0.019348059,0.019038368,0.018706767,0.018310433,0.017891282,0.017440952,0.016978677,0.0165581,0.016200854,0.01594248,0.015793147,0.015770413,0.0159065,0.016210338,0.016707707,0.017444052,0.018487697,0.019887382,0.021645166,0.023598539,0.025359832,0.026541688,0.027011503,0.026830947,0.026091354,0.024857044,0.023263238],[0.012044719,0.012874474,0.013881895,0.015141924,0.016749788,0.018806785,0.021208338,0.023523416,0.025215605,0.026063804,0.02609895,0.025430754,0.024128063,0.022474376,0.020832594,0.019773412,0.019372351,0.019416204,0.019658148,0.019841075,0.0199303,0.019817049,0.019594485,0.019314004,0.019010684,0.018651335,0.018275151,0.017858436,0.017406587,0.016964007,0.016550316,0.016207406,0.015953086,0.01580948,0.015807858,0.015953617,0.016264223,0.01677284,0.017533993,0.018596552,0.020012796,0.021778816,0.023720615,0.025450971,0.02657822,0.026991712,0.026778748,0.026011366,0.024734562,0.023134118],[0.012055708,0.012897885,0.013908398,0.015164623,0.01679347,0.018864164,0.021262165,0.023564473,0.025251348,0.026061693,0.026066134,0.025355024,0.024088696,0.022374751,0.020753067,0.019717576,0.019346558,0.019404579,0.019612739,0.019842431,0.019884007,0.019780733,0.019561496,0.019286864,0.018953947,0.018616501,0.018241756,0.01782245,0.017389754,0.016952544,0.016552353,0.016212918,0.015964001,0.015840424,0.015847843,0.015999282,0.016319277,0.016849494,0.017627042,0.018705552,0.020136837,0.021911787,0.023850936,0.02553947,0.026605459,0.026978632,0.026731767,0.025917657,0.024615545,0.022918282],[0.012058277,0.012898695,0.013898672,0.015163357,0.016794411,0.018857878,0.02125481,0.023577617,0.025249427,0.02604878,0.026030606,0.025361955,0.024045821,0.022336867,0.02071679,0.019697808,0.019335056,0.019355405,0.019619709,0.019802758,0.019859701,0.019761674,0.019548729,0.01924266,0.018934581,0.018599035,0.018222118,0.017822748,0.017394044,0.016968623,0.016569097,0.016231926,0.015998911,0.015880119,0.015888294,0.016043095,0.016376663,0.016914288,0.017697282,0.018780954,0.02021825,0.022004817,0.023931628,0.025584187,0.026625663,0.026976286,0.026696557,0.025865264,0.024467964,0.022790153],[0.012051093,0.012880665,0.013885318,0.015148594,0.016768597,0.01882678,0.021245912,0.023560107,0.025229942,0.026016977,0.026043713,0.025338396,0.024029894,0.022319332,0.020708544,0.01969162,0.019282231,0.019364102,0.019578654,0.019781243,0.019845465,0.01975456,0.0195079,0.01922929,0.018922975,0.018585283,0.018229425,0.017833428,0.01741625,0.016990282,0.016591815,0.016268713,0.016038433,0.015918091,0.015926791,0.016091172,0.016428037,0.016966177,0.017748915,0.018834025,0.020283042,0.022067545,0.023974048,0.025615554,0.02664143,0.026965825,0.026675265,0.025765866,0.024375243,0.022757528],[0.012037021,0.012871117,0.013875724,0.015130601,0.016746664,0.018826136,0.02123471,0.023542479,0.025196347,0.026024675,0.026016794,0.025317416,0.024006803,0.022305677,0.020699518,0.019632744,0.019293038,0.019320717,0.019558117,0.019768327,0.01983914,0.019711124,0.019493952,0.019216422,0.018907469,0.018591719,0.018238284,0.017853597,0.017434977,0.017009743,0.01662507,0.016304288,0.01607219,0.015951948,0.015969161,0.016136091,0.01647258,0.017009597,0.017793208,0.018890467,0.02034226,0.022114849,0.024019297,0.025648013,0.026645008,0.026956422,0.026597962,0.025691003,0.024343219,0.022716228],[0.012035386,0.012871182,0.013871025,0.015125974,0.01676625,0.01884075,0.021242639,0.023526078,0.025213066,0.025997555,0.025987921,0.025279833,0.023971463,0.022272894,0.020618021,0.01963507,0.019242225,0.019300265,0.019547727,0.019763567,0.019792251,0.019693946,0.019475777,0.019194592,0.018908648,0.018594213,0.018251594,0.017864069,0.01744545,0.017033802,0.016651258,0.016329141,0.016097866,0.015986582,0.01600719,0.016174695,0.016511228,0.017050618,0.017848141,0.018952854,0.020400718,0.022181893,0.02408155,0.025677446,0.026652154,0.02689347,0.026531434,0.025652084,0.024284763,0.022671683],[0.012031988,0.012862758,0.013861169,0.01513559,0.016769962,0.018837688,0.02121701,0.023542255,0.025188623,0.025976796,0.025963396,0.025259834,0.023953239,0.022200355,0.020623928,0.019580433,0.019220978,0.019292485,0.019548872,0.019720836,0.019782353,0.019681646,0.019458449,0.019201651,0.018916585,0.018613396,0.018267179,0.017879078,0.01747341,0.017062357,0.016677216,0.016354699,0.016130842,0.016021507,0.016041113,0.016206898,0.01654369,0.017093906,0.017896652,0.01899687,0.02045603,0.022242922,0.02412143,0.025701987,0.026609307,0.02685116,0.026513843,0.02561703,0.024254834,0.022543693],[0.012024234,0.012853621,0.0138688125,0.015138016,0.016765557,0.018810546,0.021233628,0.023517292,0.025169378,0.025955925,0.025948394,0.025247537,0.02389148,0.02220827,0.020565404,0.01955677,0.019213533,0.019297373,0.019508291,0.019717114,0.019775124,0.019667493,0.019469295,0.019212464,0.018939156,0.018631756,0.018284688,0.017909348,0.017502971,0.017088303,0.016701907,0.016385866,0.016163083,0.016051915,0.016068958,0.016233994,0.01657981,0.017134,0.017931754,0.01904293,0.020511866,0.02228579,0.024157736,0.025670346,0.026580825,0.026845787,0.02649367,0.025600731,0.024144256,0.022442935],[0.012020112,0.01286479,0.013876778,0.015141229,0.016749594,0.018838735,0.021220965,0.023507321,0.025153557,0.025942441,0.025934566,0.02518924,0.02389083,0.022139661,0.02053011,0.019543406,0.01921874,0.019256044,0.019510187,0.019714454,0.019763228,0.019679958,0.019479547,0.019234596,0.018956447,0.0186481,0.018313866,0.017936576,0.01752561,0.017108992,0.01672859,0.01641329,0.016188622,0.016074985,0.016091388,0.016264994,0.016614862,0.01716482,0.017973619,0.019096844,0.020558527,0.022333957,0.024137927,0.025653785,0.02658472,0.026833052,0.026482586,0.02550772,0.02404837,0.02235775],[0.01202953,0.012871429,0.013878722,0.015125682,0.016774265,0.01882661,0.021211833,0.023492532,0.025141362,0.025930058,0.025884368,0.025189046,0.023828117,0.02210041,0.020509304,0.019545173,0.01917112,0.019259997,0.019511474,0.019706078,0.019779673,0.019691464,0.019502271,0.019251648,0.018972881,0.01867821,0.018341308,0.017958697,0.017544992,0.01713356,0.016752927,0.016435016,0.016207295,0.016092429,0.01611625,0.016293017,0.016638095,0.017197257,0.018016899,0.019133851,0.02060011,0.022310317,0.024121122,0.025662044,0.026577145,0.026828382,0.026411172,0.025434291,0.023974886,0.022355659],[0.012024392,0.012859599,0.013847823,0.015124793,0.016734142,0.01878165,0.021159165,0.02345013,0.025113493,0.025882568,0.025896205,0.02515954,0.023825776,0.022112299,0.020534512,0.019504374,0.019180058,0.019264001,0.019506661,0.019730167,0.019799352,0.019723501,0.019528246,0.019277578,0.019014105,0.018716985,0.018375143,0.017989952,0.01758109,0.01716805,0.016782956,0.016459728,0.01622814,0.016117325,0.016140837,0.016309308,0.01665838,0.017222594,0.018030569,0.019145645,0.020542353,0.022255294,0.024098415,0.025634635,0.026568027,0.026775347,0.026373401,0.025408251,0.024015272,0.022368206],[0.012017533,0.0128372265,0.013853004,0.015098237,0.016703831,0.018741608,0.02112084,0.023417521,0.025056034,0.025883097,0.025861239,0.02515033,0.023832066,0.022137385,0.020494003,0.019518536,0.019188907,0.01926269,0.01953561,0.019751929,0.019832304,0.019748608,0.019553179,0.019318996,0.019052612,0.018750386,0.018406024,0.01802589,0.01761518,0.0171976,0.016807169,0.016480036,0.016252123,0.016140735,0.01615606,0.016327754,0.016681278,0.017234467,0.018040301,0.019088821,0.020484071,0.022225194,0.024056016,0.025608212,0.026501745,0.026732573,0.026348991,0.025447346,0.024038235,0.02238639],[0.012002952,0.012847477,0.013838071,0.015081945,0.016681248,0.01872009,0.021098912,0.023358246,0.025051327,0.025841434,0.025843102,0.025145395,0.02384573,0.02209098,0.020506997,0.019529905,0.019190777,0.019298133,0.019560834,0.019786388,0.019855767,0.019770864,0.01959294,0.019355383,0.01908374,0.01877915,0.018440163,0.018057933,0.017642656,0.01721989,0.016825818,0.016502457,0.016274063,0.016154904,0.016173176,0.016349157,0.016692631,0.017243875,0.017988218,0.019034369,0.020456664,0.022179913,0.024017131,0.025519373,0.026440231,0.026695203,0.026372459,0.0254654,0.024062295,0.022434205],[0.012022078,0.012847378,0.013839684,0.015083159,0.016689714,0.018733159,0.021069713,0.023375472,0.025016114,0.025819594,0.025824666,0.025135964,0.023777647,0.02207759,0.020500597,0.019524416,0.019230379,0.019328855,0.019599691,0.019809136,0.019873703,0.019805256,0.01962252,0.019379329,0.019105451,0.018806463,0.01846484,0.018077675,0.017657168,0.017231163,0.016841585,0.016518636,0.016283823,0.016168617,0.016192323,0.016360497,0.016703796,0.017200671,0.017945321,0.019022036,0.02043032,0.022155523,0.02392436,0.025442144,0.026383188,0.026693622,0.026367353,0.025469415,0.024095923,0.022472236],[0.01200403,0.012826459,0.01381245,0.0150536,0.016653396,0.01864484,0.02102523,0.023287656,0.02496722,0.025800405,0.02583658,0.025118276,0.023821613,0.022129202,0.020538472,0.019593105,0.019275384,0.019374788,0.019625338,0.019831643,0.019917382,0.01984697,0.019660678,0.019416794,0.019150257,0.018849814,0.018504597,0.018113282,0.017689893,0.017267624,0.016876174,0.016543586,0.016308364,0.016193457,0.016204322,0.016365895,0.01665207,0.017140903,0.017906066,0.018960321,0.020357853,0.021997267,0.023770606,0.02531936,0.026343396,0.02668072,0.026392091,0.025547741,0.024205452,0.022597408],[0.012001143,0.012821906,0.013811784,0.015055416,0.016616784,0.01865293,0.020979023,0.023258975,0.024948036,0.025795497,0.025794407,0.025120663,0.023828926,0.022134168,0.020595314,0.01964012,0.01933031,0.019405399,0.019646619,0.019870019,0.019949306,0.019873811,0.019687144,0.019451281,0.019182676,0.01887807,0.018528499,0.018134676,0.017716158,0.017293349,0.016894057,0.016562954,0.016329825,0.01620456,0.016211098,0.016322266,0.01660405,0.017117528,0.017868966,0.018918527,0.020231364,0.02185608,0.023629561,0.025241097,0.026283644,0.026657613,0.026418708,0.025609147,0.024303349,0.02273311],[0.011997475,0.012821714,0.013813995,0.01502394,0.016625473,0.01860974,0.020947997,0.023234075,0.024937047,0.025750587,0.025792563,0.02512503,0.023834215,0.022194874,0.020653136,0.01970893,0.019370146,0.019430283,0.019685505,0.019899214,0.01997272,0.019898336,0.019721806,0.019484287,0.019211609,0.018902967,0.018551564,0.01816366,0.017745262,0.017315121,0.016917586,0.016588122,0.016344152,0.016213566,0.016171863,0.016277747,0.016582573,0.017084103,0.017830614,0.018798226,0.020087061,0.021692494,0.023506666,0.025123613,0.026209608,0.026644293,0.0264501,0.025689092,0.024445182,0.022920031],[0.011998241,0.012824774,0.013788115,0.015033641,0.016589517,0.018582447,0.02092298,0.02321963,0.02488556,0.025743032,0.025791526,0.025126858,0.023889463,0.02225806,0.020737618,0.019763742,0.019405015,0.019474724,0.019713258,0.019918293,0.019993285,0.019931784,0.019755164,0.019514032,0.01923735,0.018927217,0.018582687,0.018195698,0.017770935,0.017343733,0.016948216,0.016607875,0.016358025,0.016180867,0.016133204,0.016260585,0.016554875,0.017051406,0.017721532,0.018662926,0.019924946,0.021551022,0.023340264,0.024983486,0.026135769,0.026626816,0.026489956,0.025799388,0.02462811,0.02312232],[0.011999142,0.012800275,0.013793607,0.014998791,0.016559767,0.018551847,0.020898985,0.023152782,0.024867814,0.02573662,0.025793334,0.0251799,0.02395877,0.022362627,0.020820918,0.01982155,0.019466005,0.019508187,0.019730065,0.019935055,0.020025373,0.019967021,0.019789374,0.019545075,0.019266998,0.018964352,0.018621348,0.018229093,0.017809112,0.017385127,0.016979173,0.016632672,0.016336944,0.016152749,0.01612434,0.016241226,0.016529245,0.016954111,0.017597347,0.018510886,0.019783607,0.021361453,0.023140451,0.024831101,0.026046768,0.026610743,0.026553662,0.025945336,0.024829185,0.023300119],[0.01197761,0.012804376,0.0137634175,0.0149725145,0.016532443,0.018527918,0.020822883,0.023121156,0.024848102,0.025729118,0.025835097,0.025239687,0.024060689,0.022464583,0.020908957,0.019910019,0.019515628,0.019528756,0.019741645,0.019960824,0.020055834,0.020000517,0.019823175,0.019578611,0.019308154,0.019006645,0.018658727,0.018273136,0.017858414,0.01742578,0.017015142,0.016624078,0.016321491,0.016155224,0.01611658,0.01622644,0.01644773,0.016846787,0.017465195,0.018387957,0.019606816,0.021146841,0.022931416,0.024657115,0.025948044,0.026604414,0.026635548,0.026093174,0.024994908,0.023520716],[0.011998886,0.012800361,0.013768429,0.014985959,0.016560333,0.018513514,0.020847708,0.023140628,0.024855869,0.025761526,0.025862474,0.025286943,0.024103587,0.022509662,0.020980658,0.019957758,0.019538634,0.019539995,0.019760912,0.019979283,0.020074503,0.020019954,0.019843841,0.019607365,0.019336384,0.01902804,0.018686412,0.018306501,0.017884625,0.017450484,0.016998986,0.016605541,0.016324216,0.01615224,0.016110726,0.01616327,0.016365837,0.016750438,0.01738743,0.018270679,0.019455692,0.020984748,0.022762751,0.024519885,0.025880404,0.026611187,0.026693696,0.026165573,0.025130806,0.023674726],[0.011977108,0.012781887,0.013751233,0.014972421,0.016496547,0.0184748,0.020803843,0.023099791,0.024866724,0.02579057,0.025927525,0.025364552,0.024200244,0.022646112,0.021090828,0.020020029,0.019566821,0.019562073,0.019773426,0.019993402,0.020095725,0.020050723,0.019889327,0.019654099,0.019375687,0.019074246,0.018739488,0.018354036,0.017933192,0.017459383,0.017006885,0.016633252,0.01634372,0.016165048,0.016065512,0.016095677,0.016281221,0.016678862,0.017275147,0.018118395,0.019278208,0.020773716,0.022545882,0.024353718,0.02580269,0.026610462,0.026733095,0.026284315,0.025299367,0.023868915],[0.011979397,0.012789885,0.013769371,0.014956075,0.016513614,0.018496275,0.02082326,0.023154225,0.024912346,0.025842905,0.025965527,0.025398852,0.024262084,0.022700917,0.02112597,0.020037197,0.019586163,0.01957055,0.019775625,0.01999709,0.020106304,0.020077212,0.019918498,0.019675178,0.01940228,0.019105429,0.018763138,0.01837908,0.017919697,0.01745002,0.017022286,0.016645387,0.016354186,0.016125293,0.016009824,0.016031215,0.016237069,0.016607894,0.017178457,0.018010471,0.019146465,0.020626388,0.022412619,0.024263198,0.025756018,0.026583735,0.02676375,0.02634624,0.025386298,0.02403913],[0.0119811045,0.0127992015,0.013746878,0.014960004,0.016519906,0.018499853,0.0208678,0.023199882,0.024970634,0.025885856,0.026001837,0.025455516,0.024313994,0.022741873,0.021153038,0.020062998,0.019595087,0.019567557,0.019768769,0.019996872,0.020125022,0.020102408,0.019938597,0.019702416,0.019433225,0.019126968,0.018785888,0.018362762,0.017910874,0.017468845,0.017039703,0.016662842,0.016324088,0.016080795,0.015958536,0.01600042,0.01618396,0.016532924,0.017095681,0.017908067,0.01902762,0.020509781,0.022315703,0.024186818,0.025688369,0.02657311,0.026782503,0.026388103,0.02550631,0.024188895],[0.011984124,0.012773882,0.0137428455,0.014956979,0.016512234,0.018530775,0.020906223,0.023261117,0.025019811,0.025926225,0.026054896,0.025499783,0.02434899,0.022770403,0.021185976,0.020075843,0.019590573,0.019554516,0.019757662,0.020004842,0.020140907,0.020116221,0.019963738,0.019732462,0.019452041,0.019145828,0.01876348,0.018350154,0.017928394,0.017486772,0.017060282,0.016638597,0.01628793,0.01604014,0.015939035,0.015962584,0.016127797,0.016472299,0.01702069,0.017820973,0.018943017,0.020437406,0.02224569,0.024101382,0.025649965,0.026559813,0.026788494,0.02645781,0.025604675,0.024303718],[0.011956055,0.012763018,0.013732122,0.014940155,0.016527819,0.018553915,0.020958794,0.02331132,0.025065785,0.025982019,0.026097106,0.025529867,0.024372978,0.022804273,0.021205068,0.02007376,0.01957464,0.019537065,0.019756073,0.020010004,0.02014476,0.0201354,0.019991392,0.01974918,0.019468118,0.01911726,0.018745964,0.018364146,0.017943496,0.017506976,0.017037932,0.016607556,0.016254883,0.016029287,0.015913088,0.015921168,0.016084444,0.016418833,0.016959464,0.017765416,0.018900763,0.020393532,0.022170816,0.024057422,0.02562064,0.026544688,0.026826397,0.026514815,0.025675986,0.024384357],[0.0119640445,0.012775729,0.013746011,0.014992067,0.016600287,0.018670553,0.02108616,0.023428505,0.025165068,0.026030814,0.026101604,0.025500458,0.024330687,0.022743579,0.02113883,0.020016957,0.019536108,0.019527113,0.019753952,0.02000178,0.020147186,0.020142457,0.019984871,0.019741248,0.019411623,0.01907184,0.018731128,0.01834808,0.017932741,0.017454755,0.016981876,0.016554993,0.016230166,0.015997065,0.01587337,0.015887635,0.016050937,0.016388875,0.016947461,0.01778081,0.018930634,0.02040431,0.022212146,0.024096245,0.025641464,0.02658151,0.026845464,0.026516287,0.02566221,0.02434018],[0.011959018,0.012768161,0.013765775,0.015022277,0.016662862,0.018746722,0.021176036,0.02353351,0.025235696,0.026062587,0.02610323,0.025489448,0.024298478,0.02269329,0.02108153,0.019968996,0.019516997,0.019517625,0.01974017,0.020002337,0.020155055,0.020138068,0.019980855,0.019686537,0.01937008,0.019062111,0.018718876,0.018341199,0.017883256,0.017402943,0.01693409,0.016535101,0.016203018,0.015962694,0.0158448,0.015859244,0.016025726,0.016379926,0.016963156,0.017808659,0.01893829,0.020441685,0.022255465,0.024133073,0.025702868,0.026621306,0.026861833,0.026512608,0.025626207,0.024306629],[0.011948036,0.012779982,0.013785572,0.015068493,0.016721234,0.01882551,0.021291632,0.023632493,0.025295673,0.026084343,0.026103172,0.025461137,0.024243591,0.022619294,0.02100928,0.019930003,0.019495005,0.019495966,0.01973699,0.020007217,0.02014617,0.020129351,0.01991862,0.019639682,0.019356476,0.01904401,0.018705374,0.018282862,0.017823786,0.017348146,0.016908357,0.016503215,0.016165849,0.015933037,0.0158176,0.015837342,0.016021388,0.016401,0.016998034,0.01782693,0.01898728,0.020503784,0.022322237,0.024238052,0.02578282,0.026662646,0.026867658,0.026475614,0.025576508,0.02424155],[0.01195747,0.012796394,0.013824252,0.015117354,0.016790288,0.018942058,0.021416392,0.023733098,0.025352618,0.026105952,0.026085272,0.0254073,0.024157975,0.022517882,0.020934163,0.019880682,0.019456914,0.019486224,0.019740582,0.019996364,0.020134235,0.020059472,0.01986512,0.019620622,0.019330991,0.019022431,0.01863616,0.018213121,0.017758427,0.017312266,0.016866222,0.016457243,0.016129097,0.015901025,0.015793197,0.015832132,0.016042672,0.016437827,0.017021885,0.0178818,0.019060332,0.020591868,0.022469692,0.024377929,0.025878686,0.026703365,0.026848271,0.026425993,0.025494317,0.024134398],[0.011953617,0.012807404,0.013837164,0.015138019,0.016845476,0.019010007,0.02148624,0.023790175,0.025392964,0.026116388,0.026068872,0.025366563,0.024098907,0.02246625,0.020888755,0.019836305,0.01944076,0.01948585,0.019728405,0.019987065,0.020067265,0.020013817,0.01985675,0.019604353,0.019318638,0.01896024,0.018575221,0.018157037,0.017732326,0.017278258,0.016827453,0.016426407,0.016101578,0.015879475,0.0157883,0.015850177,0.016072515,0.016451722,0.017058972,0.01793061,0.019119175,0.020714646,0.022610415,0.02450465,0.025963197,0.026727354,0.026839318,0.02638272,0.025420465,0.024021734],[0.011957774,0.012812077,0.013846301,0.015174938,0.016893612,0.019066766,0.021547167,0.02384904,0.02542319,0.026116835,0.026043521,0.025320731,0.024051568,0.022413371,0.020828905,0.019807432,0.01943371,0.019469513,0.019718405,0.01991725,0.020022677,0.020008633,0.019841174,0.01959195,0.019253219,0.018897656,0.018517816,0.018130247,0.017696042,0.017236944,0.01679397,0.01639618,0.016077504,0.015871823,0.015802773,0.015875837,0.016082915,0.016482346,0.01709981,0.01797987,0.019231267,0.020857148,0.022764046,0.024638304,0.026036613,0.026756616,0.026823435,0.026327543,0.025317013,0.023896543],[0.011950332,0.012805792,0.013859936,0.0151929045,0.01691399,0.019093394,0.021588285,0.023879807,0.025434572,0.026109047,0.026021397,0.025299085,0.024022698,0.022367729,0.020802619,0.019798946,0.019413512,0.01945678,0.019643696,0.019874565,0.020024657,0.01999964,0.019835113,0.019529346,0.019195316,0.01884589,0.018498054,0.018099662,0.017660227,0.017208567,0.016767822,0.01637517,0.016071467,0.015885828,0.01582589,0.015882652,0.016105631,0.016511766,0.017133124,0.018067839,0.019348461,0.020995634,0.022909494,0.02474886,0.026110943,0.02678155,0.026805533,0.026261218,0.025220549,0.02376501],[0.01194408,0.012816626,0.013874439,0.015208955,0.016936412,0.019135613,0.021630822,0.023907928,0.025440667,0.026096512,0.026004301,0.02527085,0.023973633,0.022329474,0.020780748,0.019768279,0.019395359,0.019373355,0.019599827,0.019880233,0.020017555,0.019993978,0.019768154,0.019468289,0.019141084,0.018825023,0.018464567,0.018060563,0.01762837,0.017178267,0.016742418,0.016364576,0.01608052,0.01590381,0.015828542,0.015899882,0.016129322,0.016538776,0.01721033,0.018173566,0.019478565,0.02114726,0.023052143,0.024875473,0.026185283,0.026800599,0.02676795,0.02618524,0.025097849,0.02362393],[0.011950773,0.012825985,0.013883758,0.015222231,0.016967937,0.019173693,0.021665726,0.023927439,0.025441095,0.026089452,0.025984041,0.025229571,0.023936098,0.02229992,0.020738123,0.019740617,0.019298086,0.01932344,0.019608429,0.019876286,0.02001482,0.019925332,0.01970605,0.01941317,0.019120967,0.018790547,0.01842428,0.018027488,0.017595973,0.017150048,0.016728334,0.016369266,0.016093405,0.01590165,0.015839607,0.015916847,0.016148748,0.016603611,0.017300941,0.018286023,0.019615015,0.021290293,0.023209054,0.025001507,0.026254179,0.026803328,0.026725285,0.02609161,0.024971526,0.023498334],[0.011945597,0.012817592,0.013873819,0.015221698,0.016966991,0.019168789,0.021655116,0.023913264,0.025434121,0.026080407,0.025965303,0.025220755,0.023937002,0.022283278,0.020724915,0.019639654,0.019241754,0.019331366,0.019605642,0.019877985,0.019949391,0.01987025,0.019659221,0.019403191,0.01909477,0.018758778,0.018400576,0.018004335,0.01757667,0.017144041,0.016739389,0.016386256,0.016093547,0.015912019,0.015853189,0.015929801,0.016200177,0.016674744,0.017386112,0.018387139,0.019720206,0.021421755,0.023340676,0.025102926,0.026297882,0.026803816,0.02667985,0.026015969,0.024886288,0.023402015],[0.01193634,0.012806751,0.013870864,0.015218168,0.016959378,0.019155389,0.021638295,0.02390537,0.025424497,0.026061954,0.025955865,0.025219636,0.023921171,0.022270689,0.020617617,0.019574994,0.019248188,0.019327758,0.019608444,0.019809706,0.019894525,0.019824676,0.019651765,0.019376718,0.019062297,0.018734915,0.018376881,0.017984273,0.017569678,0.017153457,0.01675377,0.016383357,0.01610023,0.01592152,0.015861725,0.015973637,0.016261727,0.016747335,0.017470874,0.018473718,0.019834744,0.021552095,0.02346655,0.025185844,0.02633659,0.026791997,0.026635278,0.025955938,0.024804104,0.023328716],[0.0119277965,0.012805443,0.013869867,0.015214447,0.016951444,0.019144922,0.021637395,0.023900952,0.025407627,0.02605066,0.02594872,0.025197882,0.023900796,0.02215591,0.020539006,0.019574452,0.019240767,0.019330362,0.019535802,0.01975407,0.019849528,0.019818729,0.019622909,0.019340735,0.019035496,0.018707976,0.0183534,0.017973674,0.017574828,0.017162483,0.016744839,0.016383987,0.016103731,0.015924415,0.015898142,0.01602698,0.016324634,0.016820177,0.017543867,0.01857262,0.019954668,0.02168495,0.02357991,0.025266903,0.02636245,0.026778158,0.026599493,0.025892694,0.0247351,0.023274153],[0.011925889,0.012803854,0.013865745,0.015206453,0.016941287,0.01914553,0.02163697,0.023887506,0.025398748,0.026043233,0.025926685,0.025175683,0.023792114,0.02206996,0.020528015,0.019559428,0.019240843,0.019250032,0.019478701,0.019710813,0.019847821,0.019790083,0.019584987,0.019311996,0.01900638,0.018682538,0.018341064,0.017976623,0.017580366,0.017148713,0.016740369,0.01638188,0.016100988,0.015953707,0.015943486,0.016080491,0.016385978,0.016879776,0.017625488,0.01867408,0.02007446,0.021802634,0.02368946,0.025332186,0.02638503,0.02677227,0.026562436,0.025843138,0.024685983,0.023228146],[0.011917874,0.01279223,0.013848572,0.015184366,0.016925871,0.019127952,0.021607706,0.023869023,0.02538796,0.026023492,0.025911227,0.025090985,0.023724854,0.022066364,0.020515123,0.01956073,0.019151516,0.01918755,0.019435732,0.019715212,0.019823635,0.019755576,0.019559342,0.01928526,0.018983668,0.018673783,0.018347828,0.017985146,0.01756815,0.01714542,0.016738111,0.016377958,0.016127106,0.015993983,0.01598965,0.01613152,0.016432302,0.016942672,0.017703133,0.018766375,0.02016769,0.021903083,0.023768332,0.025382917,0.026410118,0.026766092,0.026543166,0.025820993,0.024659093,0.023203675],[0.01190648,0.012776068,0.013828312,0.015170347,0.016910272,0.019099582,0.021587975,0.023856152,0.025364852,0.02600442,0.025833512,0.025028856,0.023716515,0.022048369,0.020512905,0.019460687,0.019081088,0.01914152,0.019444935,0.019693881,0.019790854,0.019730648,0.019531325,0.019260744,0.018973824,0.018679786,0.01835481,0.017969998,0.017561985,0.017139208,0.016729597,0.016398687,0.016161062,0.016032903,0.016032195,0.016168442,0.016483001,0.017005559,0.01777808,0.018842055,0.020255443,0.021983776,0.023838915,0.025436841,0.026430123,0.026768021,0.026536772,0.025805114,0.02463794,0.02321556],[0.01189373,0.012760395,0.013819147,0.015161502,0.016891057,0.019088808,0.021583462,0.023837114,0.025346382,0.025929356,0.025773235,0.025012493,0.023690125,0.022036511,0.02039888,0.019378131,0.019028476,0.019154636,0.019427767,0.019664941,0.019768974,0.0197027,0.019504772,0.01924876,0.01897808,0.018684423,0.01833598,0.017960424,0.017551139,0.017125146,0.016744269,0.016425645,0.01619245,0.016067378,0.01606094,0.016209463,0.01653493,0.017067969,0.017840689,0.018917356,0.020330591,0.022063402,0.023919359,0.025488287,0.026457977,0.026778903,0.026531078,0.025787551,0.024641259,0.023204066],[0.011882162,0.012755113,0.013815348,0.015149982,0.01688902,0.01909579,0.021576291,0.023828011,0.025274727,0.025872173,0.025752608,0.024981383,0.02366988,0.021912698,0.020299114,0.019312423,0.019041553,0.019139457,0.019404002,0.01964904,0.019744644,0.019676736,0.019491555,0.019251375,0.01898057,0.018662402,0.018324075,0.017946225,0.017532628,0.017134761,0.016764656,0.016449591,0.01621889,0.016088014,0.016092822,0.01625138,0.016586116,0.017118713,0.017903002,0.01898158,0.020406347,0.022156378,0.024000159,0.02555035,0.026495695,0.02679026,0.026522432,0.025787326,0.024620004,0.023170559],[0.011877965,0.01275248,0.013806249,0.015149644,0.016898766,0.019094842,0.021576254,0.023758598,0.025220435,0.025851943,0.025722345,0.024960345,0.023554085,0.021805415,0.020216992,0.019319445,0.019023366,0.019116977,0.019394472,0.019630888,0.019723257,0.019665772,0.019494409,0.019252738,0.018956391,0.018650092,0.018309219,0.017926408,0.017540611,0.017151473,0.016783329,0.016469495,0.016232248,0.016111327,0.01612495,0.016291222,0.01662428,0.01716609,0.01795129,0.019041762,0.020490676,0.022245118,0.024089053,0.025621433,0.026533937,0.026799895,0.026529277,0.0257677,0.02458086,0.02314418],[0.01186987,0.012737567,0.013796921,0.0151468655,0.016883729,0.019080013,0.021488292,0.023689818,0.02519449,0.025823276,0.025708746,0.024872892,0.023472149,0.021733748,0.020227203,0.019300675,0.01899975,0.019109944,0.01938181,0.01961658,0.01972004,0.01967521,0.0195002,0.019231183,0.018948967,0.018640794,0.018295366,0.017941182,0.01756244,0.017173368,0.016804338,0.016481897,0.016252158,0.016137453,0.01615581,0.016317518,0.016655523,0.0171943,0.017986476,0.019097744,0.020554833,0.022324326,0.024172101,0.025683334,0.026567766,0.02682616,0.026527775,0.02574523,0.02456328,0.02312891],[0.011855548,0.012727826,0.01379279,0.015131602,0.016867828,0.01898834,0.02140697,0.023652196,0.025156332,0.02580439,0.025632147,0.024806669,0.023413908,0.021749323,0.020210637,0.01927782,0.018995127,0.019100472,0.019372806,0.019619878,0.019735534,0.019684605,0.019479377,0.019226173,0.018942632,0.018630596,0.01831548,0.017967466,0.017587688,0.017196314,0.016817074,0.016500449,0.016274985,0.01616288,0.016174778,0.016338585,0.01667115,0.017213384,0.018022345,0.019140288,0.02061567,0.02240274,0.024246989,0.025738534,0.02661337,0.026839854,0.026517952,0.025733748,0.024548182,0.023098502],[0.011850919,0.0127291195,0.013785985,0.015126191,0.016793922,0.018918395,0.021374479,0.023610555,0.025130546,0.025724748,0.025565648,0.024748227,0.023420498,0.021726694,0.02018289,0.019273303,0.018987706,0.019095413,0.019381898,0.019640302,0.019746676,0.0196616,0.019472875,0.019218203,0.018931257,0.018651629,0.018342108,0.017992409,0.017609514,0.017206885,0.01683269,0.0165193,0.016295414,0.016176175,0.016188942,0.01634667,0.016681306,0.017238256,0.01805307,0.019189188,0.020687604,0.022484647,0.024323571,0.02581012,0.026645657,0.026841054,0.026508419,0.02571238,0.024505714,0.023059197],[0.011847077,0.012717259,0.013773473,0.015050603,0.016716054,0.018871142,0.02131191,0.023564143,0.025035124,0.02565532,0.025514485,0.02476108,0.02341498,0.021717334,0.020193381,0.019275723,0.018988581,0.019109895,0.019407658,0.019655129,0.019725138,0.019658608,0.019468611,0.019210977,0.018959176,0.018685171,0.018374085,0.018021261,0.01762651,0.017228346,0.016855871,0.016542152,0.016309146,0.016188217,0.01619262,0.01634928,0.01669438,0.017253177,0.018080756,0.019235866,0.020746168,0.02254993,0.024403945,0.025860414,0.026665678,0.026847826,0.026500951,0.025683062,0.024473503,0.02302879],[0.011831835,0.01270044,0.0137009695,0.014973736,0.01666465,0.018797955,0.02124338,0.023435155,0.024940964,0.025591703,0.02551811,0.024760064,0.023421777,0.021751286,0.020219449,0.019293664,0.019014876,0.019143168,0.019424671,0.019631874,0.019722901,0.019656312,0.019464472,0.019245122,0.018998789,0.018723281,0.018409481,0.018044963,0.0176553,0.01725847,0.016884748,0.016560555,0.016323939,0.016192753,0.016193535,0.01635718,0.0167009,0.017267602,0.018108709,0.019271398,0.020788152,0.022617985,0.024456963,0.025892155,0.026686093,0.026853222,0.026485758,0.025662865,0.024451176,0.023005495],[0.011821738,0.01264426,0.013643648,0.01494422,0.016619965,0.018753601,0.021116715,0.02332469,0.024855347,0.025570229,0.025493832,0.024746567,0.023440227,0.021776402,0.020247431,0.019334072,0.019061707,0.019166943,0.019398691,0.01962581,0.019715298,0.01964709,0.019496867,0.019282699,0.019034306,0.018755872,0.018430162,0.018071644,0.017683761,0.01728625,0.016902536,0.01657507,0.016328493,0.016193619,0.016200714,0.016362842,0.016713358,0.017292146,0.018139815,0.01930843,0.020854369,0.022677982,0.024503747,0.025928799,0.026701462,0.026842613,0.026464367,0.025633367,0.024415111,0.022971136],[0.011772627,0.012594594,0.013620346,0.014910519,0.016587038,0.018633304,0.020992449,0.023212168,0.024808744,0.025525656,0.025466079,0.024753463,0.023463797,0.021816893,0.020309893,0.019403204,0.019100066,0.01914277,0.019390464,0.0196136,0.019701691,0.019679438,0.019535359,0.019319233,0.019067813,0.018777184,0.01845859,0.018102527,0.017714828,0.01730801,0.016921557,0.016584089,0.016333202,0.016203169,0.01620739,0.016373875,0.016733306,0.017315269,0.018164739,0.01935822,0.02089902,0.022716526,0.024544662,0.025954407,0.026701478,0.026831305,0.026444342,0.02560569,0.02438542,0.022939974],[0.011759365,0.012611759,0.01364063,0.014947668,0.016562844,0.01861253,0.020968895,0.0232226,0.0247789,0.025478218,0.02542176,0.024700956,0.023414442,0.021799851,0.020333393,0.019425694,0.019071078,0.01913658,0.019375872,0.019590538,0.019720372,0.019698497,0.019549519,0.019329164,0.019064048,0.018780055,0.018462671,0.018106112,0.017709387,0.01730187,0.016908549,0.016570978,0.016329445,0.016201809,0.0162156,0.016396565,0.016765907,0.01735749,0.018240107,0.019441215,0.020989625,0.022822356,0.024633333,0.025994206,0.026701108,0.026797418,0.026382394,0.02552292,0.024285601,0.022868028],[0.011768706,0.0126226945,0.01366341,0.014912587,0.016526088,0.018573089,0.020971559,0.023190614,0.024734467,0.025441142,0.025380805,0.024665337,0.023407714,0.021831859,0.020365365,0.019399898,0.019067489,0.019121733,0.019351572,0.019611549,0.019741438,0.019714776,0.019562222,0.019328102,0.019070797,0.018788358,0.018470896,0.01810558,0.01770879,0.01729441,0.016900744,0.016571438,0.016330726,0.016210174,0.016235065,0.016422017,0.016795954,0.017413013,0.01829705,0.019500574,0.021068383,0.02290389,0.02468762,0.026018405,0.026693178,0.026762966,0.026329074,0.025452413,0.024230722,0.022783553],[0.011754464,0.012612971,0.013594975,0.0148299625,0.016426865,0.018502768,0.020865928,0.023088204,0.024669021,0.025400665,0.025369726,0.024700297,0.023496192,0.021933224,0.020397732,0.01943124,0.019065686,0.01909688,0.019371167,0.019632567,0.019762056,0.019737791,0.019575631,0.01935247,0.01909754,0.018815903,0.018490925,0.018127691,0.017725475,0.017311485,0.016924988,0.01659346,0.016354969,0.016238967,0.016262157,0.016444484,0.016831324,0.017436864,0.018307293,0.019513905,0.021077406,0.022895051,0.024674537,0.026001748,0.02667425,0.026745832,0.026313465,0.025462432,0.024219852,0.0227895],[0.011745616,0.012554086,0.013524267,0.014746949,0.01637083,0.01840657,0.020753512,0.022999791,0.024604278,0.025368141,0.025381401,0.024762701,0.023585794,0.021983935,0.020461937,0.019454738,0.019053193,0.01912326,0.019387692,0.01964388,0.019775702,0.019745057,0.019599296,0.01938032,0.019125776,0.018835679,0.018513441,0.018146036,0.017746793,0.01734276,0.016956056,0.016627785,0.016393518,0.016274717,0.016291551,0.016483273,0.016856387,0.017444974,0.018313568,0.01951134,0.021051373,0.022859829,0.024635924,0.025967287,0.026650244,0.02673117,0.026327176,0.025466507,0.024246337,0.022787664],[0.011690895,0.012488858,0.013449782,0.014697598,0.01628454,0.018293303,0.020644994,0.02290293,0.024542352,0.025355324,0.02541807,0.024829352,0.02363532,0.022072453,0.02052494,0.019471036,0.019099925,0.019146536,0.019391796,0.0196452,0.01977077,0.01976285,0.019626986,0.019410724,0.019146863,0.018859135,0.018532751,0.018170152,0.017783768,0.017382452,0.017001672,0.01667887,0.01644177,0.016315598,0.01633908,0.016515316,0.016868979,0.017451838,0.01830794,0.01947718,0.020998659,0.022791767,0.024565674,0.02591422,0.026618846,0.026736237,0.02633514,0.025504474,0.024272922,0.022832025],[0.0116678085,0.012466415,0.013462706,0.014697631,0.016280815,0.018306723,0.020657694,0.022912435,0.024553854,0.025368808,0.025419282,0.0247861,0.023611022,0.022039916,0.0204826,0.019496795,0.019121718,0.019153234,0.019387009,0.019623037,0.019764272,0.019762201,0.019628396,0.019401938,0.019139187,0.018844612,0.018521238,0.018170947,0.017788216,0.017396402,0.017026357,0.016707154,0.01646992,0.016357496,0.016374419,0.016541155,0.01689998,0.01748448,0.018329466,0.01949723,0.021013586,0.02279493,0.024556305,0.025891708,0.026602756,0.026700504,0.026307069,0.025454331,0.024234654,0.022843558],[0.011650147,0.012479917,0.013466108,0.014698131,0.016299311,0.018331597,0.020689726,0.022952784,0.02459011,0.025379634,0.025378818,0.024751505,0.023560721,0.02197595,0.02049243,0.0195123,0.019127367,0.019147784,0.019359758,0.01961022,0.019755982,0.01975617,0.01961288,0.019388597,0.019118275,0.018826181,0.018514797,0.018167745,0.017795254,0.017415393,0.017050406,0.016732661,0.016510112,0.016392408,0.016400957,0.016573189,0.016934628,0.017510047,0.018355591,0.019522121,0.02103142,0.02280276,0.024547977,0.025884368,0.026569363,0.026669275,0.026254319,0.02540894,0.024231127,0.02281267],[0.011658009,0.012478441,0.013460031,0.014705847,0.016312614,0.018357141,0.02073873,0.023011947,0.024623182,0.025356553,0.025353946,0.024705837,0.023495415,0.02197441,0.020499744,0.019514205,0.019120377,0.019117292,0.019343322,0.019597255,0.019745024,0.019736234,0.019597191,0.019365795,0.019098064,0.018817775,0.018508816,0.01817206,0.017811898,0.017437708,0.017075075,0.01677256,0.01654509,0.01641918,0.01643249,0.016606739,0.016959058,0.017534364,0.018379055,0.019540317,0.021042718,0.022800481,0.02454888,0.025855774,0.026540946,0.02662073,0.02621185,0.02540092,0.024200335,0.022798572],[0.011632436,0.012443373,0.013428746,0.014668212,0.016272815,0.018333472,0.02073979,0.023015298,0.024595402,0.02534709,0.02533995,0.024686763,0.023539945,0.02203126,0.020544022,0.01953225,0.01909742,0.019100493,0.019324949,0.019582082,0.019724892,0.019726995,0.019585868,0.01936002,0.0191051,0.01882681,0.01852869,0.018205144,0.017851496,0.017480355,0.017132804,0.01682364,0.01658517,0.01645958,0.016469622,0.016629096,0.016973969,0.017540371,0.01837101,0.019516168,0.020996902,0.022756439,0.024480427,0.025805054,0.026490258,0.026593352,0.026227668,0.025411885,0.024237331,0.022848155],[0.011608814,0.012425042,0.013408445,0.014650708,0.01627586,0.018367104,0.020780029,0.023015877,0.024601666,0.025332784,0.025307292,0.024695832,0.02355517,0.02204489,0.020548752,0.019504214,0.019080903,0.019082945,0.019305835,0.019553117,0.019705066,0.019704774,0.019571178,0.019359583,0.019105472,0.01883664,0.018550292,0.018232267,0.017881999,0.017527744,0.017175684,0.016858526,0.016623162,0.016497087,0.016495785,0.016651174,0.016991602,0.017549869,0.018371543,0.019502109,0.020987257,0.022711955,0.024436614,0.02574567,0.02644637,0.026582325,0.026209122,0.02541411,0.02425598,0.022873765],[0.011596245,0.012412009,0.013399545,0.01466266,0.01632101,0.018429058,0.020811899,0.023056515,0.024610678,0.02530995,0.025306944,0.024687998,0.023538923,0.022022208,0.02050123,0.019477444,0.019059299,0.019062443,0.01927268,0.019527452,0.019675089,0.019682541,0.01956457,0.019353664,0.019108495,0.01885008,0.018567499,0.018251797,0.01791862,0.017560314,0.01720215,0.016890386,0.016656823,0.016522104,0.016519219,0.016673205,0.017009424,0.017563652,0.018377176,0.019518733,0.020973278,0.022694314,0.02438847,0.02570099,0.02642468,0.026547264,0.026187107,0.025403243,0.024253571,0.022895517],[0.0115781175,0.012396157,0.0133998,0.014689772,0.016362892,0.018447455,0.020855078,0.023081627,0.024606412,0.025323214,0.025306864,0.024675839,0.023517754,0.021974683,0.020471785,0.019452639,0.01903592,0.019025339,0.01924297,0.019493219,0.019650197,0.01967553,0.019559396,0.019358383,0.01912333,0.018867316,0.018585915,0.018287059,0.017949192,0.017585369,0.017233614,0.016924364,0.016682869,0.01654682,0.016542653,0.016692657,0.01702515,0.017572157,0.018397221,0.019511053,0.020962447,0.022648655,0.024341075,0.025675392,0.026384875,0.02651995,0.026170004,0.025395118,0.024270713,0.022923956],[0.011562803,0.012394608,0.013421319,0.0147240795,0.016376626,0.01849212,0.020897169,0.023102148,0.024642471,0.02533532,0.025298122,0.024651144,0.023463368,0.021932285,0.020434365,0.019420205,0.018991845,0.01899172,0.019204732,0.019465122,0.019640835,0.019667814,0.019562418,0.019371888,0.019138236,0.018882036,0.018616755,0.01831169,0.01796815,0.017611552,0.017263321,0.01694754,0.016706107,0.016570074,0.016563328,0.016711123,0.017038502,0.017598627,0.018400768,0.019514667,0.020933094,0.02261388,0.024323655,0.025635013,0.026352456,0.026493413,0.026148863,0.025394134,0.02428275,0.022935739],[0.011557342,0.01240819,0.013444269,0.014726039,0.016405566,0.018526774,0.02092574,0.023161866,0.024676673,0.025341839,0.025282966,0.024604343,0.023420257,0.021887809,0.020392193,0.019365996,0.018950945,0.018947858,0.019173307,0.019454423,0.019631768,0.019670125,0.0195759,0.019386599,0.019152028,0.018911552,0.018638257,0.018326813,0.017990675,0.017637905,0.017283937,0.016969318,0.016728817,0.016591044,0.016582817,0.016726462,0.017066985,0.017607005,0.01841049,0.019494629,0.020908179,0.022607246,0.024287354,0.02560251,0.026322646,0.026466403,0.026137229,0.02539314,0.024284797,0.022953032],[0.011557519,0.012413638,0.013426539,0.014725236,0.016405182,0.018522501,0.020971524,0.023201795,0.024697613,0.025344053,0.025258059,0.024582451,0.023395607,0.021860903,0.020345146,0.01932522,0.018902583,0.01891221,0.019160504,0.019444447,0.01963534,0.019686835,0.019595174,0.01940564,0.019187393,0.018937305,0.018656917,0.018353017,0.018020738,0.017662553,0.017310422,0.016996987,0.016754588,0.016614715,0.016601503,0.016756188,0.017076477,0.017615683,0.018389385,0.019466598,0.02089801,0.022563854,0.02424575,0.02556549,0.02629236,0.026453372,0.026136138,0.025398577,0.024309432,0.022960883],[0.011548154,0.012381086,0.01340338,0.014696119,0.016364759,0.018529251,0.020985877,0.023214605,0.02470407,0.025331834,0.025253044,0.024578338,0.023392497,0.021839095,0.020322798,0.019283853,0.018866992,0.018898454,0.019147675,0.019446256,0.019652143,0.01970807,0.019618629,0.019447915,0.0192192,0.018961258,0.018688442,0.018388264,0.018050838,0.017695539,0.017345427,0.017030545,0.016785892,0.016640382,0.016636295,0.016770288,0.017087454,0.01759667,0.018361185,0.019454096,0.020848889,0.022509137,0.024190655,0.025519501,0.026270011,0.02644752,0.026141215,0.025425479,0.024330733,0.022990212],[0.0115164835,0.012356862,0.013373991,0.014656007,0.016367072,0.018541733,0.021001466,0.023227524,0.024697142,0.025328632,0.02524639,0.024569286,0.02336642,0.02181484,0.020281518,0.019247763,0.018853916,0.018886132,0.019148545,0.019460145,0.019668382,0.019725954,0.01965743,0.019476417,0.01923969,0.018989202,0.018719222,0.018413266,0.018079313,0.017727165,0.01737731,0.017062109,0.016813703,0.016678473,0.016656097,0.016788285,0.017079212,0.017581977,0.018365242,0.019426472,0.020814408,0.02246611,0.024143707,0.025488624,0.026251497,0.026436754,0.026147287,0.025427321,0.02434386,0.023013676],[0.011510259,0.012350243,0.01336403,0.014692342,0.016425924,0.018616915,0.021079922,0.023272142,0.024720348,0.025322141,0.025215663,0.024505572,0.023289725,0.02171717,0.020198893,0.019209139,0.018832712,0.018888546,0.019165792,0.019474693,0.01967786,0.01975171,0.019668937,0.019478817,0.019249799,0.019001173,0.018723797,0.018420413,0.018089136,0.017737934,0.017389905,0.017074386,0.016840361,0.016692469,0.01667387,0.016787933,0.017080469,0.017611008,0.018376514,0.01944315,0.020832611,0.022479286,0.024158418,0.025491642,0.026238188,0.026418902,0.026109926,0.025386162,0.02430395,0.022959068],[0.011495865,0.012331111,0.013382109,0.014727252,0.016474292,0.018677704,0.021126924,0.023314329,0.024735292,0.02531107,0.025172764,0.024448048,0.023206329,0.02163361,0.020149386,0.019178312,0.018832048,0.018907469,0.019183327,0.019486317,0.019705268,0.019762594,0.019670153,0.019488756,0.019261878,0.019005496,0.018730814,0.018429866,0.018099256,0.017749792,0.017401494,0.017100383,0.016853996,0.016709797,0.016674079,0.016789738,0.017109113,0.017624043,0.018395219,0.019465744,0.020854367,0.022509342,0.024181243,0.025495669,0.026231946,0.02638929,0.026072571,0.025345393,0.024246033,0.022873152],[0.011477757,0.012344878,0.01341064,0.014767257,0.016528266,0.018729078,0.02119146,0.023358718,0.024747012,0.02528338,0.025124514,0.024369983,0.023117125,0.021563143,0.020093685,0.019162273,0.01884695,0.018926138,0.019197382,0.019515598,0.019713758,0.019758746,0.019674532,0.019495038,0.019260101,0.019006783,0.018734364,0.018433638,0.018104417,0.017754506,0.017420838,0.01710778,0.016865866,0.0167062,0.01667323,0.016816026,0.017122844,0.017644806,0.018422807,0.019496962,0.020900948,0.022557585,0.02421377,0.025512284,0.026214711,0.026355626,0.0260278,0.025278926,0.024147168,0.022822628],[0.011490089,0.012370295,0.013445458,0.01481421,0.016576322,0.018803779,0.021266548,0.023406815,0.024746466,0.025252815,0.025059013,0.024285879,0.023036828,0.021482224,0.020049239,0.0191611,0.018861294,0.018941382,0.019231547,0.01952583,0.019708421,0.019759925,0.019675964,0.019487362,0.019255958,0.019005118,0.018732725,0.018433018,0.018102821,0.017767292,0.017421197,0.017112946,0.016856458,0.016700378,0.016694559,0.016826946,0.017141357,0.017671606,0.018455625,0.019549266,0.020963734,0.022616068,0.024263924,0.025522491,0.026198149,0.026318729,0.025964119,0.025180148,0.024079647,0.022726886],[0.011486453,0.012368369,0.013443814,0.014799595,0.016573515,0.018804507,0.02126543,0.023387058,0.024722116,0.025214557,0.025019875,0.024260983,0.02301424,0.021482619,0.020075565,0.019190107,0.018882992,0.01897917,0.019241896,0.019521361,0.019714383,0.019769846,0.019679444,0.019496752,0.01926905,0.019019019,0.018748522,0.018448569,0.018133385,0.01778457,0.017442195,0.017117007,0.016860735,0.016726557,0.016705606,0.016838545,0.017153405,0.017680643,0.018473595,0.019569036,0.020976223,0.02262996,0.024255319,0.025506146,0.026176572,0.026284589,0.025910936,0.025160234,0.024037156,0.022697873],[0.011475461,0.0123555735,0.013416617,0.014778475,0.016551973,0.018780496,0.021226088,0.023351168,0.024680544,0.025179842,0.02500313,0.02425094,0.023028305,0.02152472,0.020121612,0.019225266,0.01893162,0.018993432,0.019235281,0.019523827,0.019720953,0.01977129,0.019690018,0.019513285,0.019287199,0.019039318,0.018768737,0.018484574,0.018156076,0.017811993,0.017452953,0.017128102,0.016892357,0.016741851,0.016718833,0.016849319,0.017157882,0.017689515,0.018479945,0.019563694,0.020969179,0.022599032,0.024220387,0.025473839,0.026140643,0.02624058,0.025901921,0.025138978,0.024031635,0.022731464],[0.011462074,0.012329642,0.013395678,0.014757358,0.016528232,0.018739466,0.021185327,0.023302771,0.02464089,0.025158705,0.024988871,0.024258716,0.023065286,0.021575673,0.020170216,0.01928986,0.018956019,0.018990772,0.0192362,0.01952504,0.019715494,0.019776687,0.01970437,0.01953148,0.019308355,0.01906016,0.018805668,0.018507618,0.018185059,0.01782524,0.017468244,0.01716465,0.016912967,0.016759887,0.016733518,0.016856618,0.017167559,0.017694972,0.018471794,0.01955086,0.02092778,0.022546878,0.02416723,0.025419243,0.02608615,0.026225349,0.025883565,0.025140874,0.02407463,0.022770328],[0.011439429,0.012311543,0.013378386,0.014738759,0.016493898,0.018702948,0.021135619,0.023258673,0.024614917,0.02513839,0.02498689,0.024281552,0.023105424,0.02162602,0.020248996,0.019328823,0.018962001,0.018996514,0.019235149,0.01951219,0.019712918,0.019784473,0.019719057,0.019551754,0.019328969,0.019097084,0.018827269,0.018535787,0.018197993,0.017842283,0.017508352,0.017190073,0.016936714,0.016780464,0.016746545,0.016870996,0.017176954,0.017690094,0.018460624,0.019509,0.020868562,0.022476293,0.024084708,0.025336405,0.026050689,0.026196064,0.025880221,0.025180219,0.024122039,0.02284137],[0.01143093,0.01230586,0.013374688,0.014725423,0.016483078,0.018680843,0.021113902,0.023246739,0.024597844,0.0251289,0.024990244,0.02429352,0.023126865,0.021686641,0.02028674,0.01933954,0.018973617,0.018999748,0.019219626,0.019502586,0.019711455,0.019789578,0.019731816,0.019566823,0.01936156,0.019112382,0.01884881,0.018541358,0.01820896,0.01787814,0.017531263,0.017213939,0.016959583,0.016797742,0.016766492,0.016887574,0.017181385,0.017690059,0.018433055,0.019464659,0.020809049,0.022390874,0.02397967,0.02527438,0.025996687,0.026171,0.025895698,0.025208969,0.024181964,0.022907712],[0.011420041,0.012295416,0.013353879,0.014703999,0.016448464,0.01864487,0.021091456,0.023224404,0.024587667,0.025131913,0.025000764,0.02431325,0.023185777,0.021736033,0.02031609,0.019366564,0.018985033,0.018985892,0.019205617,0.019493332,0.019708825,0.019796921,0.019745499,0.01960219,0.019379321,0.019136494,0.018855736,0.01855449,0.018248305,0.017905425,0.017561719,0.017244892,0.016985754,0.016826248,0.016790768,0.01689865,0.017186075,0.01766641,0.018390143,0.01940275,0.02071204,0.02225472,0.023874203,0.025176222,0.025940523,0.026165297,0.025913758,0.025265988,0.024261614,0.023058543],[0.011408366,0.01227439,0.013331554,0.014669191,0.016410593,0.018618703,0.021065092,0.023212824,0.02459021,0.025139475,0.025014058,0.024358416,0.023227701,0.021772156,0.020360313,0.019393718,0.018978573,0.018974975,0.019192697,0.019482307,0.01970716,0.019803137,0.019778257,0.01961959,0.01940494,0.019143466,0.018868806,0.01859416,0.018275818,0.017938366,0.017597552,0.01727833,0.017023195,0.01686039,0.016812338,0.016913762,0.01717406,0.017635548,0.018340813,0.019316953,0.020576274,0.02212962,0.02373071,0.025069246,0.025893683,0.026152711,0.025945645,0.025329253,0.024403185,0.023207713],[0.011388978,0.012253809,0.013300434,0.014635437,0.016387535,0.018594481,0.021055367,0.023218367,0.024598356,0.025148412,0.02504526,0.024383768,0.023250818,0.021815017,0.020399222,0.01939867,0.0189736,0.018964626,0.019177685,0.019471405,0.019702584,0.019826738,0.019788584,0.019642573,0.019409716,0.0191545,0.01890611,0.018617641,0.018305784,0.017973004,0.017632496,0.017320232,0.017064268,0.016891034,0.01683798,0.016914746,0.017158283,0.017604165,0.018276671,0.019203532,0.02046576,0.021976648,0.023583733,0.024971176,0.025834447,0.026144145,0.025972638,0.025429718,0.024527766,0.023402022],[0.011376847,0.012234338,0.013281306,0.014629828,0.016385734,0.018610677,0.021089148,0.02324922,0.024617588,0.02517413,0.025053099,0.024380403,0.023260988,0.02183067,0.020396011,0.01939339,0.018964367,0.018951438,0.019164775,0.019459184,0.019716416,0.019824168,0.019800894,0.019638345,0.019413672,0.019184971,0.018919868,0.018637313,0.018330125,0.017999029,0.017668268,0.017358549,0.01709598,0.016921436,0.016848255,0.016912775,0.01714622,0.017566886,0.018198635,0.019133719,0.020352283,0.02184855,0.023474086,0.024877002,0.025784897,0.026127521,0.02601778,0.025496606,0.024662487,0.02354009],[0.011359162,0.012216945,0.013275907,0.014628413,0.016402522,0.018651644,0.021137992,0.023289615,0.024658073,0.025186645,0.025046837,0.0243778,0.0232592,0.021814924,0.020385405,0.019383252,0.01895089,0.018939327,0.019150699,0.019468479,0.019705212,0.019827733,0.019788584,0.019637583,0.019441713,0.019194044,0.018934038,0.018655147,0.018349454,0.018029196,0.017702809,0.017389128,0.017128129,0.01693675,0.016854485,0.016912468,0.01712574,0.017512212,0.018157095,0.019055605,0.020257797,0.021759294,0.02337372,0.02480284,0.02573742,0.026135491,0.026042292,0.025576023,0.024751127,0.023643164],[0.011347781,0.012217015,0.013281279,0.0146525,0.016454885,0.018724209,0.02121554,0.02336858,0.02469335,0.025187723,0.025036724,0.02435601,0.023216614,0.021775132,0.020352848,0.019357063,0.018933266,0.01892429,0.019160995,0.019452805,0.019702047,0.019805381,0.019778503,0.0196584,0.019442191,0.019199397,0.018941784,0.018663125,0.018367874,0.018052226,0.017723396,0.017413933,0.017139556,0.016943045,0.016858589,0.016902033,0.01708838,0.017494015,0.018113049,0.019003287,0.020215422,0.021698147,0.02331865,0.024752753,0.025729127,0.026131047,0.026074639,0.025608426,0.02479358,0.023679309],[0.011344891,0.012218215,0.013297602,0.014693204,0.016517682,0.01880644,0.021323593,0.023438944,0.024720246,0.025191588,0.02501914,0.024311256,0.023165304,0.021723783,0.020307396,0.01932612,0.018911103,0.018934326,0.019143693,0.01944762,0.019674718,0.019790202,0.019795198,0.01965337,0.019442692,0.019201864,0.018943453,0.018674526,0.01838307,0.018064896,0.017741216,0.017419944,0.017142776,0.01694663,0.016851,0.016872002,0.0170804,0.01746713,0.018083643,0.018990057,0.020188257,0.02167488,0.023289597,0.024755957,0.025722822,0.026146997,0.026079483,0.02561304,0.024787797,0.023680205],[0.011335388,0.012219266,0.01331602,0.014726517,0.016567927,0.018897327,0.021403247,0.023488723,0.024746547,0.02519183,0.024990803,0.02427244,0.023120318,0.021676283,0.020268546,0.019296028,0.018918114,0.01891375,0.019137017,0.019416967,0.019657474,0.019806432,0.019788422,0.019653328,0.01944505,0.019203067,0.018954089,0.018688096,0.018393515,0.018080564,0.017745329,0.01742228,0.017146489,0.016940527,0.016824495,0.016867895,0.017060602,0.01744669,0.018081404,0.018977536,0.020181425,0.021662056,0.023311201,0.024763148,0.025745569,0.026149191,0.026073027,0.025591029,0.024765726,0.023671294],[0.011331094,0.012228932,0.013336898,0.014760468,0.016642842,0.01897783,0.021474723,0.023544274,0.024768284,0.02517707,0.02495895,0.0242278,0.02306572,0.021621855,0.020220008,0.019291084,0.018889477,0.018904101,0.01910277,0.019397542,0.019672431,0.019795319,0.01978382,0.019651085,0.019441526,0.019209055,0.01896218,0.018692136,0.018402405,0.018077545,0.017741261,0.017420609,0.017136553,0.016912568,0.016820211,0.01685137,0.017045967,0.017452719,0.018081777,0.018987294,0.020189503,0.021711523,0.023348965,0.024815021,0.025763292,0.02614441,0.026042629,0.025549922,0.02472619,0.023648906],[0.011328881,0.012234,0.013349283,0.014804747,0.016692992,0.01903264,0.021538312,0.023586053,0.02477233,0.025161397,0.024928527,0.024185214,0.023017952,0.021571232,0.02020737,0.019253846,0.018874796,0.01886422,0.019080378,0.01941265,0.01965943,0.019789351,0.019780442,0.019646617,0.019447165,0.019216454,0.018964862,0.018699422,0.018397171,0.018071525,0.017737897,0.01740942,0.017108308,0.01690816,0.016804826,0.01683829,0.017053291,0.017455637,0.018094044,0.01899898,0.020246033,0.021764427,0.023429666,0.024863057,0.02578058,0.026126541,0.026005907,0.025505519,0.02468782,0.023612376],[0.011320935,0.012229529,0.013368023,0.01482353,0.016713487,0.019073011,0.021578701,0.02360047,0.024770178,0.025145,0.024900932,0.024152147,0.022979619,0.021562988,0.020169508,0.01923666,0.018829405,0.018837765,0.01909509,0.01939717,0.01965208,0.019785201,0.01977589,0.019653393,0.019455917,0.019220099,0.018973064,0.018694457,0.018391693,0.018068902,0.017727656,0.017382734,0.017105611,0.016894821,0.016793536,0.01684623,0.017056666,0.017466707,0.018103467,0.019051634,0.020298364,0.021856118,0.023502402,0.02491057,0.025787149,0.026106922,0.025971692,0.0254688,0.024645766,0.023568232],[0.011309874,0.0122368485,0.01337313,0.014826724,0.016735125,0.01910489,0.021598022,0.023609845,0.024764061,0.025125457,0.024874114,0.024118535,0.022969685,0.021523234,0.02014825,0.019185193,0.018798308,0.01885256,0.019077187,0.019387716,0.019645426,0.019777779,0.019780489,0.019660318,0.01945775,0.019226724,0.018965706,0.018686727,0.018386899,0.018056626,0.017699651,0.017379653,0.017092526,0.01688437,0.016802073,0.01685073,0.017068222,0.017476508,0.01815445,0.019103825,0.020394657,0.021945564,0.02358084,0.024950724,0.025793571,0.0260892,0.025942383,0.025426893,0.02459466,0.02350639],[0.01131117,0.012235377,0.013367943,0.01483603,0.016755803,0.019121518,0.021616256,0.0236163,0.024754148,0.025104824,0.024844399,0.024105618,0.022928702,0.021497024,0.020090207,0.019148111,0.018812336,0.018832544,0.019066619,0.019379215,0.01963524,0.0197795,0.019784268,0.019659115,0.019462068,0.019216439,0.018955242,0.018679187,0.018371742,0.018026182,0.017695239,0.017365633,0.017082013,0.016893001,0.016807254,0.016862674,0.01707849,0.01752568,0.018205313,0.019198773,0.020489188,0.022042187,0.02365351,0.024993155,0.02580366,0.026077354,0.025910381,0.025379471,0.02453081,0.023413092],[0.011294402,0.012211731,0.013351326,0.014822743,0.016732931,0.019103032,0.021600042,0.023598507,0.024736004,0.025084846,0.024843164,0.024085008,0.02292367,0.02146127,0.020067902,0.019171761,0.01879376,0.018821273,0.019055529,0.019365393,0.019634793,0.019782314,0.019783849,0.019666709,0.019455656,0.019210638,0.01895265,0.01866894,0.01834671,0.018028514,0.017687932,0.017362256,0.017097104,0.016903538,0.016822398,0.016873742,0.01712327,0.017568534,0.018285643,0.019275757,0.020569146,0.02210889,0.023708032,0.025026595,0.025816105,0.026068194,0.025885854,0.0253397,0.024463598,0.023358611],[0.011274575,0.012198585,0.01334251,0.014807106,0.016723232,0.01909801,0.021593435,0.023587499,0.02471686,0.025076514,0.024813343,0.024064727,0.022875195,0.021426123,0.020084148,0.019149179,0.01878112,0.018809926,0.019040182,0.019361569,0.019631788,0.019773921,0.019783499,0.019652525,0.019443313,0.019201936,0.01893575,0.018637024,0.018343223,0.018015195,0.017679833,0.017373772,0.017105225,0.0169173,0.016833212,0.016917497,0.017166063,0.017647056,0.018361937,0.019356186,0.020641455,0.022180142,0.023769893,0.025067853,0.025826437,0.026054593,0.025852028,0.025277602,0.024406157,0.023323795],[0.011265027,0.012193712,0.013333016,0.014804804,0.016729338,0.019108374,0.02160235,0.023583071,0.024714343,0.025045533,0.024784189,0.024006847,0.02282442,0.02142324,0.02004837,0.019129949,0.018767582,0.01879453,0.01903723,0.019356899,0.019618753,0.019767202,0.01976146,0.01963318,0.01942843,0.019178571,0.018896969,0.018627642,0.018323096,0.018000923,0.017685834,0.017377052,0.01711527,0.016925624,0.01687436,0.016958753,0.017241653,0.017721245,0.018440243,0.019428577,0.020719454,0.022262722,0.023844818,0.025110062,0.025834212,0.026033424,0.025799615,0.02522264,0.024363965,0.023251448],[0.011252914,0.0121759875,0.0133188125,0.0147951525,0.016722603,0.019105582,0.021595808,0.023586331,0.024689393,0.0250221,0.024736201,0.023964398,0.022822652,0.021390865,0.020031268,0.019117964,0.018752852,0.018793186,0.019032951,0.019341838,0.019609487,0.019741604,0.019739972,0.019617867,0.019405171,0.019139852,0.018889133,0.018608028,0.018309796,0.018008197,0.017690238,0.0173885,0.017124966,0.016966969,0.016914884,0.01703034,0.017309781,0.017789872,0.01849995,0.019492364,0.020793047,0.022343582,0.023907805,0.025142414,0.025834095,0.026000949,0.025762273,0.025193043,0.024306158,0.023190783],[0.011232418,0.012157537,0.013303144,0.014780651,0.016711472,0.019094074,0.021602828,0.02356566,0.024670018,0.024978943,0.024697136,0.023957944,0.022789782,0.02137281,0.020019934,0.019104714,0.018754076,0.018791346,0.01901803,0.019330705,0.019579636,0.019716,0.019721674,0.019592566,0.019364959,0.019132547,0.018868744,0.018594153,0.018316612,0.01801173,0.017701253,0.017398076,0.017166037,0.017006872,0.0169839,0.017094726,0.017372245,0.017841263,0.018553043,0.019555617,0.020870298,0.022415752,0.023960114,0.025163068,0.025818635,0.025977135,0.025741378,0.025146661,0.024254574,0.02314746],[0.01121827,0.012146706,0.013294764,0.014777497,0.016711663,0.019119987,0.021602029,0.023561923,0.024633743,0.024940116,0.02467962,0.023913616,0.022755215,0.02134524,0.019995578,0.019102108,0.018752873,0.018778272,0.019008609,0.019298626,0.019550232,0.019692784,0.019690625,0.019546673,0.01935432,0.01910753,0.018850269,0.018596208,0.01831435,0.018017005,0.01770525,0.017434118,0.017201275,0.017071053,0.01704382,0.017152468,0.017419087,0.01788962,0.018612612,0.019633478,0.020952366,0.022489857,0.024008507,0.025169874,0.025808878,0.025961405,0.025698224,0.025094617,0.02420488,0.023092194],[0.011204502,0.012134265,0.013285625,0.014770101,0.01673037,0.019119268,0.021607501,0.023534544,0.024602754,0.024925238,0.024639215,0.023879569,0.022725658,0.02131787,0.019991055,0.019101638,0.018741198,0.018771226,0.018976104,0.019267678,0.019525135,0.01965927,0.019642588,0.01953676,0.019329207,0.01908935,0.018852796,0.018593248,0.018318757,0.018019797,0.017740237,0.017467745,0.01726327,0.017128088,0.01709753,0.0171942,0.01746054,0.017940596,0.018681355,0.019709306,0.0210278,0.022550723,0.024033764,0.025178896,0.025806768,0.025929678,0.02565619,0.02505191,0.02415458,0.023034573],[0.011189188,0.012120946,0.01327257,0.014779374,0.016722763,0.019123819,0.02158379,0.02351044,0.0245936,0.02488993,0.024608005,0.023850776,0.022697931,0.021311738,0.019991186,0.019091789,0.018736728,0.01873902,0.018944656,0.019241089,0.019489197,0.019608725,0.019633157,0.019511737,0.019312043,0.01909351,0.01885017,0.018597681,0.018321004,0.018054368,0.017772635,0.017528322,0.017318234,0.017179038,0.017135771,0.017230786,0.017504988,0.018001262,0.018749151,0.019779129,0.021089392,0.02258399,0.024058014,0.02519248,0.025786929,0.025897708,0.025621502,0.025009364,0.02410376,0.022986451],[0.011174581,0.012106146,0.013276525,0.014768011,0.016723638,0.019100202,0.021564653,0.023509948,0.024563525,0.02486149,0.024579393,0.023821456,0.02268674,0.021308536,0.019981286,0.019089485,0.018704718,0.018707568,0.01891759,0.019202601,0.019435318,0.019598665,0.019606799,0.019494526,0.01931736,0.01909093,0.018854322,0.01859882,0.018354515,0.018084561,0.017831007,0.017580518,0.017366385,0.017214457,0.017169077,0.017271088,0.017560354,0.018063337,0.018813713,0.019838035,0.021124175,0.022617362,0.024087118,0.025184898,0.02576409,0.025869435,0.025584748,0.02496458,0.024059488,0.022952091]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"matches\":\"x2\",\"showticklabels\":false,\"title\":{\"text\":\"Date\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.33499999999999996,0.9999999999999999],\"title\":{\"text\":\"Price ($)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.285],\"title\":{\"text\":\"Lookback Days\"}},\"title\":{\"text\":\"SPY Price Prediction with Pattern Importance Analysis\"},\"height\":800,\"showlegend\":true,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('537ae865-d5fd-4102-8bd8-098fbab57e3f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "How to Interpret the Visualization:\n",
            "--------------------------------------------------\n",
            "1. Top Panel:\n",
            "   - Blue line: Actual SPY price\n",
            "   - Red line: LSTM predictions\n",
            "\n",
            "2. Bottom Panel (Heatmap):\n",
            "   - Each row represents one prediction\n",
            "   - Colors show which past days were most important\n",
            "   - Brighter colors = More important for prediction\n",
            "   - X-axis shows lookback days (0 = most recent)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import json\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "class RegimeLSTM:\n",
        "    def __init__(self, lookback=50):\n",
        "        self.lookback = lookback\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.models = {}\n",
        "        self.regime_metadata = {}\n",
        "\n",
        "    def create_model(self):\n",
        "        \"\"\"Create model using functional API\"\"\"\n",
        "        inputs = Input(shape=(self.lookback, 1))\n",
        "        lstm_out = LSTM(50)(inputs)\n",
        "        outputs = Dense(1)(lstm_out)\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "    def prepare_data(self, prices, for_prediction=False):\n",
        "        \"\"\"Prepare data with validation checks\"\"\"\n",
        "        if for_prediction:\n",
        "            if len(prices) != self.lookback:\n",
        "                raise ValueError(f\"For prediction, need exactly {self.lookback} price points, got {len(prices)}\")\n",
        "        else:\n",
        "            if len(prices) < self.lookback + 1:\n",
        "                raise ValueError(f\"For training, need at least {self.lookback + 1} price points, got {len(prices)}\")\n",
        "\n",
        "        scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
        "\n",
        "        if for_prediction:\n",
        "            X = np.array([scaled_data])\n",
        "            return X, None\n",
        "        else:\n",
        "            X, y = [], []\n",
        "            for i in range(self.lookback, len(scaled_data)):\n",
        "                X.append(scaled_data[i-self.lookback:i])\n",
        "                y.append(scaled_data[i])\n",
        "            return np.array(X), np.array(y)\n",
        "\n",
        "    def train_regime(self, prices, regime_name, regime_characteristics):\n",
        "        \"\"\"Train and save model with error handling\"\"\"\n",
        "        try:\n",
        "            X, y = self.prepare_data(prices, for_prediction=False)\n",
        "\n",
        "            # Calculate appropriate batch size\n",
        "            batch_size = min(32, len(X))\n",
        "\n",
        "            # Create and train model\n",
        "            model = self.create_model()\n",
        "\n",
        "            print(f\"\\nTraining {regime_name} model...\")\n",
        "            print(f\"Training data shape: {X.shape}\")\n",
        "\n",
        "            history = model.fit(\n",
        "                X, y,\n",
        "                epochs=50,\n",
        "                batch_size=batch_size,\n",
        "                validation_split=0.2,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            # Create save directory\n",
        "            save_dir = Path(\"regime_models\")\n",
        "            save_dir.mkdir(exist_ok=True)\n",
        "\n",
        "            # Save model in .keras format\n",
        "            model_path = save_dir / f\"{regime_name}_model.keras\"\n",
        "            metadata_path = save_dir / f\"{regime_name}_metadata.json\"\n",
        "\n",
        "            model.save(model_path)\n",
        "\n",
        "            # Save metadata\n",
        "            metadata = {\n",
        "                \"regime_name\": regime_name,\n",
        "                \"characteristics\": regime_characteristics,\n",
        "                \"training_loss\": float(history.history['loss'][-1]),\n",
        "                \"data_points\": len(prices),\n",
        "                \"lookback\": self.lookback,\n",
        "                \"scaler_params\": {\n",
        "                    \"scale_\": self.scaler.scale_.tolist(),\n",
        "                    \"min_\": self.scaler.min_.tolist(),\n",
        "                }\n",
        "            }\n",
        "\n",
        "            with open(metadata_path, 'w') as f:\n",
        "                json.dump(metadata, f, indent=4)\n",
        "\n",
        "            self.models[regime_name] = model\n",
        "            self.regime_metadata[regime_name] = metadata\n",
        "\n",
        "            print(f\"Final loss: {history.history['loss'][-1]:.6f}\")\n",
        "            print(f\"Training data points: {len(prices)}\")\n",
        "\n",
        "            return model, metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error training regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def predict_with_regime(self, prices, regime_name):\n",
        "        \"\"\"Make predictions with error handling\"\"\"\n",
        "        try:\n",
        "            if regime_name not in self.models:\n",
        "                self.load_regime_model(regime_name)\n",
        "\n",
        "            if len(prices) != self.lookback:\n",
        "                prices = prices[-self.lookback:]  # Take last lookback prices\n",
        "                print(f\"Adjusted input to last {self.lookback} prices\")\n",
        "\n",
        "            # Prepare data specifically for prediction\n",
        "            X, _ = self.prepare_data(prices, for_prediction=True)\n",
        "\n",
        "            # Make prediction\n",
        "            prediction = self.models[regime_name].predict(X, verbose=0)\n",
        "\n",
        "            # Inverse transform\n",
        "            prediction = self.scaler.inverse_transform(prediction)\n",
        "\n",
        "            return float(prediction[0][0])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error predicting with regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Fetching SPY data...\")\n",
        "        df = yf.download('SPY', start='2014-01-01', end='2017-12-31')\n",
        "        if df.empty:\n",
        "            raise ValueError(\"No data downloaded\")\n",
        "\n",
        "        print(f\"Downloaded {len(df)} days of data\")\n",
        "\n",
        "        # Create regime classifier\n",
        "        regime_lstm = RegimeLSTM(lookback=50)\n",
        "\n",
        "        # Define example regimes\n",
        "        regimes = {\n",
        "            \"high_vol_uptrend\": {\n",
        "                \"volatility\": \"high\",\n",
        "                \"trend\": \"upward\",\n",
        "                \"volume\": \"above_average\"\n",
        "            },\n",
        "            \"low_vol_sideways\": {\n",
        "                \"volatility\": \"low\",\n",
        "                \"trend\": \"sideways\",\n",
        "                \"volume\": \"below_average\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(\"\\nTraining regime models...\")\n",
        "\n",
        "        # Train models\n",
        "        high_vol_period = df['Close'].values[:500]\n",
        "        model_high_vol, metadata_high_vol = regime_lstm.train_regime(\n",
        "            high_vol_period,\n",
        "            \"high_vol_uptrend\",\n",
        "            regimes[\"high_vol_uptrend\"]\n",
        "        )\n",
        "\n",
        "        low_vol_period = df['Close'].values[500:1000]\n",
        "        model_low_vol, metadata_low_vol = regime_lstm.train_regime(\n",
        "            low_vol_period,\n",
        "            \"low_vol_sideways\",\n",
        "            regimes[\"low_vol_sideways\"]\n",
        "        )\n",
        "\n",
        "        # Get exactly lookback days for prediction\n",
        "        recent_prices = df['Close'].values[-regime_lstm.lookback:]\n",
        "        print(f\"\\nMaking predictions using last {len(recent_prices)} price points\")\n",
        "\n",
        "        prediction_high_vol = regime_lstm.predict_with_regime(\n",
        "            recent_prices,\n",
        "            \"high_vol_uptrend\"\n",
        "        )\n",
        "\n",
        "        prediction_low_vol = regime_lstm.predict_with_regime(\n",
        "            recent_prices,\n",
        "            \"low_vol_sideways\"\n",
        "        )\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\nRegime-Based LSTM Analysis\")\n",
        "        print(\"-\" * 50)\n",
        "        current_price = float(df['Close'].values[-1])\n",
        "        print(f\"Current Price: ${current_price:.2f}\")\n",
        "        print(f\"High Volatility Regime Prediction: ${prediction_high_vol:.2f} ({((prediction_high_vol/current_price) - 1)*100:.2f}% change)\")\n",
        "        print(f\"Low Volatility Regime Prediction: ${prediction_low_vol:.2f} ({((prediction_low_vol/current_price) - 1)*100:.2f}% change)\")\n",
        "\n",
        "        # Print regime characteristics\n",
        "        print(\"\\nStored Regime Characteristics:\")\n",
        "        for regime_name, metadata in regime_lstm.regime_metadata.items():\n",
        "            print(f\"\\n{regime_name}:\")\n",
        "            for key, value in metadata['characteristics'].items():\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kUBt6I21FfE",
        "outputId": "5551585c-fd95-47b9-b164-fc3f96e7ff1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching SPY data...\n",
            "Downloaded 1007 days of data\n",
            "\n",
            "Training regime models...\n",
            "\n",
            "Training high_vol_uptrend model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.2638 - val_loss: 0.0580\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0339 - val_loss: 0.0177\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0125 - val_loss: 0.0149\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0066 - val_loss: 0.0171\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0054 - val_loss: 0.0145\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0056 - val_loss: 0.0158\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0050 - val_loss: 0.0148\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0050 - val_loss: 0.0150\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0045 - val_loss: 0.0150\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0039 - val_loss: 0.0157\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0049 - val_loss: 0.0149\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0043 - val_loss: 0.0146\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0042 - val_loss: 0.0152\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0041 - val_loss: 0.0149\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0043 - val_loss: 0.0144\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0045 - val_loss: 0.0151\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0047 - val_loss: 0.0148\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.0148\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0043 - val_loss: 0.0140\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0139\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0043 - val_loss: 0.0141\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0147\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0038 - val_loss: 0.0134\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0136\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0149\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0045 - val_loss: 0.0132\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0131\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0037 - val_loss: 0.0129\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0039 - val_loss: 0.0129\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0144\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0037 - val_loss: 0.0124\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0045 - val_loss: 0.0124\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0045 - val_loss: 0.0142\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0039 - val_loss: 0.0126\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0040 - val_loss: 0.0124\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0035 - val_loss: 0.0132\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0043 - val_loss: 0.0124\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0034 - val_loss: 0.0121\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0035 - val_loss: 0.0119\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0036 - val_loss: 0.0117\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0032 - val_loss: 0.0122\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0037 - val_loss: 0.0117\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0036 - val_loss: 0.0116\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0116\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0036 - val_loss: 0.0118\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0032 - val_loss: 0.0115\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0035 - val_loss: 0.0109\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0114\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0033 - val_loss: 0.0108\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0032 - val_loss: 0.0113\n",
            "Final loss: 0.003291\n",
            "Training data points: 500\n",
            "\n",
            "Training low_vol_sideways model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.1759 - val_loss: 0.0018\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0138 - val_loss: 0.0213\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0047 - val_loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0020 - val_loss: 0.0089\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.5945e-04 - val_loss: 0.0015\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 9.2275e-04 - val_loss: 9.4172e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 7.8362e-04 - val_loss: 7.3881e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 7.8051e-04 - val_loss: 4.3872e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 6.6403e-04 - val_loss: 6.4983e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 6.7705e-04 - val_loss: 3.4185e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.1621e-04 - val_loss: 3.5545e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.1744e-04 - val_loss: 4.1358e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 7.3369e-04 - val_loss: 3.4509e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.9460e-04 - val_loss: 3.3723e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.7453e-04 - val_loss: 3.2845e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.5581e-04 - val_loss: 3.4475e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.5519e-04 - val_loss: 3.3766e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.8467e-04 - val_loss: 3.6658e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.0378e-04 - val_loss: 3.2046e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 6.3534e-04 - val_loss: 4.1256e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.9982e-04 - val_loss: 4.0270e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 5.6772e-04 - val_loss: 3.4917e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.4578e-04 - val_loss: 4.4592e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.4893e-04 - val_loss: 3.2047e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.2242e-04 - val_loss: 3.9515e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.9683e-04 - val_loss: 3.3367e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.3563e-04 - val_loss: 3.3237e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.5638e-04 - val_loss: 3.6350e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.3986e-04 - val_loss: 3.0864e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.2421e-04 - val_loss: 3.1259e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.9660e-04 - val_loss: 3.7722e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.1167e-04 - val_loss: 3.9932e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.7661e-04 - val_loss: 4.5390e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.7504e-04 - val_loss: 3.4487e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 6.7039e-04 - val_loss: 3.0633e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 7.0260e-04 - val_loss: 3.1600e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 6.9807e-04 - val_loss: 3.0133e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.1960e-04 - val_loss: 3.1383e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 5.4382e-04 - val_loss: 3.0924e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 6.3882e-04 - val_loss: 3.4263e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.6881e-04 - val_loss: 4.3818e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.7233e-04 - val_loss: 3.0400e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 6.5833e-04 - val_loss: 3.1517e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 5.9800e-04 - val_loss: 3.3573e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.2141e-04 - val_loss: 2.9639e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.3137e-04 - val_loss: 3.4053e-04\n",
            "Final loss: 0.000620\n",
            "Training data points: 500\n",
            "\n",
            "Making predictions using last 50 price points\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7963f79052d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Regime-Based LSTM Analysis\n",
            "--------------------------------------------------\n",
            "Current Price: $266.86\n",
            "High Volatility Regime Prediction: $267.29 (0.16% change)\n",
            "Low Volatility Regime Prediction: $267.32 (0.17% change)\n",
            "\n",
            "Stored Regime Characteristics:\n",
            "\n",
            "high_vol_uptrend:\n",
            "  volatility: high\n",
            "  trend: upward\n",
            "  volume: above_average\n",
            "\n",
            "low_vol_sideways:\n",
            "  volatility: low\n",
            "  trend: sideways\n",
            "  volume: below_average\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d44dff01ab1c>:193: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import json\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define prediction function at module level\n",
        "@tf.function(reduce_retracing=True, jit_compile=True)\n",
        "def make_prediction(model, data):\n",
        "    return model(data, training=False)\n",
        "\n",
        "class RegimeLSTM:\n",
        "    def __init__(self, lookback=50):\n",
        "        self.lookback = lookback\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.models = {}\n",
        "        self.regime_metadata = {}\n",
        "\n",
        "    def create_model(self):\n",
        "        \"\"\"Create model using functional API\"\"\"\n",
        "        inputs = Input(shape=(self.lookback, 1))\n",
        "        lstm_out = LSTM(50)(inputs)\n",
        "        outputs = Dense(1)(lstm_out)\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "    def prepare_data(self, prices, for_prediction=False):\n",
        "        \"\"\"Prepare data with validation and convert to tensor\"\"\"\n",
        "        if for_prediction:\n",
        "            if len(prices) != self.lookback:\n",
        "                raise ValueError(f\"For prediction, need exactly {self.lookback} price points, got {len(prices)}\")\n",
        "            scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
        "            # Convert to tensor with explicit shape\n",
        "            return tf.convert_to_tensor(scaled_data.reshape(1, self.lookback, 1), dtype=tf.float32), None\n",
        "        else:\n",
        "            if len(prices) < self.lookback + 1:\n",
        "                raise ValueError(f\"For training, need at least {self.lookback + 1} price points, got {len(prices)}\")\n",
        "\n",
        "            scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
        "            X, y = [], []\n",
        "            for i in range(self.lookback, len(scaled_data)):\n",
        "                X.append(scaled_data[i-self.lookback:i])\n",
        "                y.append(scaled_data[i])\n",
        "            # Convert to tensors with explicit shapes\n",
        "            X_tensor = tf.convert_to_tensor(np.array(X), dtype=tf.float32)\n",
        "            y_tensor = tf.convert_to_tensor(np.array(y), dtype=tf.float32)\n",
        "            return X_tensor, y_tensor\n",
        "\n",
        "    def train_regime(self, prices, regime_name, regime_characteristics):\n",
        "        \"\"\"Train and save model with error handling\"\"\"\n",
        "        try:\n",
        "            X, y = self.prepare_data(prices, for_prediction=False)\n",
        "\n",
        "            # Calculate appropriate batch size\n",
        "            batch_size = min(32, len(X))\n",
        "\n",
        "            # Create and train model\n",
        "            model = self.create_model()\n",
        "\n",
        "            print(f\"\\nTraining {regime_name} model...\")\n",
        "            print(f\"Training data shape: {X.shape}\")\n",
        "\n",
        "            history = model.fit(\n",
        "                X, y,\n",
        "                epochs=50,\n",
        "                batch_size=batch_size,\n",
        "                validation_split=0.2,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            # Create save directory\n",
        "            save_dir = Path(\"regime_models\")\n",
        "            save_dir.mkdir(exist_ok=True)\n",
        "\n",
        "            # Save model in .keras format\n",
        "            model_path = save_dir / f\"{regime_name}_model.keras\"\n",
        "            metadata_path = save_dir / f\"{regime_name}_metadata.json\"\n",
        "\n",
        "            model.save(model_path)\n",
        "\n",
        "            # Save metadata\n",
        "            metadata = {\n",
        "                \"regime_name\": regime_name,\n",
        "                \"characteristics\": regime_characteristics,\n",
        "                \"training_loss\": float(history.history['loss'][-1]),\n",
        "                \"data_points\": len(prices),\n",
        "                \"lookback\": self.lookback,\n",
        "                \"scaler_params\": {\n",
        "                    \"scale_\": self.scaler.scale_.tolist(),\n",
        "                    \"min_\": self.scaler.min_.tolist(),\n",
        "                }\n",
        "            }\n",
        "\n",
        "            with open(metadata_path, 'w') as f:\n",
        "                json.dump(metadata, f, indent=4)\n",
        "\n",
        "            self.models[regime_name] = model\n",
        "            self.regime_metadata[regime_name] = metadata\n",
        "\n",
        "            print(f\"Final loss: {history.history['loss'][-1]:.6f}\")\n",
        "            print(f\"Training data points: {len(prices)}\")\n",
        "\n",
        "            return model, metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error training regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def predict_with_regime(self, prices, regime_name):\n",
        "        \"\"\"Make predictions with optimized TensorFlow handling\"\"\"\n",
        "        try:\n",
        "            if regime_name not in self.models:\n",
        "                self.load_regime_model(regime_name)\n",
        "\n",
        "            if len(prices) != self.lookback:\n",
        "                prices = prices[-self.lookback:]\n",
        "                print(f\"Adjusted input to last {self.lookback} prices\")\n",
        "\n",
        "            # Prepare data as tensor\n",
        "            X, _ = self.prepare_data(prices, for_prediction=True)\n",
        "\n",
        "            # Make prediction using global function\n",
        "            prediction = make_prediction(self.models[regime_name], X)\n",
        "\n",
        "            # Convert to numpy and inverse transform\n",
        "            prediction_np = prediction.numpy()\n",
        "            prediction_orig = self.scaler.inverse_transform(prediction_np)\n",
        "\n",
        "            return float(prediction_orig[0][0])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error predicting with regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def load_regime_model(self, regime_name):\n",
        "        \"\"\"Load a pre-trained model for a specific regime\"\"\"\n",
        "        try:\n",
        "            save_dir = Path(\"regime_models\")\n",
        "            model_path = save_dir / f\"{regime_name}_model.keras\"\n",
        "            metadata_path = save_dir / f\"{regime_name}_metadata.json\"\n",
        "\n",
        "            if not model_path.exists():\n",
        "                raise FileNotFoundError(f\"No saved model found for regime {regime_name}\")\n",
        "\n",
        "            # Load model\n",
        "            model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "            # Load metadata\n",
        "            with open(metadata_path, 'r') as f:\n",
        "                metadata = json.load(f)\n",
        "\n",
        "            # Restore scaler parameters\n",
        "            self.scaler.scale_ = np.array(metadata['scaler_params']['scale_'])\n",
        "            self.scaler.min_ = np.array(metadata['scaler_params']['min_'])\n",
        "\n",
        "            self.models[regime_name] = model\n",
        "            self.regime_metadata[regime_name] = metadata\n",
        "\n",
        "            return model, metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Fetching SPY data...\")\n",
        "        df = yf.download('SPY', start='2014-01-01', end='2017-12-31')\n",
        "        if df.empty:\n",
        "            raise ValueError(\"No data downloaded\")\n",
        "\n",
        "        print(f\"Downloaded {len(df)} days of data\")\n",
        "\n",
        "        # Create regime classifier\n",
        "        regime_lstm = RegimeLSTM(lookback=50)\n",
        "\n",
        "        # Define example regimes\n",
        "        regimes = {\n",
        "            \"high_vol_uptrend\": {\n",
        "                \"volatility\": \"high\",\n",
        "                \"trend\": \"upward\",\n",
        "                \"volume\": \"above_average\"\n",
        "            },\n",
        "            \"low_vol_sideways\": {\n",
        "                \"volatility\": \"low\",\n",
        "                \"trend\": \"sideways\",\n",
        "                \"volume\": \"below_average\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(\"\\nTraining regime models...\")\n",
        "\n",
        "        # Train models\n",
        "        high_vol_period = df['Close'].values[:500]\n",
        "        model_high_vol, metadata_high_vol = regime_lstm.train_regime(\n",
        "            high_vol_period,\n",
        "            \"high_vol_uptrend\",\n",
        "            regimes[\"high_vol_uptrend\"]\n",
        "        )\n",
        "\n",
        "        low_vol_period = df['Close'].values[500:1000]\n",
        "        model_low_vol, metadata_low_vol = regime_lstm.train_regime(\n",
        "            low_vol_period,\n",
        "            \"low_vol_sideways\",\n",
        "            regimes[\"low_vol_sideways\"]\n",
        "        )\n",
        "\n",
        "        # Get exactly lookback days for prediction\n",
        "        recent_prices = df['Close'].values[-regime_lstm.lookback:]\n",
        "        print(f\"\\nMaking predictions using last {len(recent_prices)} price points\")\n",
        "\n",
        "        prediction_high_vol = regime_lstm.predict_with_regime(\n",
        "            recent_prices,\n",
        "            \"high_vol_uptrend\"\n",
        "        )\n",
        "\n",
        "        prediction_low_vol = regime_lstm.predict_with_regime(\n",
        "            recent_prices,\n",
        "            \"low_vol_sideways\"\n",
        "        )\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\nRegime-Based LSTM Analysis\")\n",
        "        print(\"-\" * 50)\n",
        "        current_price = float(df['Close'].values[-1])\n",
        "        print(f\"Current Price: ${current_price:.2f}\")\n",
        "        print(f\"High Volatility Regime Prediction: ${prediction_high_vol:.2f} ({((prediction_high_vol/current_price) - 1)*100:.2f}% change)\")\n",
        "        print(f\"Low Volatility Regime Prediction: ${prediction_low_vol:.2f} ({((prediction_low_vol/current_price) - 1)*100:.2f}% change)\")\n",
        "\n",
        "        # Print regime characteristics\n",
        "        print(\"\\nStored Regime Characteristics:\")\n",
        "        for regime_name, metadata in regime_lstm.regime_metadata.items():\n",
        "            print(f\"\\n{regime_name}:\")\n",
        "            for key, value in metadata['characteristics'].items():\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIQB2d2L2R4g",
        "outputId": "781306fb-3eb0-49b8-a141-9b1f80d5578d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching SPY data...\n",
            "Downloaded 1007 days of data\n",
            "\n",
            "Training regime models...\n",
            "\n",
            "Training high_vol_uptrend model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2181 - val_loss: 0.0701\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0240 - val_loss: 0.0184\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0131 - val_loss: 0.0150\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0057 - val_loss: 0.0139\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0050 - val_loss: 0.0134\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0046 - val_loss: 0.0139\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0041 - val_loss: 0.0137\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0045 - val_loss: 0.0136\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0042 - val_loss: 0.0137\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0138\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0043 - val_loss: 0.0134\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0042 - val_loss: 0.0137\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0046 - val_loss: 0.0137\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0130\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0142\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0127\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0141\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0127\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0042 - val_loss: 0.0128\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0041 - val_loss: 0.0131\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0035 - val_loss: 0.0122\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0127\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0037 - val_loss: 0.0126\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0123\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0125\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0037 - val_loss: 0.0120\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0038 - val_loss: 0.0118\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0035 - val_loss: 0.0113\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0038 - val_loss: 0.0114\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0033 - val_loss: 0.0114\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0035 - val_loss: 0.0113\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0034 - val_loss: 0.0113\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0033 - val_loss: 0.0109\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0033 - val_loss: 0.0107\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0036 - val_loss: 0.0117\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0037 - val_loss: 0.0110\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0033 - val_loss: 0.0107\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0034 - val_loss: 0.0101\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0034 - val_loss: 0.0101\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0033 - val_loss: 0.0103\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0032 - val_loss: 0.0099\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0035 - val_loss: 0.0107\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0035 - val_loss: 0.0105\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0031 - val_loss: 0.0096\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0030 - val_loss: 0.0097\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0030 - val_loss: 0.0099\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0029 - val_loss: 0.0097\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0030 - val_loss: 0.0093\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0033 - val_loss: 0.0096\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0028 - val_loss: 0.0098\n",
            "Final loss: 0.002827\n",
            "Training data points: 500\n",
            "\n",
            "Training low_vol_sideways model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.2626 - val_loss: 0.1146\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0141 - val_loss: 0.0055\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0050 - val_loss: 0.0317\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0032\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0029 - val_loss: 0.0098\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0022 - val_loss: 0.0055\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0018 - val_loss: 0.0034\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0022\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 9.0048e-04 - val_loss: 6.1148e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.6788e-04 - val_loss: 6.7485e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.5636e-04 - val_loss: 5.6269e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 8.2632e-04 - val_loss: 4.0064e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.5847e-04 - val_loss: 4.1185e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.5505e-04 - val_loss: 8.5784e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.9958e-04 - val_loss: 9.2936e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 4.0764e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.9472e-04 - val_loss: 5.7555e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 9.3003e-04 - val_loss: 4.4666e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.0967e-04 - val_loss: 3.8839e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 8.6181e-04 - val_loss: 3.8841e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.9187e-04 - val_loss: 4.4390e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 8.2106e-04 - val_loss: 3.8032e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.6988e-04 - val_loss: 4.8751e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 8.1558e-04 - val_loss: 4.6574e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.7473e-04 - val_loss: 5.5454e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 5.6654e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 8.2306e-04 - val_loss: 4.7060e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 9.0969e-04 - val_loss: 4.4602e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.4217e-04 - val_loss: 4.9550e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.6608e-04 - val_loss: 3.7785e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 8.2236e-04 - val_loss: 5.3196e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.2778e-04 - val_loss: 3.9551e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.6816e-04 - val_loss: 4.7596e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 8.9389e-04 - val_loss: 7.4266e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 3.7169e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 8.1912e-04 - val_loss: 3.6939e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.5293e-04 - val_loss: 3.7728e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.0783e-04 - val_loss: 3.6523e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 7.6608e-04 - val_loss: 3.7302e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.1541e-04 - val_loss: 4.7052e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.8500e-04 - val_loss: 3.6285e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.0764e-04 - val_loss: 4.0549e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.4807e-04 - val_loss: 4.5397e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.9943e-04 - val_loss: 3.5917e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.8636e-04 - val_loss: 3.3781e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 7.1648e-04 - val_loss: 4.1612e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.8051e-04 - val_loss: 4.7511e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.1278e-04 - val_loss: 3.7172e-04\n",
            "Final loss: 0.000757\n",
            "Training data points: 500\n",
            "\n",
            "Making predictions using last 50 price points\n",
            "\n",
            "Regime-Based LSTM Analysis\n",
            "--------------------------------------------------\n",
            "Current Price: $266.86\n",
            "High Volatility Regime Prediction: $267.32 (0.17% change)\n",
            "Low Volatility Regime Prediction: $267.48 (0.23% change)\n",
            "\n",
            "Stored Regime Characteristics:\n",
            "\n",
            "high_vol_uptrend:\n",
            "  volatility: high\n",
            "  trend: upward\n",
            "  volume: above_average\n",
            "\n",
            "low_vol_sideways:\n",
            "  volatility: low\n",
            "  trend: sideways\n",
            "  volume: below_average\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b356cbf4c46b>:230: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import json\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "class RegimeLSTM:\n",
        "    def __init__(self, lookback=50):\n",
        "        self.lookback = lookback\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.models = {}\n",
        "        self.regime_metadata = {}\n",
        "        self.training_history = {}\n",
        "\n",
        "    def create_model(self):\n",
        "        \"\"\"Create model using functional API\"\"\"\n",
        "        inputs = Input(shape=(self.lookback, 1))\n",
        "        lstm_out = LSTM(50)(inputs)\n",
        "        outputs = Dense(1)(lstm_out)\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "    def prepare_data(self, prices, for_prediction=False):\n",
        "        \"\"\"Prepare data with validation and convert to tensor\"\"\"\n",
        "        if for_prediction:\n",
        "            if len(prices) != self.lookback:\n",
        "                raise ValueError(f\"For prediction, need exactly {self.lookback} price points, got {len(prices)}\")\n",
        "            scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
        "            return tf.convert_to_tensor(scaled_data.reshape(1, self.lookback, 1), dtype=tf.float32), None\n",
        "        else:\n",
        "            if len(prices) < self.lookback + 1:\n",
        "                raise ValueError(f\"For training, need at least {self.lookback + 1} price points, got {len(prices)}\")\n",
        "\n",
        "            scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
        "            X, y = [], []\n",
        "            for i in range(self.lookback, len(scaled_data)):\n",
        "                X.append(scaled_data[i-self.lookback:i])\n",
        "                y.append(scaled_data[i])\n",
        "            X_tensor = tf.convert_to_tensor(np.array(X), dtype=tf.float32)\n",
        "            y_tensor = tf.convert_to_tensor(np.array(y), dtype=tf.float32)\n",
        "            return X_tensor, y_tensor\n",
        "\n",
        "    def train_regime(self, prices, regime_name, regime_characteristics):\n",
        "        \"\"\"Train and save model with error handling\"\"\"\n",
        "        try:\n",
        "            X, y = self.prepare_data(prices, for_prediction=False)\n",
        "\n",
        "            batch_size = min(32, len(X))\n",
        "            model = self.create_model()\n",
        "\n",
        "            print(f\"\\nTraining {regime_name} model...\")\n",
        "            print(f\"Training data shape: {X.shape}\")\n",
        "\n",
        "            history = model.fit(\n",
        "                X, y,\n",
        "                epochs=50,\n",
        "                batch_size=batch_size,\n",
        "                validation_split=0.2,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            # Store training history\n",
        "            self.training_history[regime_name] = history\n",
        "\n",
        "            save_dir = Path(\"regime_models\")\n",
        "            save_dir.mkdir(exist_ok=True)\n",
        "\n",
        "            model_path = save_dir / f\"{regime_name}_model.keras\"\n",
        "            metadata_path = save_dir / f\"{regime_name}_metadata.json\"\n",
        "\n",
        "            model.save(model_path)\n",
        "\n",
        "            metadata = {\n",
        "                \"regime_name\": regime_name,\n",
        "                \"characteristics\": regime_characteristics,\n",
        "                \"training_loss\": float(history.history['loss'][-1]),\n",
        "                \"data_points\": len(prices),\n",
        "                \"lookback\": self.lookback,\n",
        "                \"scaler_params\": {\n",
        "                    \"scale_\": self.scaler.scale_.tolist(),\n",
        "                    \"min_\": self.scaler.min_.tolist(),\n",
        "                }\n",
        "            }\n",
        "\n",
        "            with open(metadata_path, 'w') as f:\n",
        "                json.dump(metadata, f, indent=4)\n",
        "\n",
        "            self.models[regime_name] = model\n",
        "            self.regime_metadata[regime_name] = metadata\n",
        "\n",
        "            return model, metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error training regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def predict_with_regime(self, prices, regime_name):\n",
        "        \"\"\"Make predictions with error handling\"\"\"\n",
        "        try:\n",
        "            if regime_name not in self.models:\n",
        "                self.load_regime_model(regime_name)\n",
        "\n",
        "            if len(prices) != self.lookback:\n",
        "                prices = prices[-self.lookback:]\n",
        "\n",
        "            X, _ = self.prepare_data(prices, for_prediction=True)\n",
        "            prediction = self.models[regime_name].predict(X, verbose=0)\n",
        "            prediction_orig = self.scaler.inverse_transform(prediction)\n",
        "\n",
        "            return float(prediction_orig[0][0])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error predicting with regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def train_with_cross_validation(self, prices, regime_name, regime_characteristics, n_splits=5):\n",
        "        \"\"\"Train with time series cross-validation\"\"\"\n",
        "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "        cv_scores = []\n",
        "        cv_predictions = []\n",
        "\n",
        "        print(f\"\\nPerforming {n_splits}-fold time series cross-validation for {regime_name}\")\n",
        "\n",
        "        min_required = self.lookback * (n_splits + 1)\n",
        "        if len(prices) < min_required:\n",
        "            raise ValueError(f\"Need at least {min_required} data points for {n_splits}-fold validation\")\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(tscv.split(prices)):\n",
        "            print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
        "\n",
        "            train_prices = prices[train_idx]\n",
        "            val_prices = prices[val_idx]\n",
        "\n",
        "            if len(val_prices) <= self.lookback:\n",
        "                print(f\"Skipping fold {fold + 1} - insufficient validation data\")\n",
        "                continue\n",
        "\n",
        "            X_train, y_train = self.prepare_data(train_prices, for_prediction=False)\n",
        "\n",
        "            try:\n",
        "                X_val, y_val = self.prepare_data(val_prices, for_prediction=False)\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping fold {fold + 1}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            model = self.create_model()\n",
        "            history = model.fit(\n",
        "                X_train, y_train,\n",
        "                epochs=50,\n",
        "                batch_size=32,\n",
        "                validation_data=(X_val, y_val),\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            val_score = model.evaluate(X_val, y_val, verbose=0)\n",
        "            cv_scores.append(val_score)\n",
        "\n",
        "            val_pred = model.predict(X_val, verbose=0)\n",
        "            cv_predictions.append({\n",
        "                'true': self.scaler.inverse_transform(y_val.numpy()),\n",
        "                'pred': self.scaler.inverse_transform(val_pred)\n",
        "            })\n",
        "\n",
        "        return cv_scores, cv_predictions\n",
        "\n",
        "    def visualize_training(self, history, regime_name):\n",
        "        \"\"\"Create interactive training visualization\"\"\"\n",
        "        fig = make_subplots(rows=2, cols=1,\n",
        "                           subplot_titles=('Training & Validation Loss',\n",
        "                                         'Learning Rate'))\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Scatter(y=history.history['loss'],\n",
        "                      name='Training Loss',\n",
        "                      line=dict(color='blue')),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        if 'val_loss' in history.history:\n",
        "            fig.add_trace(\n",
        "                go.Scatter(y=history.history['val_loss'],\n",
        "                          name='Validation Loss',\n",
        "                          line=dict(color='red')),\n",
        "                row=1, col=1\n",
        "            )\n",
        "\n",
        "        if 'lr' in history.history:\n",
        "            fig.add_trace(\n",
        "                go.Scatter(y=history.history['lr'],\n",
        "                          name='Learning Rate',\n",
        "                          line=dict(color='green')),\n",
        "                row=2, col=1\n",
        "            )\n",
        "\n",
        "        fig.update_layout(height=800,\n",
        "                         title_text=f\"Training Progress for {regime_name}\",\n",
        "                         showlegend=True)\n",
        "\n",
        "        return fig\n",
        "\n",
        "def enhanced_main():\n",
        "    try:\n",
        "        print(\"Fetching SPY data...\")\n",
        "        df = yf.download('SPY', start='2014-01-01', end='2017-12-31')\n",
        "\n",
        "        regime_lstm = RegimeLSTM(lookback=50)\n",
        "\n",
        "        regimes = {\n",
        "            \"high_vol_uptrend\": {\n",
        "                \"volatility\": \"high\",\n",
        "                \"trend\": \"upward\",\n",
        "                \"volume\": \"above_average\"\n",
        "            },\n",
        "            \"low_vol_sideways\": {\n",
        "                \"volatility\": \"low\",\n",
        "                \"trend\": \"sideways\",\n",
        "                \"volume\": \"below_average\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        predictions_dict = {}\n",
        "\n",
        "        for regime_name, characteristics in regimes.items():\n",
        "            print(f\"\\nProcessing {regime_name}...\")\n",
        "            train_data = df['Close'].values[:500]\n",
        "\n",
        "            # Perform cross-validation\n",
        "            cv_scores, cv_predictions = regime_lstm.train_with_cross_validation(\n",
        "                train_data, regime_name, characteristics\n",
        "            )\n",
        "\n",
        "            print(f\"\\n{regime_name} Cross-Validation Results:\")\n",
        "            print(f\"Mean MSE: {np.mean(cv_scores):.6f}\")\n",
        "            print(f\"Std MSE: {np.std(cv_scores):.6f}\")\n",
        "\n",
        "            # Train final model\n",
        "            model, metadata = regime_lstm.train_regime(\n",
        "                train_data,\n",
        "                regime_name,\n",
        "                characteristics\n",
        "            )\n",
        "\n",
        "            # Visualize training\n",
        "            training_viz = regime_lstm.visualize_training(\n",
        "                regime_lstm.training_history[regime_name],\n",
        "                regime_name\n",
        "            )\n",
        "            training_viz.show()\n",
        "\n",
        "            # Make prediction\n",
        "            recent_prices = df['Close'].values[-regime_lstm.lookback:]\n",
        "            prediction = regime_lstm.predict_with_regime(\n",
        "                recent_prices,\n",
        "                regime_name\n",
        "            )\n",
        "            predictions_dict[regime_name] = prediction\n",
        "\n",
        "        # Print results\n",
        "        current_price = float(df['Close'].values[-1])\n",
        "        print(\"\\nPrediction Summary:\")\n",
        "        print(\"-\" * 50)\n",
        "        for regime_name, pred in predictions_dict.items():\n",
        "            change_pct = ((pred/current_price) - 1) * 100\n",
        "            print(f\"{regime_name}:\")\n",
        "            print(f\"  Prediction: ${pred:.2f}\")\n",
        "            print(f\"  Expected Change: {change_pct:.2f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in enhanced execution: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    enhanced_main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "99omPuBA4jAI",
        "outputId": "58a7415c-b636-42a8-bd07-7169b114db80"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching SPY data...\n",
            "\n",
            "Processing high_vol_uptrend...\n",
            "\n",
            "Performing 5-fold time series cross-validation for high_vol_uptrend\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - loss: 0.7020 - val_loss: 0.4358\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5486 - val_loss: 0.3366\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4153 - val_loss: 0.2486\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2966 - val_loss: 0.1693\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1865 - val_loss: 0.1004\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0927 - val_loss: 0.0516\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0276 - val_loss: 0.0475\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0236 - val_loss: 0.0789\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0606 - val_loss: 0.0729\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0540 - val_loss: 0.0528\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0276 - val_loss: 0.0413\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0158 - val_loss: 0.0397\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0164 - val_loss: 0.0425\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0204 - val_loss: 0.0453\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0256 - val_loss: 0.0467\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0276 - val_loss: 0.0458\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0265 - val_loss: 0.0433\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0235 - val_loss: 0.0405\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0189 - val_loss: 0.0384\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0169 - val_loss: 0.0375\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0153 - val_loss: 0.0376\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0145 - val_loss: 0.0380\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0151 - val_loss: 0.0385\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0156 - val_loss: 0.0388\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0161 - val_loss: 0.0386\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0160 - val_loss: 0.0380\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0155 - val_loss: 0.0374\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0133 - val_loss: 0.0369\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0143 - val_loss: 0.0370\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0153 - val_loss: 0.0374\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0166 - val_loss: 0.0378\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0175 - val_loss: 0.0377\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0166 - val_loss: 0.0373\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0164 - val_loss: 0.0370\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0160 - val_loss: 0.0367\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0150 - val_loss: 0.0365\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0140 - val_loss: 0.0367\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0149 - val_loss: 0.0368\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0148 - val_loss: 0.0370\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0147 - val_loss: 0.0372\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0150 - val_loss: 0.0377\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0156 - val_loss: 0.0385\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0161 - val_loss: 0.0391\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0156 - val_loss: 0.0384\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0157 - val_loss: 0.0372\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0150 - val_loss: 0.0365\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0146 - val_loss: 0.0362\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0141 - val_loss: 0.0362\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0145 - val_loss: 0.0361\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0148 - val_loss: 0.0361\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.4892 - val_loss: 0.4944\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2656 - val_loss: 0.2303\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1052 - val_loss: 0.0582\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0190 - val_loss: 0.0252\n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0249 - val_loss: 0.0355\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0247 - val_loss: 0.0169\n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0076 - val_loss: 0.0218\n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0084 - val_loss: 0.0286\n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0113 - val_loss: 0.0274\n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0092 - val_loss: 0.0216\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0076 - val_loss: 0.0171\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0067 - val_loss: 0.0158\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0071 - val_loss: 0.0157\n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0064 - val_loss: 0.0159\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0055 - val_loss: 0.0168\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0061 - val_loss: 0.0178\n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0072 - val_loss: 0.0180\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0064 - val_loss: 0.0172\n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0059 - val_loss: 0.0165\n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0053 - val_loss: 0.0163\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0050 - val_loss: 0.0162\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0058 - val_loss: 0.0166\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0056 - val_loss: 0.0169\n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0055 - val_loss: 0.0169\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0060 - val_loss: 0.0167\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0058 - val_loss: 0.0164\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0058 - val_loss: 0.0163\n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0058 - val_loss: 0.0164\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0057 - val_loss: 0.0165\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0054 - val_loss: 0.0165\n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0054 - val_loss: 0.0165\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0054 - val_loss: 0.0163\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0058 - val_loss: 0.0162\n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0062 - val_loss: 0.0163\n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0057 - val_loss: 0.0165\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0056 - val_loss: 0.0166\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0060 - val_loss: 0.0163\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0053 - val_loss: 0.0161\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0054 - val_loss: 0.0161\n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0054 - val_loss: 0.0163\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0047 - val_loss: 0.0164\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0050 - val_loss: 0.0164\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0057 - val_loss: 0.0162\n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0052 - val_loss: 0.0160\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0052 - val_loss: 0.0161\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0047 - val_loss: 0.0162\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0046 - val_loss: 0.0162\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0051 - val_loss: 0.0163\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0052 - val_loss: 0.0160\n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0048 - val_loss: 0.0159\n",
            "\n",
            "Fold 3/5\n",
            "Epoch 1/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.3076 - val_loss: 0.1705\n",
            "Epoch 2/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0688 - val_loss: 0.0254\n",
            "Epoch 3/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0268 - val_loss: 0.0165\n",
            "Epoch 4/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0097 - val_loss: 0.0252\n",
            "Epoch 5/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0106 - val_loss: 0.0221\n",
            "Epoch 6/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0089 - val_loss: 0.0160\n",
            "Epoch 7/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0069 - val_loss: 0.0156\n",
            "Epoch 8/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0075 - val_loss: 0.0175\n",
            "Epoch 9/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0068 - val_loss: 0.0181\n",
            "Epoch 10/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0069 - val_loss: 0.0162\n",
            "Epoch 11/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0070 - val_loss: 0.0155\n",
            "Epoch 12/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0076 - val_loss: 0.0166\n",
            "Epoch 13/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0067 - val_loss: 0.0165\n",
            "Epoch 14/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0064 - val_loss: 0.0159\n",
            "Epoch 15/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0057 - val_loss: 0.0155\n",
            "Epoch 16/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0062 - val_loss: 0.0160\n",
            "Epoch 17/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0064 - val_loss: 0.0162\n",
            "Epoch 18/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0062 - val_loss: 0.0158\n",
            "Epoch 19/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0054 - val_loss: 0.0157\n",
            "Epoch 20/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0058 - val_loss: 0.0166\n",
            "Epoch 21/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0053 - val_loss: 0.0163\n",
            "Epoch 22/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0061 - val_loss: 0.0153\n",
            "Epoch 23/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0045 - val_loss: 0.0165\n",
            "Epoch 24/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0055 - val_loss: 0.0158\n",
            "Epoch 25/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0057 - val_loss: 0.0159\n",
            "Epoch 26/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0050 - val_loss: 0.0156\n",
            "Epoch 27/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0060 - val_loss: 0.0163\n",
            "Epoch 28/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0054 - val_loss: 0.0153\n",
            "Epoch 29/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0057 - val_loss: 0.0162\n",
            "Epoch 30/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0051 - val_loss: 0.0156\n",
            "Epoch 31/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0053 - val_loss: 0.0159\n",
            "Epoch 32/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0048 - val_loss: 0.0160\n",
            "Epoch 33/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0050 - val_loss: 0.0155\n",
            "Epoch 34/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - val_loss: 0.0158\n",
            "Epoch 35/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0051 - val_loss: 0.0159\n",
            "Epoch 36/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0055 - val_loss: 0.0163\n",
            "Epoch 37/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0052 - val_loss: 0.0156\n",
            "Epoch 38/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0046 - val_loss: 0.0163\n",
            "Epoch 39/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0050 - val_loss: 0.0157\n",
            "Epoch 40/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0049 - val_loss: 0.0164\n",
            "Epoch 41/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0047 - val_loss: 0.0167\n",
            "Epoch 42/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0052 - val_loss: 0.0160\n",
            "Epoch 43/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0041 - val_loss: 0.0176\n",
            "Epoch 44/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0047 - val_loss: 0.0168\n",
            "Epoch 45/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0046 - val_loss: 0.0168\n",
            "Epoch 46/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0178\n",
            "Epoch 47/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0039 - val_loss: 0.0171\n",
            "Epoch 48/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0045 - val_loss: 0.0181\n",
            "Epoch 49/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0043 - val_loss: 0.0169\n",
            "Epoch 50/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0048 - val_loss: 0.0177\n",
            "\n",
            "Fold 4/5\n",
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.3917 - val_loss: 0.1191\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0400 - val_loss: 0.1223\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0281 - val_loss: 0.0491\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0105 - val_loss: 0.0497\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0092 - val_loss: 0.0518\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - val_loss: 0.0534\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0072 - val_loss: 0.0480\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0070 - val_loss: 0.0496\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0058 - val_loss: 0.0505\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0053 - val_loss: 0.0489\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0061 - val_loss: 0.0490\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0058 - val_loss: 0.0495\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0060 - val_loss: 0.0493\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0061 - val_loss: 0.0490\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0053 - val_loss: 0.0488\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0055 - val_loss: 0.0491\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0050 - val_loss: 0.0483\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0055 - val_loss: 0.0489\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0051 - val_loss: 0.0475\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0047 - val_loss: 0.0482\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0054 - val_loss: 0.0477\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0047 - val_loss: 0.0476\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0048 - val_loss: 0.0471\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0054 - val_loss: 0.0478\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0046 - val_loss: 0.0464\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0051 - val_loss: 0.0476\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0048 - val_loss: 0.0461\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0051 - val_loss: 0.0461\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0050 - val_loss: 0.0469\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0050 - val_loss: 0.0450\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0045 - val_loss: 0.0461\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0046 - val_loss: 0.0453\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0044 - val_loss: 0.0453\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - val_loss: 0.0449\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0047 - val_loss: 0.0447\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0044 - val_loss: 0.0443\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0046 - val_loss: 0.0438\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0042 - val_loss: 0.0446\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0044 - val_loss: 0.0427\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0440\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0427\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0044 - val_loss: 0.0430\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0428\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0046 - val_loss: 0.0420\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0421\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0045 - val_loss: 0.0422\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - val_loss: 0.0414\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0041 - val_loss: 0.0419\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0405\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0410\n",
            "\n",
            "Fold 5/5\n",
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.6660 - val_loss: 0.2514\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1024 - val_loss: 0.0682\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0333 - val_loss: 0.0184\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0161 - val_loss: 0.0126\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0085 - val_loss: 0.0140\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0080 - val_loss: 0.0125\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0092 - val_loss: 0.0131\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0065 - val_loss: 0.0128\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0085 - val_loss: 0.0127\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0075 - val_loss: 0.0132\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0070 - val_loss: 0.0129\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0076 - val_loss: 0.0135\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0068 - val_loss: 0.0133\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0063 - val_loss: 0.0128\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0064 - val_loss: 0.0140\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0071 - val_loss: 0.0127\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0062 - val_loss: 0.0145\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0083 - val_loss: 0.0137\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0069 - val_loss: 0.0129\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0055 - val_loss: 0.0133\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0060 - val_loss: 0.0145\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0059 - val_loss: 0.0121\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0062 - val_loss: 0.0126\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0062 - val_loss: 0.0155\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - val_loss: 0.0125\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0052 - val_loss: 0.0125\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0054 - val_loss: 0.0134\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0048 - val_loss: 0.0127\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0063 - val_loss: 0.0146\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0070 - val_loss: 0.0130\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0058 - val_loss: 0.0128\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0059 - val_loss: 0.0134\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0051 - val_loss: 0.0131\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0061 - val_loss: 0.0132\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0055 - val_loss: 0.0137\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0053 - val_loss: 0.0120\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0060 - val_loss: 0.0154\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0051 - val_loss: 0.0123\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - val_loss: 0.0119\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0055 - val_loss: 0.0145\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0121\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0061 - val_loss: 0.0167\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0058 - val_loss: 0.0119\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - val_loss: 0.0125\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0146\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0058 - val_loss: 0.0119\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0052 - val_loss: 0.0134\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0053 - val_loss: 0.0122\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0061 - val_loss: 0.0132\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0050 - val_loss: 0.0127\n",
            "\n",
            "high_vol_uptrend Cross-Validation Results:\n",
            "Mean MSE: 0.024673\n",
            "Std MSE: 0.011536\n",
            "\n",
            "Training high_vol_uptrend model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.3837 - val_loss: 0.0233\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0292 - val_loss: 0.0184\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0150 - val_loss: 0.0166\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0073 - val_loss: 0.0203\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0070 - val_loss: 0.0161\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0066 - val_loss: 0.0176\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0056 - val_loss: 0.0164\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0056 - val_loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0065 - val_loss: 0.0168\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0053 - val_loss: 0.0170\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0049 - val_loss: 0.0164\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0050 - val_loss: 0.0171\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - val_loss: 0.0169\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0045 - val_loss: 0.0165\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0047 - val_loss: 0.0180\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0054 - val_loss: 0.0158\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - val_loss: 0.0179\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0043 - val_loss: 0.0157\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0156\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0053 - val_loss: 0.0173\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0049 - val_loss: 0.0155\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - val_loss: 0.0158\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0043 - val_loss: 0.0160\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0149\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0050 - val_loss: 0.0159\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - val_loss: 0.0150\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0048 - val_loss: 0.0153\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0048 - val_loss: 0.0161\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0147\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0158\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0046 - val_loss: 0.0146\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0046 - val_loss: 0.0149\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0137\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0048 - val_loss: 0.0155\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0045 - val_loss: 0.0144\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0050 - val_loss: 0.0136\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0042 - val_loss: 0.0135\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0041 - val_loss: 0.0135\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0041 - val_loss: 0.0149\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0048 - val_loss: 0.0134\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0040 - val_loss: 0.0127\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0041 - val_loss: 0.0128\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0040 - val_loss: 0.0148\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0127\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0040 - val_loss: 0.0129\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0132\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0037 - val_loss: 0.0123\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0038 - val_loss: 0.0128\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0042 - val_loss: 0.0119\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0040 - val_loss: 0.0130\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9f0151a7-02cd-47c5-9c4a-f144d3b4131b\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9f0151a7-02cd-47c5-9c4a-f144d3b4131b\")) {                    Plotly.newPlot(                        \"9f0151a7-02cd-47c5-9c4a-f144d3b4131b\",                        [{\"line\":{\"color\":\"blue\"},\"name\":\"Training Loss\",\"y\":[0.29092785716056824,0.029120953753590584,0.015419693663716316,0.008054896257817745,0.006703243590891361,0.006545959040522575,0.006034992169588804,0.00580391613766551,0.005637018010020256,0.005352165084332228,0.005334294401109219,0.005198813509196043,0.005115960258990526,0.005025714635848999,0.005002363119274378,0.0050901626236736774,0.005070921964943409,0.004992465954273939,0.005041230469942093,0.004979031626135111,0.004780819173902273,0.004858968313783407,0.004732308443635702,0.004647117108106613,0.004629687871783972,0.004571057856082916,0.004561827518045902,0.004670916590839624,0.0045473319478333,0.00450530368834734,0.004478892311453819,0.004412442445755005,0.004313428420573473,0.004512486048042774,0.004550467245280743,0.004362702835351229,0.0041963797993958,0.00414914870634675,0.004122944548726082,0.004390634596347809,0.004113748203963041,0.004197008907794952,0.00400167191401124,0.004158238414674997,0.004027029499411583,0.003926153294742107,0.003851956222206354,0.0038006699178367853,0.00387959904037416,0.0037308421451598406],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\"},\"name\":\"Validation Loss\",\"y\":[0.0232993233948946,0.018434084951877594,0.016614072024822235,0.020278021693229675,0.01606789417564869,0.017638282850384712,0.01644417643547058,0.01774568296968937,0.01681506261229515,0.017028577625751495,0.01644018478691578,0.017117464914917946,0.016892146319150925,0.01647348888218403,0.017960665747523308,0.01582196354866028,0.017949536442756653,0.015710845589637756,0.01558983325958252,0.017330646514892578,0.015471147373318672,0.015798313543200493,0.016020657494664192,0.014935050159692764,0.015918245539069176,0.01501513458788395,0.01526693906635046,0.016104910522699356,0.014694702811539173,0.015829987823963165,0.01457883883267641,0.014888640493154526,0.013747302815318108,0.015479364432394505,0.014386776834726334,0.013614049181342125,0.013525862246751785,0.01349191926419735,0.014919614419341087,0.013383959420025349,0.012723471038043499,0.012757317163050175,0.014768918044865131,0.012664275243878365,0.012869398109614849,0.013208312913775444,0.012337050400674343,0.012842243537306786,0.01191652100533247,0.01296917349100113],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training & Validation Loss\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Learning Rate\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Training Progress for high_vol_uptrend\"},\"height\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9f0151a7-02cd-47c5-9c4a-f144d3b4131b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing low_vol_sideways...\n",
            "\n",
            "Performing 5-fold time series cross-validation for low_vol_sideways\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321ms/step - loss: 0.8446 - val_loss: 0.5072\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.6461 - val_loss: 0.3771\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4666 - val_loss: 0.2658\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3197 - val_loss: 0.1714\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1917 - val_loss: 0.0963\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0898 - val_loss: 0.0489\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0258 - val_loss: 0.0464\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0225 - val_loss: 0.0802\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0635 - val_loss: 0.0850\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0692 - val_loss: 0.0655\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0446 - val_loss: 0.0473\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0241 - val_loss: 0.0392\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0158 - val_loss: 0.0383\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0159 - val_loss: 0.0396\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0184 - val_loss: 0.0406\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0205 - val_loss: 0.0405\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0203 - val_loss: 0.0395\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0192 - val_loss: 0.0382\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0176 - val_loss: 0.0373\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0158 - val_loss: 0.0369\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0143 - val_loss: 0.0367\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0150 - val_loss: 0.0366\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0147 - val_loss: 0.0367\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0146 - val_loss: 0.0369\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0147 - val_loss: 0.0373\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0149 - val_loss: 0.0376\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0149 - val_loss: 0.0376\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0155 - val_loss: 0.0376\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0143 - val_loss: 0.0374\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0155 - val_loss: 0.0370\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0150 - val_loss: 0.0367\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0147 - val_loss: 0.0364\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0147 - val_loss: 0.0362\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0141 - val_loss: 0.0360\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0147 - val_loss: 0.0360\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0146 - val_loss: 0.0359\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0146 - val_loss: 0.0360\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0146 - val_loss: 0.0362\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0147 - val_loss: 0.0365\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0143 - val_loss: 0.0367\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0146 - val_loss: 0.0366\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0148 - val_loss: 0.0363\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0144 - val_loss: 0.0360\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0145 - val_loss: 0.0358\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0147 - val_loss: 0.0358\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0141 - val_loss: 0.0359\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0142 - val_loss: 0.0357\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0147 - val_loss: 0.0356\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0146 - val_loss: 0.0355\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0141 - val_loss: 0.0354\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - loss: 0.4140 - val_loss: 0.4270\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2353 - val_loss: 0.1755\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0636 - val_loss: 0.0195\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0247 - val_loss: 0.0399\n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0262 - val_loss: 0.0189\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0067 - val_loss: 0.0359\n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0141 - val_loss: 0.0381\n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0143 - val_loss: 0.0264\n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0079 - val_loss: 0.0172\n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0069 - val_loss: 0.0162\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0083 - val_loss: 0.0161\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0077 - val_loss: 0.0178\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0062 - val_loss: 0.0200\n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0064 - val_loss: 0.0198\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0071 - val_loss: 0.0179\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0062 - val_loss: 0.0166\n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0062 - val_loss: 0.0165\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0059 - val_loss: 0.0173\n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0057 - val_loss: 0.0181\n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0059 - val_loss: 0.0179\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0058 - val_loss: 0.0171\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0058 - val_loss: 0.0171\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0055 - val_loss: 0.0170\n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0056 - val_loss: 0.0170\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0053 - val_loss: 0.0170\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0061 - val_loss: 0.0169\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0060 - val_loss: 0.0170\n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0059 - val_loss: 0.0171\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0054 - val_loss: 0.0168\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0058 - val_loss: 0.0170\n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0049 - val_loss: 0.0172\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0053 - val_loss: 0.0166\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0055 - val_loss: 0.0165\n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0049 - val_loss: 0.0166\n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0052 - val_loss: 0.0171\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0056 - val_loss: 0.0170\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0052 - val_loss: 0.0165\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0050 - val_loss: 0.0164\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0053 - val_loss: 0.0166\n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0058 - val_loss: 0.0169\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0053 - val_loss: 0.0165\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0055 - val_loss: 0.0162\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0056 - val_loss: 0.0164\n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0054 - val_loss: 0.0161\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0051 - val_loss: 0.0160\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0047 - val_loss: 0.0163\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0047 - val_loss: 0.0164\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0053 - val_loss: 0.0160\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0056 - val_loss: 0.0159\n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0049 - val_loss: 0.0157\n",
            "\n",
            "Fold 3/5\n",
            "Epoch 1/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.2851 - val_loss: 0.1123\n",
            "Epoch 2/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0404 - val_loss: 0.0541\n",
            "Epoch 3/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0341 - val_loss: 0.0172\n",
            "Epoch 4/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0102 - val_loss: 0.0320\n",
            "Epoch 5/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0133 - val_loss: 0.0202\n",
            "Epoch 6/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0078 - val_loss: 0.0153\n",
            "Epoch 7/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0079 - val_loss: 0.0155\n",
            "Epoch 8/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0066 - val_loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0077 - val_loss: 0.0179\n",
            "Epoch 10/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0068 - val_loss: 0.0154\n",
            "Epoch 11/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0068 - val_loss: 0.0157\n",
            "Epoch 12/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0060 - val_loss: 0.0161\n",
            "Epoch 13/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0064 - val_loss: 0.0157\n",
            "Epoch 14/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0057 - val_loss: 0.0155\n",
            "Epoch 15/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0064 - val_loss: 0.0157\n",
            "Epoch 16/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0058 - val_loss: 0.0160\n",
            "Epoch 17/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0058 - val_loss: 0.0154\n",
            "Epoch 18/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0054 - val_loss: 0.0155\n",
            "Epoch 19/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0060 - val_loss: 0.0158\n",
            "Epoch 20/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0060 - val_loss: 0.0159\n",
            "Epoch 21/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0056 - val_loss: 0.0155\n",
            "Epoch 22/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0049 - val_loss: 0.0155\n",
            "Epoch 23/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0054 - val_loss: 0.0162\n",
            "Epoch 24/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0047 - val_loss: 0.0155\n",
            "Epoch 25/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0047 - val_loss: 0.0164\n",
            "Epoch 26/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0051 - val_loss: 0.0161\n",
            "Epoch 27/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0045 - val_loss: 0.0162\n",
            "Epoch 28/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0050 - val_loss: 0.0166\n",
            "Epoch 29/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0046 - val_loss: 0.0167\n",
            "Epoch 30/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0051 - val_loss: 0.0169\n",
            "Epoch 31/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0041 - val_loss: 0.0171\n",
            "Epoch 32/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0036 - val_loss: 0.0178\n",
            "Epoch 33/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0047 - val_loss: 0.0175\n",
            "Epoch 34/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0040 - val_loss: 0.0180\n",
            "Epoch 35/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0040 - val_loss: 0.0185\n",
            "Epoch 36/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0044 - val_loss: 0.0186\n",
            "Epoch 37/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0043 - val_loss: 0.0190\n",
            "Epoch 38/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0201\n",
            "Epoch 39/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0194\n",
            "Epoch 40/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0037 - val_loss: 0.0199\n",
            "Epoch 41/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0035 - val_loss: 0.0204\n",
            "Epoch 42/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0038 - val_loss: 0.0207\n",
            "Epoch 43/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0034 - val_loss: 0.0205\n",
            "Epoch 44/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0034 - val_loss: 0.0212\n",
            "Epoch 45/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0210\n",
            "Epoch 46/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0038 - val_loss: 0.0206\n",
            "Epoch 47/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0029 - val_loss: 0.0209\n",
            "Epoch 48/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0034 - val_loss: 0.0204\n",
            "Epoch 49/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0036 - val_loss: 0.0208\n",
            "Epoch 50/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0032 - val_loss: 0.0206\n",
            "\n",
            "Fold 4/5\n",
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.5158 - val_loss: 0.2635\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.1195 - val_loss: 0.1212\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0342 - val_loss: 0.0519\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0103 - val_loss: 0.0523\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0117 - val_loss: 0.0544\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0084 - val_loss: 0.0543\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0074 - val_loss: 0.0507\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0062 - val_loss: 0.0513\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0057 - val_loss: 0.0520\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0064 - val_loss: 0.0508\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0062 - val_loss: 0.0514\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0055 - val_loss: 0.0519\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0067 - val_loss: 0.0505\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0055 - val_loss: 0.0516\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0054 - val_loss: 0.0503\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0056 - val_loss: 0.0501\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0058 - val_loss: 0.0515\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0056 - val_loss: 0.0492\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0053 - val_loss: 0.0512\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0056 - val_loss: 0.0499\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0059 - val_loss: 0.0504\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - val_loss: 0.0494\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0051 - val_loss: 0.0492\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0053 - val_loss: 0.0494\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0053 - val_loss: 0.0494\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0051 - val_loss: 0.0491\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0045 - val_loss: 0.0480\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0054 - val_loss: 0.0488\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0050 - val_loss: 0.0479\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0047 - val_loss: 0.0474\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0048 - val_loss: 0.0481\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0050 - val_loss: 0.0467\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0051 - val_loss: 0.0478\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0052 - val_loss: 0.0469\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0044 - val_loss: 0.0464\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0046 - val_loss: 0.0468\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0048 - val_loss: 0.0460\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0046 - val_loss: 0.0463\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - val_loss: 0.0453\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0045 - val_loss: 0.0458\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0048 - val_loss: 0.0448\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0047 - val_loss: 0.0455\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0047 - val_loss: 0.0441\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0044 - val_loss: 0.0451\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0048 - val_loss: 0.0437\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0049 - val_loss: 0.0450\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0042 - val_loss: 0.0430\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0048 - val_loss: 0.0436\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0041 - val_loss: 0.0435\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0419\n",
            "\n",
            "Fold 5/5\n",
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.6623 - val_loss: 0.1635\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0713 - val_loss: 0.0338\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0113 - val_loss: 0.0210\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0154 - val_loss: 0.0143\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0085 - val_loss: 0.0132\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0080 - val_loss: 0.0125\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0077 - val_loss: 0.0134\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0079 - val_loss: 0.0128\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0073 - val_loss: 0.0130\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0065 - val_loss: 0.0131\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0078 - val_loss: 0.0132\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0060 - val_loss: 0.0129\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0082 - val_loss: 0.0138\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0069 - val_loss: 0.0130\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0071 - val_loss: 0.0134\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0063 - val_loss: 0.0138\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0066 - val_loss: 0.0129\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0062 - val_loss: 0.0133\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0056 - val_loss: 0.0125\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0061 - val_loss: 0.0141\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - val_loss: 0.0130\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0065 - val_loss: 0.0133\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0071 - val_loss: 0.0131\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0065 - val_loss: 0.0128\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0059 - val_loss: 0.0130\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0071 - val_loss: 0.0146\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0080 - val_loss: 0.0134\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0055 - val_loss: 0.0121\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0070 - val_loss: 0.0148\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0058 - val_loss: 0.0121\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0070 - val_loss: 0.0134\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0057 - val_loss: 0.0127\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0057 - val_loss: 0.0125\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0052 - val_loss: 0.0144\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0055 - val_loss: 0.0122\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0053 - val_loss: 0.0132\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0047 - val_loss: 0.0131\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0065 - val_loss: 0.0133\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0048 - val_loss: 0.0125\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0050 - val_loss: 0.0139\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0051 - val_loss: 0.0126\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0063 - val_loss: 0.0124\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0047 - val_loss: 0.0127\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0049 - val_loss: 0.0125\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0133\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0047 - val_loss: 0.0128\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - val_loss: 0.0122\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0050 - val_loss: 0.0134\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0055 - val_loss: 0.0123\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0068 - val_loss: 0.0145\n",
            "\n",
            "low_vol_sideways Cross-Validation Results:\n",
            "Mean MSE: 0.025611\n",
            "Std MSE: 0.011039\n",
            "\n",
            "Training low_vol_sideways model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.3201 - val_loss: 0.0589\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0341 - val_loss: 0.0205\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0134 - val_loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0062 - val_loss: 0.0157\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - val_loss: 0.0160\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0047 - val_loss: 0.0165\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0058 - val_loss: 0.0164\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0046 - val_loss: 0.0157\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0050 - val_loss: 0.0167\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0045 - val_loss: 0.0156\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0049 - val_loss: 0.0158\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0045 - val_loss: 0.0159\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0051 - val_loss: 0.0160\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0049 - val_loss: 0.0167\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0049 - val_loss: 0.0164\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0049 - val_loss: 0.0154\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0147\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0152\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0163\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0044 - val_loss: 0.0143\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - val_loss: 0.0144\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0040 - val_loss: 0.0144\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0040 - val_loss: 0.0143\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0044 - val_loss: 0.0138\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0041 - val_loss: 0.0160\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0047 - val_loss: 0.0140\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0129\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0040 - val_loss: 0.0132\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0037 - val_loss: 0.0132\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0039 - val_loss: 0.0127\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0122\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0036 - val_loss: 0.0123\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0039 - val_loss: 0.0129\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0039 - val_loss: 0.0125\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0037 - val_loss: 0.0125\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0115\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0035 - val_loss: 0.0113\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0034 - val_loss: 0.0111\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0032 - val_loss: 0.0111\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0033 - val_loss: 0.0114\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0034 - val_loss: 0.0114\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0034 - val_loss: 0.0115\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0033 - val_loss: 0.0108\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0031 - val_loss: 0.0107\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0036 - val_loss: 0.0108\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0030 - val_loss: 0.0107\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0032 - val_loss: 0.0103\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0028 - val_loss: 0.0101\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0031 - val_loss: 0.0113\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0031 - val_loss: 0.0101\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"fddfc4ad-9f04-4f73-bbc0-f844c989962b\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fddfc4ad-9f04-4f73-bbc0-f844c989962b\")) {                    Plotly.newPlot(                        \"fddfc4ad-9f04-4f73-bbc0-f844c989962b\",                        [{\"line\":{\"color\":\"blue\"},\"name\":\"Training Loss\",\"y\":[0.2164977639913559,0.0239655040204525,0.011200876906514168,0.006910751108080149,0.005882014986127615,0.0052786096930503845,0.0051268902607262135,0.0049196225591003895,0.005018615163862705,0.004749824292957783,0.004708640743046999,0.0045880782417953014,0.004542710725218058,0.004632727708667517,0.004615183919668198,0.004537439905107021,0.004463538061827421,0.004464657977223396,0.004366146866232157,0.004561988171190023,0.00426374189555645,0.0041568949818611145,0.00410666037350893,0.004120485857129097,0.004107566550374031,0.004299890249967575,0.0040313685312867165,0.004004203248769045,0.003866135375574231,0.003816843032836914,0.00383223919197917,0.0038469070568680763,0.003690525656566024,0.003737702267244458,0.0036954276729375124,0.0038366508670151234,0.003666733391582966,0.0034723542630672455,0.0035306629724800587,0.003475775709375739,0.0032762179616838694,0.0033156913705170155,0.0034320736303925514,0.003301141317933798,0.0031261113472282887,0.0031835506670176983,0.0030503682792186737,0.0030597406439483166,0.002982577309012413,0.0029986687004566193],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\"},\"name\":\"Validation Loss\",\"y\":[0.05887915939092636,0.020509591326117516,0.018080728128552437,0.01570245809853077,0.016014568507671356,0.016515003517270088,0.016421141102910042,0.015727296471595764,0.01670948415994644,0.015576854348182678,0.015770461410284042,0.015934666618704796,0.015971677377820015,0.016707727685570717,0.016415715217590332,0.015392513945698738,0.014723670668900013,0.015224422328174114,0.01631626859307289,0.014345105737447739,0.014357036910951138,0.014381783083081245,0.014259831048548222,0.013822388835251331,0.015966393053531647,0.013977552764117718,0.01293883752077818,0.013182178139686584,0.013185041025280952,0.012694859877228737,0.012208637781441212,0.012288651429116726,0.012904729694128036,0.012482987716794014,0.012544231489300728,0.011491603218019009,0.011279026977717876,0.011108702048659325,0.011051906272768974,0.011445405893027782,0.011435603722929955,0.01145840622484684,0.010750118643045425,0.010726439766585827,0.010776559822261333,0.010700928047299385,0.010266557335853577,0.010092858225107193,0.011270353570580482,0.010115545243024826],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training & Validation Loss\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Learning Rate\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Training Progress for low_vol_sideways\"},\"height\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fddfc4ad-9f04-4f73-bbc0-f844c989962b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction Summary:\n",
            "--------------------------------------------------\n",
            "high_vol_uptrend:\n",
            "  Prediction: $267.50\n",
            "  Expected Change: 0.24%\n",
            "low_vol_sideways:\n",
            "  Prediction: $266.65\n",
            "  Expected Change: -0.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-1e23500e2626>:267: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import json\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "class RegimeLSTM:\n",
        "    def __init__(self, lookback=50):\n",
        "        self.lookback = lookback\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.models = {}\n",
        "        self.regime_metadata = {}\n",
        "        self.training_history = {}\n",
        "\n",
        "    def create_model(self):\n",
        "        \"\"\"Create model using functional API\"\"\"\n",
        "        inputs = Input(shape=(self.lookback, 1))\n",
        "        lstm_out = LSTM(50)(inputs)\n",
        "        outputs = Dense(1)(lstm_out)\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "    def prepare_data(self, prices, for_prediction=False):\n",
        "        \"\"\"Prepare data with validation and convert to tensor\"\"\"\n",
        "        if for_prediction:\n",
        "            if len(prices) != self.lookback:\n",
        "                raise ValueError(f\"For prediction, need exactly {self.lookback} price points, got {len(prices)}\")\n",
        "            scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
        "            return tf.convert_to_tensor(scaled_data.reshape(1, self.lookback, 1), dtype=tf.float32), None\n",
        "        else:\n",
        "            if len(prices) < self.lookback + 1:\n",
        "                raise ValueError(f\"For training, need at least {self.lookback + 1} price points, got {len(prices)}\")\n",
        "\n",
        "            scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
        "            X, y = [], []\n",
        "            for i in range(self.lookback, len(scaled_data)):\n",
        "                X.append(scaled_data[i-self.lookback:i])\n",
        "                y.append(scaled_data[i])\n",
        "            X_tensor = tf.convert_to_tensor(np.array(X), dtype=tf.float32)\n",
        "            y_tensor = tf.convert_to_tensor(np.array(y), dtype=tf.float32)\n",
        "            return X_tensor, y_tensor\n",
        "\n",
        "    def train_regime(self, prices, regime_name, regime_characteristics):\n",
        "        \"\"\"Train regime with progress tracking\"\"\"\n",
        "        try:\n",
        "            print(f\"\\nPreparing data for {regime_name}...\")\n",
        "            X, y = self.prepare_data(prices, for_prediction=False)\n",
        "\n",
        "            batch_size = min(32, len(X))\n",
        "            print(f\"Using batch size: {batch_size}\")\n",
        "\n",
        "            print(f\"Creating model for {regime_name}...\")\n",
        "            model = self.create_model()\n",
        "\n",
        "            print(f\"\\nTraining {regime_name} model...\")\n",
        "            print(f\"Training data shape: {X.shape}\")\n",
        "\n",
        "            history = model.fit(\n",
        "                X, y,\n",
        "                epochs=25,\n",
        "                batch_size=batch_size,\n",
        "                validation_split=0.2,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            self.training_history[regime_name] = history\n",
        "            self.models[regime_name] = model\n",
        "\n",
        "            # Save metadata\n",
        "            metadata = {\n",
        "                \"regime_name\": regime_name,\n",
        "                \"characteristics\": regime_characteristics,\n",
        "                \"training_loss\": float(history.history['loss'][-1]),\n",
        "                \"data_points\": len(prices),\n",
        "                \"lookback\": self.lookback\n",
        "            }\n",
        "            self.regime_metadata[regime_name] = metadata\n",
        "\n",
        "            print(f\"Completed training for {regime_name}\")\n",
        "            return model, metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error training regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def predict_with_regime(self, prices, regime_name):\n",
        "        \"\"\"Make predictions with error handling\"\"\"\n",
        "        try:\n",
        "            if len(prices) != self.lookback:\n",
        "                prices = prices[-self.lookback:]\n",
        "\n",
        "            X, _ = self.prepare_data(prices, for_prediction=True)\n",
        "            prediction = self.models[regime_name].predict(X, verbose=0)\n",
        "            prediction_orig = self.scaler.inverse_transform(prediction)\n",
        "\n",
        "            return float(prediction_orig[0][0])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error predicting with regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def train_with_cross_validation(self, prices, regime_name, regime_characteristics, n_splits=3):\n",
        "        \"\"\"Train with cross-validation and progress tracking\"\"\"\n",
        "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "        cv_scores = []\n",
        "        cv_predictions = []\n",
        "\n",
        "        print(f\"\\nPerforming {n_splits}-fold time series cross-validation for {regime_name}\")\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(tscv.split(prices)):\n",
        "            print(f\"\\nStarting fold {fold + 1}/{n_splits}\")\n",
        "\n",
        "            train_prices = prices[train_idx]\n",
        "            val_prices = prices[val_idx]\n",
        "\n",
        "            print(f\"Training data size: {len(train_prices)}\")\n",
        "            print(f\"Validation data size: {len(val_prices)}\")\n",
        "\n",
        "            try:\n",
        "                X_train, y_train = self.prepare_data(train_prices, for_prediction=False)\n",
        "                X_val, y_val = self.prepare_data(val_prices, for_prediction=False)\n",
        "\n",
        "                model = self.create_model()\n",
        "\n",
        "                print(f\"Training fold {fold + 1}...\")\n",
        "                history = model.fit(\n",
        "                    X_train, y_train,\n",
        "                    epochs=25,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1\n",
        "                )\n",
        "\n",
        "                val_score = model.evaluate(X_val, y_val, verbose=0)\n",
        "                cv_scores.append(val_score)\n",
        "\n",
        "                print(f\"Fold {fold + 1} validation score: {val_score:.6f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in fold {fold + 1}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return cv_scores\n",
        "\n",
        "    def visualize_training(self, regime_name):\n",
        "        \"\"\"Visualize training progress\"\"\"\n",
        "        if regime_name not in self.training_history:\n",
        "            print(f\"No training history found for {regime_name}\")\n",
        "            return None\n",
        "\n",
        "        history = self.training_history[regime_name]\n",
        "        fig = go.Figure()\n",
        "\n",
        "        # Plot training loss\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                y=history.history['loss'],\n",
        "                name='Training Loss',\n",
        "                line=dict(color='blue')\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Plot validation loss if available\n",
        "        if 'val_loss' in history.history:\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    y=history.history['val_loss'],\n",
        "                    name='Validation Loss',\n",
        "                    line=dict(color='red')\n",
        "                )\n",
        "            )\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"Training Progress for {regime_name}\",\n",
        "            xaxis_title=\"Epoch\",\n",
        "            yaxis_title=\"Loss\",\n",
        "            showlegend=True\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Fetching SPY data...\")\n",
        "        df = yf.download('SPY', start='2014-01-01', end='2017-12-31')\n",
        "        print(f\"Downloaded {len(df)} days of data\")\n",
        "\n",
        "        regime_lstm = RegimeLSTM(lookback=50)\n",
        "\n",
        "        regimes = {\n",
        "            \"high_vol_uptrend\": {\n",
        "                \"volatility\": \"high\",\n",
        "                \"trend\": \"upward\",\n",
        "                \"volume\": \"above_average\"\n",
        "            },\n",
        "            \"low_vol_sideways\": {\n",
        "                \"volatility\": \"low\",\n",
        "                \"trend\": \"sideways\",\n",
        "                \"volume\": \"below_average\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        predictions = {}\n",
        "\n",
        "        for regime_name, characteristics in regimes.items():\n",
        "            print(f\"\\nProcessing {regime_name}...\")\n",
        "            train_data = df['Close'].values[:500]\n",
        "\n",
        "            # Perform cross-validation\n",
        "            cv_scores = regime_lstm.train_with_cross_validation(\n",
        "                train_data,\n",
        "                regime_name,\n",
        "                characteristics\n",
        "            )\n",
        "\n",
        "            print(f\"\\n{regime_name} Cross-Validation Results:\")\n",
        "            print(f\"Mean MSE: {np.mean(cv_scores):.6f}\")\n",
        "            print(f\"Std MSE: {np.std(cv_scores):.6f}\")\n",
        "\n",
        "            # Train final model\n",
        "            model, metadata = regime_lstm.train_regime(\n",
        "                train_data,\n",
        "                regime_name,\n",
        "                characteristics\n",
        "            )\n",
        "\n",
        "            # Visualize training\n",
        "            fig = regime_lstm.visualize_training(regime_name)\n",
        "            if fig is not None:\n",
        "                fig.show()\n",
        "\n",
        "            # Make prediction\n",
        "            recent_prices = df['Close'].values[-regime_lstm.lookback:]\n",
        "            prediction = regime_lstm.predict_with_regime(\n",
        "                recent_prices,\n",
        "                regime_name\n",
        "            )\n",
        "            predictions[regime_name] = prediction\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\nPrediction Results:\")\n",
        "        print(\"-\" * 50)\n",
        "        current_price = float(df['Close'].values[-1])\n",
        "\n",
        "        for regime_name, pred in predictions.items():\n",
        "            change_pct = ((pred/current_price) - 1) * 100\n",
        "            print(f\"\\n{regime_name}:\")\n",
        "            print(f\"Current Price: ${current_price:.2f}\")\n",
        "            print(f\"Predicted Price: ${pred:.2f}\")\n",
        "            print(f\"Predicted Change: {change_pct:.2f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9KFYLWlk_Msg",
        "outputId": "9edf6e0d-38d7-47ab-caf5-02551d1d2beb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching SPY data...\n",
            "Downloaded 1007 days of data\n",
            "\n",
            "Processing high_vol_uptrend...\n",
            "\n",
            "Performing 3-fold time series cross-validation for high_vol_uptrend\n",
            "\n",
            "Starting fold 1/3\n",
            "Training data size: 125\n",
            "Validation data size: 125\n",
            "Training fold 1...\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - loss: 0.4055 - val_loss: 0.2820\n",
            "Epoch 2/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2668 - val_loss: 0.1643\n",
            "Epoch 3/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1343 - val_loss: 0.0712\n",
            "Epoch 4/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0393 - val_loss: 0.0375\n",
            "Epoch 5/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0121 - val_loss: 0.0786\n",
            "Epoch 6/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0390 - val_loss: 0.0568\n",
            "Epoch 7/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0185 - val_loss: 0.0350\n",
            "Epoch 8/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0070 - val_loss: 0.0321\n",
            "Epoch 9/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0094 - val_loss: 0.0337\n",
            "Epoch 10/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0130 - val_loss: 0.0338\n",
            "Epoch 11/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0133 - val_loss: 0.0319\n",
            "Epoch 12/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0106 - val_loss: 0.0303\n",
            "Epoch 13/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0081 - val_loss: 0.0302\n",
            "Epoch 14/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0072 - val_loss: 0.0315\n",
            "Epoch 15/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0067 - val_loss: 0.0325\n",
            "Epoch 16/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0077 - val_loss: 0.0318\n",
            "Epoch 17/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0076 - val_loss: 0.0305\n",
            "Epoch 18/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0069 - val_loss: 0.0295\n",
            "Epoch 19/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0061 - val_loss: 0.0290\n",
            "Epoch 20/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0062 - val_loss: 0.0288\n",
            "Epoch 21/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0068 - val_loss: 0.0288\n",
            "Epoch 22/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0064 - val_loss: 0.0288\n",
            "Epoch 23/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0062 - val_loss: 0.0290\n",
            "Epoch 24/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0062 - val_loss: 0.0292\n",
            "Epoch 25/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0061 - val_loss: 0.0292\n",
            "Fold 1 validation score: 0.029225\n",
            "\n",
            "Starting fold 2/3\n",
            "Training data size: 250\n",
            "Validation data size: 125\n",
            "Training fold 2...\n",
            "Epoch 1/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.3598 - val_loss: 0.1366\n",
            "Epoch 2/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0557 - val_loss: 0.0547\n",
            "Epoch 3/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0349 - val_loss: 0.0136\n",
            "Epoch 4/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0090 - val_loss: 0.0227\n",
            "Epoch 5/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0126 - val_loss: 0.0152\n",
            "Epoch 6/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0075 - val_loss: 0.0142\n",
            "Epoch 7/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0087 - val_loss: 0.0133\n",
            "Epoch 8/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0064 - val_loss: 0.0135\n",
            "Epoch 9/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0068 - val_loss: 0.0136\n",
            "Epoch 10/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0074 - val_loss: 0.0131\n",
            "Epoch 11/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0071 - val_loss: 0.0132\n",
            "Epoch 12/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0070 - val_loss: 0.0131\n",
            "Epoch 13/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0065 - val_loss: 0.0131\n",
            "Epoch 14/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0061 - val_loss: 0.0131\n",
            "Epoch 15/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0055 - val_loss: 0.0133\n",
            "Epoch 16/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0063 - val_loss: 0.0131\n",
            "Epoch 17/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0060 - val_loss: 0.0131\n",
            "Epoch 18/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0070 - val_loss: 0.0131\n",
            "Epoch 19/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0058 - val_loss: 0.0130\n",
            "Epoch 20/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0054 - val_loss: 0.0130\n",
            "Epoch 21/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0064 - val_loss: 0.0130\n",
            "Epoch 22/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0060 - val_loss: 0.0131\n",
            "Epoch 23/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0057 - val_loss: 0.0130\n",
            "Epoch 24/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0055 - val_loss: 0.0131\n",
            "Epoch 25/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0058 - val_loss: 0.0130\n",
            "Fold 2 validation score: 0.012985\n",
            "\n",
            "Starting fold 3/3\n",
            "Training data size: 375\n",
            "Validation data size: 125\n",
            "Training fold 3...\n",
            "Epoch 1/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.2517 - val_loss: 0.0218\n",
            "Epoch 2/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0189 - val_loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0086 - val_loss: 0.0204\n",
            "Epoch 4/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0074 - val_loss: 0.0188\n",
            "Epoch 5/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - val_loss: 0.0177\n",
            "Epoch 6/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0056 - val_loss: 0.0175\n",
            "Epoch 7/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0047 - val_loss: 0.0174\n",
            "Epoch 8/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0174\n",
            "Epoch 9/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0044 - val_loss: 0.0174\n",
            "Epoch 10/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0173\n",
            "Epoch 11/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0046 - val_loss: 0.0173\n",
            "Epoch 12/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0048 - val_loss: 0.0173\n",
            "Epoch 13/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0045 - val_loss: 0.0173\n",
            "Epoch 14/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0172\n",
            "Epoch 15/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0038 - val_loss: 0.0173\n",
            "Epoch 16/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0170\n",
            "Epoch 17/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0045 - val_loss: 0.0169\n",
            "Epoch 18/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0167\n",
            "Epoch 19/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - val_loss: 0.0166\n",
            "Epoch 20/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0039 - val_loss: 0.0165\n",
            "Epoch 21/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0040 - val_loss: 0.0164\n",
            "Epoch 22/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0038 - val_loss: 0.0164\n",
            "Epoch 23/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0042 - val_loss: 0.0162\n",
            "Epoch 24/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0038 - val_loss: 0.0160\n",
            "Epoch 25/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0036 - val_loss: 0.0160\n",
            "Fold 3 validation score: 0.016017\n",
            "\n",
            "high_vol_uptrend Cross-Validation Results:\n",
            "Mean MSE: 0.019409\n",
            "Std MSE: 0.007050\n",
            "\n",
            "Preparing data for high_vol_uptrend...\n",
            "Using batch size: 32\n",
            "Creating model for high_vol_uptrend...\n",
            "\n",
            "Training high_vol_uptrend model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.6061 - val_loss: 0.0897\n",
            "Epoch 2/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0448 - val_loss: 0.0204\n",
            "Epoch 3/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0083 - val_loss: 0.0169\n",
            "Epoch 4/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0087 - val_loss: 0.0193\n",
            "Epoch 5/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0063 - val_loss: 0.0147\n",
            "Epoch 6/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0061 - val_loss: 0.0157\n",
            "Epoch 7/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0058 - val_loss: 0.0152\n",
            "Epoch 8/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0053 - val_loss: 0.0153\n",
            "Epoch 9/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - val_loss: 0.0154\n",
            "Epoch 10/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0048 - val_loss: 0.0151\n",
            "Epoch 11/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0152\n",
            "Epoch 12/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - val_loss: 0.0156\n",
            "Epoch 13/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0049 - val_loss: 0.0147\n",
            "Epoch 14/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0054 - val_loss: 0.0165\n",
            "Epoch 15/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0054 - val_loss: 0.0149\n",
            "Epoch 16/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0149\n",
            "Epoch 17/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0148\n",
            "Epoch 18/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - val_loss: 0.0148\n",
            "Epoch 19/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0047 - val_loss: 0.0147\n",
            "Epoch 20/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0046 - val_loss: 0.0150\n",
            "Epoch 21/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0044 - val_loss: 0.0143\n",
            "Epoch 22/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0044 - val_loss: 0.0148\n",
            "Epoch 23/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0047 - val_loss: 0.0148\n",
            "Epoch 24/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0046 - val_loss: 0.0142\n",
            "Epoch 25/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0049 - val_loss: 0.0136\n",
            "Completed training for high_vol_uptrend\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"31aece8c-0b25-4a74-84d1-a0b607b91e2d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"31aece8c-0b25-4a74-84d1-a0b607b91e2d\")) {                    Plotly.newPlot(                        \"31aece8c-0b25-4a74-84d1-a0b607b91e2d\",                        [{\"line\":{\"color\":\"blue\"},\"name\":\"Training Loss\",\"y\":[0.45090553164482117,0.03524007648229599,0.010191184468567371,0.007480495609343052,0.006154680158942938,0.005799745209515095,0.005463463719934225,0.005301123019307852,0.005162345711141825,0.005059091839939356,0.004944820888340473,0.004919912200421095,0.004890178795903921,0.005098909139633179,0.004860635381191969,0.004621241707354784,0.004569515585899353,0.004534489940851927,0.004519863519817591,0.004480707459151745,0.004437215626239777,0.004401185549795628,0.004427081905305386,0.004409260582178831,0.004608207382261753],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"name\":\"Validation Loss\",\"y\":[0.08973676711320877,0.020385554060339928,0.016879277303814888,0.019312502816319466,0.014733939431607723,0.015681428834795952,0.015190280973911285,0.015304233878850937,0.015401015989482403,0.015088367275893688,0.01520549412816763,0.015583381056785583,0.014661797322332859,0.01648491621017456,0.01493040844798088,0.014857277274131775,0.014834588393568993,0.01480487734079361,0.014686433598399162,0.015046834945678711,0.01429816521704197,0.014773638918995857,0.014774596318602562,0.014240419492125511,0.01361252460628748],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Training Progress for high_vol_uptrend\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('31aece8c-0b25-4a74-84d1-a0b607b91e2d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing low_vol_sideways...\n",
            "\n",
            "Performing 3-fold time series cross-validation for low_vol_sideways\n",
            "\n",
            "Starting fold 1/3\n",
            "Training data size: 125\n",
            "Validation data size: 125\n",
            "Training fold 1...\n",
            "Epoch 1/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.5050 - val_loss: 0.3531\n",
            "Epoch 2/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3394 - val_loss: 0.2026\n",
            "Epoch 3/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1707 - val_loss: 0.0896\n",
            "Epoch 4/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0548 - val_loss: 0.0399\n",
            "Epoch 5/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0114 - val_loss: 0.0857\n",
            "Epoch 6/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0428 - val_loss: 0.0756\n",
            "Epoch 7/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0306 - val_loss: 0.0427\n",
            "Epoch 8/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0075 - val_loss: 0.0349\n",
            "Epoch 9/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0087 - val_loss: 0.0363\n",
            "Epoch 10/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0133 - val_loss: 0.0376\n",
            "Epoch 11/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0153 - val_loss: 0.0363\n",
            "Epoch 12/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0141 - val_loss: 0.0339\n",
            "Epoch 13/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0096 - val_loss: 0.0328\n",
            "Epoch 14/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0068 - val_loss: 0.0340\n",
            "Epoch 15/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0080 - val_loss: 0.0360\n",
            "Epoch 16/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0075 - val_loss: 0.0361\n",
            "Epoch 17/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0091 - val_loss: 0.0344\n",
            "Epoch 18/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0074 - val_loss: 0.0330\n",
            "Epoch 19/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0076 - val_loss: 0.0323\n",
            "Epoch 20/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0067 - val_loss: 0.0320\n",
            "Epoch 21/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0071 - val_loss: 0.0319\n",
            "Epoch 22/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0070 - val_loss: 0.0320\n",
            "Epoch 23/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0070 - val_loss: 0.0322\n",
            "Epoch 24/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0068 - val_loss: 0.0326\n",
            "Epoch 25/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0060 - val_loss: 0.0328\n",
            "Fold 1 validation score: 0.032789\n",
            "\n",
            "Starting fold 2/3\n",
            "Training data size: 250\n",
            "Validation data size: 125\n",
            "Training fold 2...\n",
            "Epoch 1/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.3443 - val_loss: 0.1955\n",
            "Epoch 2/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0932 - val_loss: 0.0139\n",
            "Epoch 3/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0187 - val_loss: 0.0233\n",
            "Epoch 4/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0116 - val_loss: 0.0167\n",
            "Epoch 5/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0100 - val_loss: 0.0188\n",
            "Epoch 6/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0096 - val_loss: 0.0133\n",
            "Epoch 7/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0069 - val_loss: 0.0136\n",
            "Epoch 8/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0087 - val_loss: 0.0133\n",
            "Epoch 9/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0076 - val_loss: 0.0139\n",
            "Epoch 10/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0065 - val_loss: 0.0132\n",
            "Epoch 11/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0078 - val_loss: 0.0131\n",
            "Epoch 12/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0074 - val_loss: 0.0132\n",
            "Epoch 13/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0065 - val_loss: 0.0131\n",
            "Epoch 14/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0067 - val_loss: 0.0131\n",
            "Epoch 15/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - val_loss: 0.0131\n",
            "Epoch 16/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0062 - val_loss: 0.0131\n",
            "Epoch 17/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0057 - val_loss: 0.0133\n",
            "Epoch 18/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - val_loss: 0.0131\n",
            "Epoch 19/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0052 - val_loss: 0.0131\n",
            "Epoch 20/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0053 - val_loss: 0.0132\n",
            "Epoch 21/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0071 - val_loss: 0.0134\n",
            "Epoch 22/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0052 - val_loss: 0.0131\n",
            "Epoch 23/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - val_loss: 0.0131\n",
            "Epoch 24/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0057 - val_loss: 0.0132\n",
            "Epoch 25/25\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0057 - val_loss: 0.0131\n",
            "Fold 2 validation score: 0.013140\n",
            "\n",
            "Starting fold 3/3\n",
            "Training data size: 375\n",
            "Validation data size: 125\n",
            "Training fold 3...\n",
            "Epoch 1/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.4103 - val_loss: 0.0309\n",
            "Epoch 2/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0262 - val_loss: 0.0232\n",
            "Epoch 3/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0089 - val_loss: 0.0276\n",
            "Epoch 4/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0114 - val_loss: 0.0207\n",
            "Epoch 5/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0071 - val_loss: 0.0200\n",
            "Epoch 6/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0059 - val_loss: 0.0199\n",
            "Epoch 7/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0060 - val_loss: 0.0196\n",
            "Epoch 8/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0060 - val_loss: 0.0194\n",
            "Epoch 9/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0193\n",
            "Epoch 10/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - val_loss: 0.0193\n",
            "Epoch 11/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0056 - val_loss: 0.0192\n",
            "Epoch 12/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0052 - val_loss: 0.0192\n",
            "Epoch 13/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0051 - val_loss: 0.0191\n",
            "Epoch 14/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0043 - val_loss: 0.0192\n",
            "Epoch 15/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0048 - val_loss: 0.0190\n",
            "Epoch 16/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0042 - val_loss: 0.0189\n",
            "Epoch 17/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0045 - val_loss: 0.0189\n",
            "Epoch 18/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0187\n",
            "Epoch 19/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0186\n",
            "Epoch 20/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0049 - val_loss: 0.0185\n",
            "Epoch 21/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0045 - val_loss: 0.0185\n",
            "Epoch 22/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0043 - val_loss: 0.0181\n",
            "Epoch 23/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0038 - val_loss: 0.0182\n",
            "Epoch 24/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0177\n",
            "Epoch 25/25\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0041 - val_loss: 0.0174\n",
            "Fold 3 validation score: 0.017433\n",
            "\n",
            "low_vol_sideways Cross-Validation Results:\n",
            "Mean MSE: 0.021121\n",
            "Std MSE: 0.008435\n",
            "\n",
            "Preparing data for low_vol_sideways...\n",
            "Using batch size: 32\n",
            "Creating model for low_vol_sideways...\n",
            "\n",
            "Training low_vol_sideways model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.4003 - val_loss: 0.0467\n",
            "Epoch 2/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0258 - val_loss: 0.0198\n",
            "Epoch 3/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0076 - val_loss: 0.0171\n",
            "Epoch 4/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0085 - val_loss: 0.0173\n",
            "Epoch 5/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0054 - val_loss: 0.0142\n",
            "Epoch 6/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0052 - val_loss: 0.0141\n",
            "Epoch 7/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0146\n",
            "Epoch 8/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - val_loss: 0.0141\n",
            "Epoch 9/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0046 - val_loss: 0.0149\n",
            "Epoch 10/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0049 - val_loss: 0.0142\n",
            "Epoch 11/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0047 - val_loss: 0.0144\n",
            "Epoch 12/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0044 - val_loss: 0.0142\n",
            "Epoch 13/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0045 - val_loss: 0.0142\n",
            "Epoch 14/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0045 - val_loss: 0.0144\n",
            "Epoch 15/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0040 - val_loss: 0.0142\n",
            "Epoch 16/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0040 - val_loss: 0.0138\n",
            "Epoch 17/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0039 - val_loss: 0.0150\n",
            "Epoch 18/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0045 - val_loss: 0.0137\n",
            "Epoch 19/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0140\n",
            "Epoch 20/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0140\n",
            "Epoch 21/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0043 - val_loss: 0.0137\n",
            "Epoch 22/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0141\n",
            "Epoch 23/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0132\n",
            "Epoch 24/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0143\n",
            "Epoch 25/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0043 - val_loss: 0.0131\n",
            "Completed training for low_vol_sideways\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c6beb011-feb7-4816-a5e7-544122773830\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c6beb011-feb7-4816-a5e7-544122773830\")) {                    Plotly.newPlot(                        \"c6beb011-feb7-4816-a5e7-544122773830\",                        [{\"line\":{\"color\":\"blue\"},\"name\":\"Training Loss\",\"y\":[0.29780223965644836,0.02641495317220688,0.009676860645413399,0.007581966929137707,0.005831039045006037,0.00530973169952631,0.0051200008019804955,0.0048047760501503944,0.004666563589125872,0.0047781094908714294,0.004558315500617027,0.004443399608135223,0.004395859781652689,0.004348610062152147,0.004309925250709057,0.004371821880340576,0.0043858010321855545,0.004368945024907589,0.004224519710987806,0.004339736886322498,0.004136024042963982,0.004096899647265673,0.004125860054045916,0.00426397705450654,0.004051805008202791],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"name\":\"Validation Loss\",\"y\":[0.04668371379375458,0.019844867289066315,0.017062200233340263,0.017262442037463188,0.014155973680317402,0.014127207919955254,0.014584532007575035,0.014141833409667015,0.014850129373371601,0.014157138764858246,0.014379598200321198,0.014234399423003197,0.014210330322384834,0.014350982382893562,0.014221728779375553,0.013804084621369839,0.014986149035394192,0.013656364753842354,0.013968812301754951,0.01396624743938446,0.013721914030611515,0.014073412865400314,0.013229616917669773,0.01427270844578743,0.013080321252346039],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Training Progress for low_vol_sideways\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c6beb011-feb7-4816-a5e7-544122773830');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction Results:\n",
            "--------------------------------------------------\n",
            "\n",
            "high_vol_uptrend:\n",
            "Current Price: $266.86\n",
            "Predicted Price: $266.75\n",
            "Predicted Change: -0.04%\n",
            "\n",
            "low_vol_sideways:\n",
            "Current Price: $266.86\n",
            "Predicted Price: $267.08\n",
            "Predicted Change: 0.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-39edfa5f859f>:251: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import json\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "class RegimeLSTM:\n",
        "    def __init__(self, lookback=50):\n",
        "        self.lookback = lookback\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.models = {}\n",
        "        self.regime_metadata = {}\n",
        "        self.training_history = {}\n",
        "\n",
        "    def create_model(self):\n",
        "        inputs = Input(shape=(self.lookback, 1))\n",
        "        lstm_out = LSTM(50)(inputs)\n",
        "        outputs = Dense(1)(lstm_out)\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "    def prepare_data(self, prices, for_prediction=False):\n",
        "        if for_prediction:\n",
        "            if len(prices) != self.lookback:\n",
        "                raise ValueError(f\"For prediction, need exactly {self.lookback} price points, got {len(prices)}\")\n",
        "            scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
        "            return tf.convert_to_tensor(scaled_data.reshape(1, self.lookback, 1), dtype=tf.float32), None\n",
        "        else:\n",
        "            if len(prices) < self.lookback + 1:\n",
        "                raise ValueError(f\"For training, need at least {self.lookback + 1} price points, got {len(prices)}\")\n",
        "\n",
        "            scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
        "            X, y = [], []\n",
        "            for i in range(self.lookback, len(scaled_data)):\n",
        "                X.append(scaled_data[i-self.lookback:i])\n",
        "                y.append(scaled_data[i])\n",
        "            X_tensor = tf.convert_to_tensor(np.array(X), dtype=tf.float32)\n",
        "            y_tensor = tf.convert_to_tensor(np.array(y), dtype=tf.float32)\n",
        "            return X_tensor, y_tensor\n",
        "\n",
        "    def train_regime(self, prices, regime_name, regime_characteristics):\n",
        "        try:\n",
        "            print(f\"\\nPreparing data for {regime_name}...\")\n",
        "            X, y = self.prepare_data(prices, for_prediction=False)\n",
        "\n",
        "            batch_size = min(32, len(X))\n",
        "            print(f\"Using batch size: {batch_size}\")\n",
        "\n",
        "            model = self.create_model()\n",
        "            print(f\"\\nTraining {regime_name} model...\")\n",
        "            print(f\"Training data shape: {X.shape}\")\n",
        "\n",
        "            history = model.fit(\n",
        "                X, y,\n",
        "                epochs=25,\n",
        "                batch_size=batch_size,\n",
        "                validation_split=0.2,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            self.training_history[regime_name] = history\n",
        "            self.models[regime_name] = model\n",
        "\n",
        "            metadata = {\n",
        "                \"regime_name\": regime_name,\n",
        "                \"characteristics\": regime_characteristics,\n",
        "                \"training_loss\": float(history.history['loss'][-1]),\n",
        "                \"data_points\": len(prices),\n",
        "                \"lookback\": self.lookback\n",
        "            }\n",
        "            self.regime_metadata[regime_name] = metadata\n",
        "\n",
        "            print(f\"Completed training for {regime_name}\")\n",
        "            return model, metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error training regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def predict_with_regime(self, prices, regime_name):\n",
        "        try:\n",
        "            if len(prices) != self.lookback:\n",
        "                prices = prices[-self.lookback:]\n",
        "\n",
        "            X, _ = self.prepare_data(prices, for_prediction=True)\n",
        "            prediction = self.models[regime_name].predict(X, verbose=0)\n",
        "            prediction_orig = self.scaler.inverse_transform(prediction)\n",
        "\n",
        "            return float(prediction_orig[0][0])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error predicting with regime {regime_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def visualize_ohlc(self, df):\n",
        "        fig = make_subplots(rows=2, cols=1,\n",
        "                           shared_xaxes=True,\n",
        "                           vertical_spacing=0.05,\n",
        "                           row_heights=[0.7, 0.3])\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Candlestick(\n",
        "                x=df.index,\n",
        "                open=df['Open'],\n",
        "                high=df['High'],\n",
        "                low=df['Low'],\n",
        "                close=df['Close'],\n",
        "                name='OHLC'\n",
        "            ),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=df.index,\n",
        "                y=df['Volume'],\n",
        "                name='Volume',\n",
        "                marker=dict(\n",
        "                    color='rgba(100, 100, 100, 0.3)'\n",
        "                )\n",
        "            ),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='SPY Price Action',\n",
        "            yaxis_title='Price',\n",
        "            yaxis2_title='Volume',\n",
        "            xaxis_rangeslider_visible=False\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def analyze_feature_importance(self, prices, regime_name):\n",
        "        base_prediction = self.predict_with_regime(prices, regime_name)\n",
        "        importance_scores = []\n",
        "\n",
        "        for i in range(self.lookback):\n",
        "            perturbed_prices = prices.copy()\n",
        "            perturbed_prices[i] *= 1.01\n",
        "\n",
        "            perturbed_prediction = self.predict_with_regime(perturbed_prices, regime_name)\n",
        "            importance = abs((perturbed_prediction - base_prediction) / base_prediction * 100)\n",
        "            importance_scores.append(importance)\n",
        "\n",
        "        return importance_scores\n",
        "\n",
        "    def visualize_feature_importance(self, importance_scores, regime_name):\n",
        "        fig = go.Figure()\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=list(range(self.lookback)),\n",
        "                y=importance_scores,\n",
        "                name='Feature Importance',\n",
        "                marker=dict(\n",
        "                    color=importance_scores,\n",
        "                    colorscale='Viridis'\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f'Feature Importance Analysis for {regime_name}',\n",
        "            xaxis_title='Days Back',\n",
        "            yaxis_title='Price Sensitivity (%)',\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Fetching SPY data...\")\n",
        "        df = yf.download('SPY', start='2014-01-01', end='2017-12-31')\n",
        "        df = df[df.index.dayofweek < 5]  # Remove weekends\n",
        "        print(f\"Downloaded {len(df)} trading days\")\n",
        "\n",
        "        regime_lstm = RegimeLSTM(lookback=50)\n",
        "\n",
        "        # Create and show OHLC chart\n",
        "        ohlc_fig = regime_lstm.visualize_ohlc(df)\n",
        "        ohlc_fig.show()\n",
        "\n",
        "        regimes = {\n",
        "            \"high_vol_uptrend\": {\n",
        "                \"volatility\": \"high\",\n",
        "                \"trend\": \"upward\",\n",
        "                \"volume\": \"above_average\"\n",
        "            },\n",
        "            \"low_vol_sideways\": {\n",
        "                \"volatility\": \"low\",\n",
        "                \"trend\": \"sideways\",\n",
        "                \"volume\": \"below_average\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        predictions = {}\n",
        "\n",
        "        for regime_name, characteristics in regimes.items():\n",
        "            print(f\"\\nProcessing {regime_name}...\")\n",
        "            train_data = df['Close'].values[:500]\n",
        "\n",
        "            # Train model\n",
        "            model, metadata = regime_lstm.train_regime(\n",
        "                train_data,\n",
        "                regime_name,\n",
        "                characteristics\n",
        "            )\n",
        "\n",
        "            # Make prediction\n",
        "            recent_prices = df['Close'].values[-regime_lstm.lookback:]\n",
        "            prediction = regime_lstm.predict_with_regime(\n",
        "                recent_prices,\n",
        "                regime_name\n",
        "            )\n",
        "            predictions[regime_name] = prediction\n",
        "\n",
        "            # Analyze and visualize feature importance\n",
        "            importance_scores = regime_lstm.analyze_feature_importance(\n",
        "                recent_prices,\n",
        "                regime_name\n",
        "            )\n",
        "\n",
        "            importance_fig = regime_lstm.visualize_feature_importance(\n",
        "                importance_scores,\n",
        "                regime_name\n",
        "            )\n",
        "            importance_fig.show()\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\nPrediction Results:\")\n",
        "        print(\"-\" * 50)\n",
        "        current_price = float(df['Close'].values[-1])\n",
        "\n",
        "        for regime_name, pred in predictions.items():\n",
        "            change_pct = ((pred/current_price) - 1) * 100\n",
        "            print(f\"\\n{regime_name}:\")\n",
        "            print(f\"Current Price: ${current_price:.2f}\")\n",
        "            print(f\"Predicted Price: ${pred:.2f}\")\n",
        "            print(f\"Predicted Change: {change_pct:.2f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rrNKehwrDRBV",
        "outputId": "0bf3cfd5-8c06-423f-8b0f-c6c135019a93"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching SPY data...\n",
            "Downloaded 1007 trading days\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"09c293f2-2290-4c13-88f8-cc01dbf58677\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"09c293f2-2290-4c13-88f8-cc01dbf58677\")) {                    Plotly.newPlot(                        \"09c293f2-2290-4c13-88f8-cc01dbf58677\",                        [{\"close\":[[182.9199981689453],[182.88999938964844],[182.36000061035156],[183.47999572753906],[183.52000427246094],[183.63999938964844],[184.13999938964844],[181.69000244140625],[183.6699981689453],[184.66000366210938],[184.4199981689453],[183.63999938964844],[184.17999267578125],[184.3000030517578],[182.7899932861328],[178.88999938964844],[178.00999450683594],[179.07000732421875],[177.35000610351562],[179.22999572753906],[178.17999267578125],[174.1699981689453],[175.38999938964844],[175.1699981689453],[177.47999572753906],[179.67999267578125],[180.00999450683594],[181.97999572753906],[182.07000732421875],[183.00999450683594],[184.02000427246094],[184.24000549316406],[183.02000427246094],[184.10000610351562],[183.88999938964844],[184.91000366210938],[184.83999633789062],[184.85000610351562],[185.82000732421875],[186.2899932861328],[184.97999572753906],[187.5800018310547],[187.75],[188.17999267578125],[188.25999450683594],[188.16000366210938],[187.22999572753906],[187.27999877929688],[185.17999267578125],[184.66000366210938],[186.3300018310547],[187.66000366210938],[186.66000366210938],[187.75],[186.1999969482422],[185.42999267578125],[186.30999755859375],[184.97000122070312],[184.5800018310547],[185.49000549316406],[187.00999450683594],[188.25],[188.8800048828125],[188.6300048828125],[186.39999389648438],[184.33999633789062],[185.10000610351562],[187.08999633789062],[183.16000366210938],[181.50999450683594],[182.94000244140625],[184.1999969482422],[186.1300048828125],[186.38999938964844],[187.0399932861328],[187.88999938964844],[187.4499969482422],[187.8300018310547],[186.2899932861328],[186.8800048828125],[187.75],[188.30999755859375],[188.3300018310547],[188.05999755859375],[188.4199981689453],[186.77999877929688],[187.8800048828125],[187.67999267578125],[187.9600067138672],[189.7899932861328],[189.9600067138672],[189.05999755859375],[187.39999389648438],[188.0500030517578],[188.74000549316406],[187.5500030517578],[189.1300048828125],[189.58999633789062],[190.35000610351562],[191.52000427246094],[191.3800048828125],[192.3699951171875],[192.67999267578125],[192.89999389648438],[192.8000030517578],[193.19000244140625],[194.4499969482422],[195.3800048828125],[195.5800018310547],[195.60000610351562],[194.9199981689453],[193.5399932861328],[194.1300048828125],[194.2899932861328],[194.8300018310547],[196.25999450683594],[196.47999572753906],[195.94000244140625],[195.8800048828125],[194.6999969482422],[195.5800018310547],[195.44000244140625],[195.82000732421875],[195.72000122070312],[197.02999877929688],[197.22999572753906],[198.1999969482422],[197.50999450683594],[196.24000549316406],[197.1199951171875],[196.33999633789062],[196.61000061035156],[197.60000610351562],[197.22999572753906],[197.9600067138672],[195.7100067138672],[197.7100067138672],[197.33999633789062],[198.1999969482422],[198.63999938964844],[198.64999389648438],[197.72000122070312],[197.8000030517578],[196.9499969482422],[196.97999572753906],[193.08999633789062],[192.5],[193.88999938964844],[192.00999450683594],[192.07000732421875],[191.02999877929688],[193.24000549316406],[193.8000030517578],[193.52999877929688],[194.83999633789062],[195.75999450683594],[195.72000122070312],[197.36000061035156],[198.38999938964844],[198.9199981689453],[199.5],[199.19000244140625],[200.1999969482422],[200.3300018310547],[200.25],[200.13999938964844],[200.7100067138672],[200.61000061035156],[200.5],[200.2100067138672],[201.11000061035156],[200.58999633789062],[199.32000732421875],[200.07000732421875],[200.3000030517578],[199.1300048828125],[198.97999572753906],[200.47999572753906],[200.75],[201.82000732421875],[200.6999969482422],[199.14999389648438],[198.00999450683594],[199.55999755859375],[196.33999633789062],[197.89999389648438],[197.5399932861328],[197.02000427246094],[194.35000610351562],[194.3800048828125],[196.52000427246094],[196.2899932861328],[193.25999450683594],[196.63999938964844],[192.74000549316406],[190.5399932861328],[187.41000366210938],[187.6999969482422],[186.42999267578125],[186.27000427246094],[188.47000122070312],[190.3000030517578],[194.07000732421875],[192.69000244140625],[194.92999267578125],[196.42999267578125],[196.16000366210938],[198.41000366210938],[198.11000061035156],[199.3800048828125],[201.66000366210938],[201.77000427246094],[201.07000732421875],[202.33999633789062],[203.14999389648438],[203.33999633789062],[203.97999572753906],[204.17999267578125],[203.9600067138672],[204.19000244140625],[204.24000549316406],[204.3699951171875],[205.5500030517578],[205.22000122070312],[205.5800018310547],[206.67999267578125],[207.25999450683594],[207.11000061035156],[207.63999938964844],[207.1999969482422],[205.75999450683594],[207.08999633789062],[207.88999938964844],[207.66000366210938],[208.0],[206.61000061035156],[206.47000122070312],[203.16000366210938],[204.19000244140625],[200.88999938964844],[199.50999450683594],[197.91000366210938],[201.7899932861328],[206.77999877929688],[206.52000427246094],[207.47000122070312],[207.75],[207.77000427246094],[208.44000244140625],[208.72000122070312],[207.60000610351562],[205.5399932861328],[205.42999267578125],[201.72000122070312],[199.82000732421875],[202.30999755859375],[205.89999389648438],[204.25],[202.64999389648438],[202.0800018310547],[200.86000061035156],[199.02000427246094],[201.6300048828125],[202.05999755859375],[203.0800018310547],[206.10000610351562],[204.97000122070312],[205.4499969482422],[202.74000549316406],[200.13999938964844],[201.99000549316406],[199.4499969482422],[201.9199981689453],[204.83999633789062],[204.05999755859375],[206.1199951171875],[205.5500030517578],[204.6300048828125],[206.80999755859375],[206.92999267578125],[208.9199981689453],[209.77999877929688],[210.11000061035156],[210.1300048828125],[209.97999572753906],[211.24000549316406],[211.2100067138672],[211.80999755859375],[211.6300048828125],[211.3800048828125],[210.66000366210938],[211.99000549316406],[211.1199951171875],[210.22999572753906],[210.4600067138672],[207.5],[208.36000061035156],[204.97999572753906],[204.5],[207.10000610351562],[205.8300018310547],[208.5800018310547],[207.9600067138672],[210.4600067138672],[209.5],[210.41000366210938],[210.0],[208.82000732421875],[205.75999450683594],[205.27000427246094],[205.74000549316406],[208.25],[206.42999267578125],[205.6999969482422],[206.44000244140625],[207.8300018310547],[207.27999877929688],[207.97999572753906],[208.89999389648438],[210.0399932861328],[209.08999633789062],[209.49000549316406],[210.42999267578125],[210.3699951171875],[207.9499969482422],[209.85000610351562],[209.60000610351562],[210.6300048828125],[211.16000366210938],[211.64999389648438],[210.77000427246094],[211.44000244140625],[210.57000732421875],[208.4600067138672],[210.72000122070312],[211.32000732421875],[208.89999389648438],[208.0399932861328],[208.8699951171875],[211.6199951171875],[210.61000061035156],[209.97999572753906],[210.02000427246094],[212.2100067138672],[212.44000244140625],[213.10000610351562],[213.02999877929688],[212.8800048828125],[213.5],[212.99000549316406],[210.6999969482422],[212.6999969482422],[212.4600067138672],[211.13999938964844],[211.57000732421875],[211.36000061035156],[211.9199981689453],[210.1300048828125],[209.77000427246094],[208.47999572753906],[208.4499969482422],[210.9499969482422],[211.6300048828125],[210.00999450683594],[209.11000061035156],[210.25],[210.58999633789062],[212.77999877929688],[210.80999755859375],[211.88999938964844],[212.0399932861328],[210.5],[209.86000061035156],[209.82000732421875],[205.4199981689453],[205.85000610351562],[207.5],[207.30999755859375],[206.72000122070312],[208.02000427246094],[204.52999877929688],[204.89999389648438],[207.47999572753906],[209.77000427246094],[210.67999267578125],[210.61000061035156],[212.3000030517578],[212.47999572753906],[212.58999633789062],[211.75],[211.3699951171875],[210.17999267578125],[208.0],[206.7899932861328],[209.3300018310547],[210.77000427246094],[210.82000732421875],[210.5],[209.7899932861328],[209.3800048828125],[210.07000732421875],[208.35000610351562],[207.9499969482422],[210.57000732421875],[208.6699981689453],[208.9199981689453],[208.66000366210938],[209.4199981689453],[210.58999633789062],[209.97999572753906],[208.32000732421875],[203.97000122070312],[197.8300018310547],[189.5],[187.27000427246094],[194.4600067138672],[199.27000427246094],[199.27999877929688],[197.6699981689453],[191.77000427246094],[195.41000366210938],[195.5500030517578],[192.58999633789062],[197.42999267578125],[194.7899932861328],[195.85000610351562],[196.74000549316406],[196.00999450683594],[198.4600067138672],[200.17999267578125],[199.72999572753906],[195.4499969482422],[196.4600067138672],[193.91000366210938],[193.60000610351562],[192.89999389648438],[192.85000610351562],[188.00999450683594],[188.1199951171875],[191.6300048828125],[192.1300048828125],[195.0],[198.47000122070312],[197.7899932861328],[199.41000366210938],[201.2100067138672],[201.3300018310547],[201.52000427246094],[200.25],[199.2899932861328],[202.35000610351562],[203.27000427246094],[203.3699951171875],[203.11000061035156],[201.85000610351562],[205.25999450683594],[207.50999450683594],[207.0],[206.60000610351562],[208.9499969482422],[208.8300018310547],[207.92999267578125],[210.38999938964844],[211.0],[210.36000061035156],[210.14999389648438],[210.0399932861328],[208.0800018310547],[208.55999755859375],[207.74000549316406],[204.83999633789062],[202.5399932861328],[205.6199951171875],[205.47000122070312],[208.72999572753906],[208.5500030517578],[209.30999755859375],[209.07000732421875],[209.35000610351562],[209.32000732421875],[209.55999755859375],[208.69000244140625],[210.67999267578125],[208.52999877929688],[205.61000061035156],[209.6199951171875],[208.35000610351562],[206.9499969482422],[205.33999633789062],[205.8699951171875],[201.8800048828125],[202.89999389648438],[205.02999877929688],[208.02999877929688],[204.86000061035156],[200.02000427246094],[201.6699981689453],[203.5],[206.02000427246094],[205.67999267578125],[205.2100067138672],[207.39999389648438],[205.92999267578125],[203.8699951171875],[201.02000427246094],[201.36000061035156],[198.82000732421875],[194.0500030517578],[191.9199981689453],[192.11000061035156],[193.66000366210938],[188.8300018310547],[191.92999267578125],[187.80999755859375],[188.05999755859375],[185.64999389648438],[186.69000244140625],[190.52000427246094],[187.63999938964844],[190.1999969482422],[188.1300048828125],[189.11000061035156],[193.72000122070312],[193.64999389648438],[190.16000366210938],[191.3000030517578],[191.60000610351562],[187.9499969482422],[185.4199981689453],[185.42999267578125],[185.27000427246094],[182.86000061035156],[186.6300048828125],[189.77999877929688],[192.8800048828125],[192.08999633789062],[192.0],[194.77999877929688],[192.32000732421875],[193.1999969482422],[195.5399932861328],[195.08999633789062],[193.55999755859375],[198.11000061035156],[199.0],[199.77999877929688],[200.42999267578125],[200.58999633789062],[198.39999389648438],[199.3800048828125],[199.5399932861328],[202.75999450683594],[202.5],[202.1699981689453],[203.33999633789062],[204.6300048828125],[204.3800048828125],[204.6699981689453],[204.55999755859375],[203.2100067138672],[203.1199951171875],[203.24000549316406],[205.1199951171875],[206.02000427246094],[205.52000427246094],[206.9199981689453],[206.25],[204.19000244140625],[206.4199981689453],[203.9499969482422],[204.5],[204.02000427246094],[205.9199981689453],[208.0],[208.00999450683594],[207.77999877929688],[209.24000549316406],[209.89999389648438],[210.10000610351562],[208.97000122070312],[208.97000122070312],[208.61000061035156],[208.9199981689453],[209.35000610351562],[207.4499969482422],[206.3300018310547],[207.97000122070312],[206.16000366210938],[205.00999450683594],[204.97000122070312],[205.72000122070312],[205.88999938964844],[208.4499969482422],[206.5],[206.55999755859375],[204.75999450683594],[206.77999877929688],[204.85000610351562],[204.91000366210938],[204.1999969482422],[205.49000549316406],[205.2100067138672],[207.8699951171875],[209.27999877929688],[209.33999633789062],[210.24000549316406],[209.83999633789062],[210.27000427246094],[210.91000366210938],[210.27999877929688],[211.35000610351562],[211.67999267578125],[212.3699951171875],[212.0800018310547],[210.07000732421875],[208.4499969482422],[208.0399932861328],[207.75],[208.3699951171875],[206.52000427246094],[207.85000610351562],[208.44000244140625],[208.10000610351562],[210.80999755859375],[203.24000549316406],[199.60000610351562],[203.1999969482422],[206.66000366210938],[209.47999572753906],[209.9199981689453],[208.41000366210938],[209.66000366210938],[209.52999877929688],[212.64999389648438],[213.39999389648438],[214.9499969482422],[214.9199981689453],[216.1199951171875],[215.8300018310547],[216.41000366210938],[216.19000244140625],[217.08999633789062],[216.27000427246094],[217.24000549316406],[216.64999389648438],[216.75],[216.52000427246094],[216.77000427246094],[217.1199951171875],[216.94000244140625],[215.5500030517578],[216.17999267578125],[216.41000366210938],[218.17999267578125],[218.0500030517578],[218.17999267578125],[217.63999938964844],[218.64999389648438],[218.4600067138672],[219.08999633789062],[217.9600067138672],[218.3699951171875],[218.86000061035156],[218.5399932861328],[218.52999877929688],[218.97000122070312],[217.85000610351562],[217.6999969482422],[217.2899932861328],[218.36000061035156],[218.0],[217.3800048828125],[217.38999938964844],[218.3699951171875],[219.02999877929688],[219.00999450683594],[218.50999450683594],[213.27999877929688],[216.33999633789062],[213.22999572753906],[213.14999389648438],[215.27999877929688],[213.3699951171875],[213.41000366210938],[213.4199981689453],[215.82000732421875],[217.17999267578125],[215.99000549316406],[214.24000549316406],[215.57000732421875],[216.63999938964844],[214.67999267578125],[216.3000030517578],[215.77999877929688],[214.67999267578125],[215.6300048828125],[215.77999877929688],[215.0399932861328],[216.16000366210938],[213.42999267578125],[213.7100067138672],[213.00999450683594],[213.1199951171875],[212.3800048828125],[213.7100067138672],[214.27999877929688],[213.8800048828125],[213.97999572753906],[214.88999938964844],[214.1699981689453],[213.74000549316406],[213.1699981689453],[212.5399932861328],[212.5500030517578],[211.00999450683594],[209.74000549316406],[208.77999877929688],[208.5500030517578],[213.14999389648438],[214.11000061035156],[216.3800048828125],[216.9199981689453],[216.4199981689453],[216.58999633789062],[218.27999877929688],[217.8699951171875],[218.99000549316406],[218.5],[220.14999389648438],[220.5800018310547],[220.6999969482422],[221.52000427246094],[220.47999572753906],[220.91000366210938],[220.3800048828125],[219.57000732421875],[219.67999267578125],[221.0],[221.6999969482422],[224.60000610351562],[225.14999389648438],[226.50999450683594],[226.25],[227.75999450683594],[225.8800048828125],[226.80999755859375],[225.0399932861328],[225.52999877929688],[226.39999389648438],[225.77000427246094],[225.3800048828125],[225.7100067138672],[226.27000427246094],[224.39999389648438],[224.35000610351562],[223.52999877929688],[225.24000549316406],[226.5800018310547],[226.39999389648438],[227.2100067138672],[226.4600067138672],[226.4600067138672],[227.10000610351562],[226.52999877929688],[227.0500030517578],[226.25],[226.75],[225.91000366210938],[226.74000549316406],[226.14999389648438],[227.60000610351562],[229.57000732421875],[229.3300018310547],[228.97000122070312],[227.5500030517578],[227.52999877929688],[227.6199951171875],[227.77000427246094],[229.33999633789062],[228.92999267578125],[228.94000244140625],[229.24000549316406],[230.60000610351562],[231.50999450683594],[232.77000427246094],[233.6999969482422],[234.9199981689453],[234.72000122070312],[235.08999633789062],[236.49000549316406],[236.27999877929688],[236.44000244140625],[236.74000549316406],[237.11000061035156],[236.47000122070312],[239.77999877929688],[238.27000427246094],[238.4199981689453],[237.7100067138672],[237.0],[236.55999755859375],[236.86000061035156],[237.69000244140625],[237.80999755859375],[236.89999389648438],[238.9499969482422],[238.47999572753906],[237.02999877929688],[236.77000427246094],[233.72999572753906],[234.27999877929688],[234.02999877929688],[233.86000061035156],[233.6199951171875],[235.32000732421875],[235.5399932861328],[236.2899932861328],[235.74000549316406],[235.3300018310547],[235.47999572753906],[234.77999877929688],[235.44000244140625],[235.1999969482422],[235.33999633789062],[235.05999755859375],[234.02999877929688],[232.50999450683594],[234.57000732421875],[233.8699951171875],[233.44000244140625],[235.33999633789062],[234.58999633789062],[237.1699981689453],[238.5500030517578],[238.39999389648438],[238.60000610351562],[238.0800018310547],[238.67999267578125],[238.77000427246094],[238.47999572753906],[238.75999450683594],[239.6999969482422],[239.66000366210938],[239.44000244140625],[239.8699951171875],[239.3800048828125],[238.97999572753906],[240.3000030517578],[240.0800018310547],[235.82000732421875],[236.77000427246094],[238.30999755859375],[239.52000427246094],[240.0500030517578],[240.61000061035156],[241.75999450683594],[241.7100067138672],[241.5],[241.44000244140625],[243.36000061035156],[244.1699981689453],[243.99000549316406],[243.2100067138672],[243.66000366210938],[243.77999877929688],[243.41000366210938],[243.36000061035156],[244.5500030517578],[244.24000549316406],[243.77000427246094],[242.63999938964844],[244.66000366210938],[243.00999450683594],[242.9499969482422],[242.83999633789062],[243.1300048828125],[243.2899932861328],[241.3300018310547],[243.49000549316406],[241.35000610351562],[241.8000030517578],[242.2100067138672],[242.77000427246094],[240.5500030517578],[242.11000061035156],[242.3699951171875],[242.19000244140625],[244.00999450683594],[244.4199981689453],[245.55999755859375],[245.52999877929688],[245.66000366210938],[246.99000549316406],[247.10000610351562],[246.8800048828125],[246.82000732421875],[247.4199981689453],[247.42999267578125],[247.1999969482422],[246.91000366210938],[246.77000427246094],[247.32000732421875],[247.44000244140625],[246.9600067138672],[247.41000366210938],[247.8699951171875],[247.25999450683594],[247.25],[243.75999450683594],[244.1199951171875],[246.5399932861328],[246.50999450683594],[246.94000244140625],[243.08999633789062],[242.7100067138672],[242.89999389648438],[245.44000244140625],[244.55999755859375],[243.99000549316406],[244.55999755859375],[244.57000732421875],[244.85000610351562],[246.00999450683594],[247.49000549316406],[247.83999633789062],[246.05999755859375],[246.89999389648438],[246.8699951171875],[246.5800018310547],[249.2100067138672],[250.0500030517578],[250.1699981689453],[250.08999633789062],[249.19000244140625],[249.72000122070312],[249.97000122070312],[250.05999755859375],[249.38999938964844],[249.44000244140625],[248.92999267578125],[249.0800018310547],[250.0500030517578],[250.35000610351562],[251.22999572753906],[252.32000732421875],[252.86000061035156],[253.16000366210938],[254.66000366210938],[254.3699951171875],[253.9499969482422],[254.6199951171875],[255.02000427246094],[254.63999938964844],[254.9499969482422],[255.2899932861328],[255.47000122070312],[255.72000122070312],[255.7899932861328],[257.1099853515625],[256.1099853515625],[256.55999755859375],[255.2899932861328],[255.6199951171875],[257.7099914550781],[256.75],[257.1499938964844],[257.489990234375],[257.5899963378906],[258.45001220703125],[258.8500061035156],[258.6700134277344],[259.1099853515625],[258.1700134277344],[258.0899963378906],[258.3299865722656],[257.7300109863281],[256.44000244140625],[258.6199951171875],[257.8599853515625],[258.29998779296875],[259.989990234375],[259.760009765625],[260.3599853515625],[260.2300109863281],[262.8699951171875],[262.7099914550781],[265.010009765625],[264.4599914550781],[264.1400146484375],[263.19000244140625],[263.239990234375],[264.07000732421875],[265.510009765625],[266.30999755859375],[266.7799987792969],[266.75],[265.6600036621094],[266.510009765625],[268.20001220703125],[267.1700134277344],[267.0299987792969],[267.5799865722656],[267.510009765625],[267.19000244140625],[267.32000732421875],[267.8699951171875],[266.8599853515625]],\"high\":[[184.07000732421875],[183.60000610351562],[183.55999755859375],[183.7899932861328],[183.8300018310547],[184.1300048828125],[184.22000122070312],[184.17999267578125],[183.77000427246094],[184.94000244140625],[184.66000366210938],[184.4499969482422],[184.77000427246094],[184.57000732421875],[183.39999389648438],[181.66000366210938],[179.52000427246094],[179.3000030517578],[178.5500030517578],[179.80999755859375],[179.2899932861328],[178.3699951171875],[175.83999633789062],[175.55999755859375],[177.47999572753906],[179.8699951171875],[180.07000732421875],[182.44000244140625],[182.8300018310547],[183.1999969482422],[184.36000061035156],[184.49000549316406],[184.9499969482422],[184.52000427246094],[184.88999938964844],[186.14999389648438],[185.58999633789062],[185.60000610351562],[185.8699951171875],[187.14999389648438],[185.4499969482422],[187.97999572753906],[188.07000732421875],[188.61000061035156],[188.9600067138672],[188.22999572753906],[188.7100067138672],[187.35000610351562],[187.99000549316406],[185.8000030517578],[186.77000427246094],[187.91000366210938],[187.94000244140625],[187.88999938964844],[189.02000427246094],[187.07000732421875],[186.94000244140625],[187.33999633789062],[185.33999633789062],[186.4199981689453],[187.3000030517578],[188.36000061035156],[189.1300048828125],[189.22000122070312],[189.6999969482422],[186.25999450683594],[185.39999389648438],[187.14999389648438],[187.1699981689453],[183.4199981689453],[183.3699951171875],[184.3300018310547],[186.13999938964844],[186.91000366210938],[187.10000610351562],[188.39999389648438],[187.9199981689453],[188.38999938964844],[187.3300018310547],[187.69000244140625],[188.0399932861328],[188.5],[188.83999633789062],[189.13999938964844],[188.5500030517578],[188.1300048828125],[187.97000122070312],[189.0500030517578],[188.0399932861328],[189.8800048828125],[190.4199981689453],[189.8800048828125],[188.72000122070312],[188.1300048828125],[188.88999938964844],[188.6699981689453],[189.22000122070312],[189.97999572753906],[190.47999572753906],[191.5800018310547],[191.82000732421875],[192.39999389648438],[192.8000030517578],[192.99000549316406],[192.89999389648438],[193.3000030517578],[194.64999389648438],[195.42999267578125],[196.0500030517578],[195.63999938964844],[195.1199951171875],[194.8000030517578],[194.32000732421875],[194.6999969482422],[194.97000122070312],[196.3699951171875],[196.60000610351562],[196.10000610351562],[196.0500030517578],[196.5],[195.77999877929688],[195.6300048828125],[195.8800048828125],[196.1699981689453],[197.6300048828125],[197.47999572753906],[198.2899932861328],[197.97999572753906],[197.22000122070312],[197.3000030517578],[196.86000061035156],[196.75],[197.86000061035156],[198.10000610351562],[198.25999450683594],[198.10000610351562],[197.91000366210938],[197.5],[198.55999755859375],[198.85000610351562],[199.05999755859375],[198.25999450683594],[198.08999633789062],[198.4499969482422],[197.91000366210938],[195.77999877929688],[193.75999450683594],[194.3000030517578],[193.60000610351562],[192.88999938964844],[193.1300048828125],[193.3699951171875],[194.66000366210938],[194.14999389648438],[195.05999755859375],[195.75999450683594],[196.64999389648438],[197.4499969482422],[198.5399932861328],[199.16000366210938],[199.75999450683594],[199.69000244140625],[200.58999633789062],[200.82000732421875],[200.57000732421875],[200.27000427246094],[200.72999572753906],[201.0],[201.41000366210938],[201.5800018310547],[201.19000244140625],[201.2100067138672],[200.5500030517578],[200.1999969482422],[200.3300018310547],[200.1199951171875],[199.32000732421875],[200.83999633789062],[201.67999267578125],[201.85000610351562],[201.89999389648438],[200.3800048828125],[199.25999450683594],[199.69000244140625],[199.0500030517578],[198.38999938964844],[197.88999938964844],[198.3000030517578],[196.77000427246094],[195.05999755859375],[196.94000244140625],[197.60000610351562],[195.72000122070312],[196.9199981689453],[196.60000610351562],[193.64999389648438],[191.14999389648438],[189.82000732421875],[187.69000244140625],[187.5800018310547],[189.75],[190.4499969482422],[194.1999969482422],[194.91000366210938],[196.1999969482422],[196.49000549316406],[196.4499969482422],[198.4199981689453],[199.1199951171875],[199.9499969482422],[201.82000732421875],[202.4499969482422],[201.60000610351562],[202.58999633789062],[203.25999450683594],[203.60000610351562],[204.0399932861328],[204.30999755859375],[204.24000549316406],[204.8300018310547],[204.49000549316406],[204.5800018310547],[205.9199981689453],[205.5500030517578],[205.7100067138672],[207.83999633789062],[207.38999938964844],[207.7899932861328],[207.75999450683594],[207.8699951171875],[206.5399932861328],[207.33999633789062],[208.14999389648438],[208.27000427246094],[208.47000122070312],[208.1199951171875],[206.60000610351562],[205.97999572753906],[206.19000244140625],[203.82000732421875],[202.52999877929688],[202.39999389648438],[202.33999633789062],[212.97000122070312],[207.3300018310547],[207.47000122070312],[208.22999572753906],[208.33999633789062],[208.85000610351562],[208.97000122070312],[208.3699951171875],[208.19000244140625],[206.8800048828125],[204.3699951171875],[202.72000122070312],[202.72000122070312],[206.16000366210938],[206.4199981689453],[204.60000610351562],[205.47999572753906],[201.10000610351562],[202.00999450683594],[201.82000732421875],[202.72000122070312],[203.66000366210938],[206.25999450683594],[206.10000610351562],[205.55999755859375],[204.1199951171875],[204.2899932861328],[202.3000030517578],[202.1699981689453],[202.02999877929688],[204.85000610351562],[205.3800048828125],[206.3000030517578],[207.24000549316406],[205.63999938964844],[207.1199951171875],[207.4499969482422],[208.99000549316406],[209.83999633789062],[210.32000732421875],[210.22000122070312],[210.4199981689453],[211.3300018310547],[211.2100067138672],[212.0500030517578],[212.24000549316406],[211.7100067138672],[211.5800018310547],[212.05999755859375],[212.0500030517578],[210.49000549316406],[210.8000030517578],[209.94000244140625],[208.7899932861328],[206.80999755859375],[205.5],[207.17999267578125],[207.92999267578125],[208.69000244140625],[208.4199981689453],[211.27000427246094],[210.47000122070312],[211.02000427246094],[211.11000061035156],[210.39999389648438],[209.35000610351562],[206.3699951171875],[205.9499969482422],[208.61000061035156],[208.10000610351562],[206.4199981689453],[206.97999572753906],[208.4499969482422],[208.75999450683594],[208.50999450683594],[209.17999267578125],[210.08999633789062],[210.6300048828125],[209.7100067138672],[211.0399932861328],[210.97999572753906],[209.22999572753906],[210.25],[210.86000061035156],[210.85000610351562],[211.94000244140625],[211.97000122070312],[212.47999572753906],[211.5],[211.2899932861328],[210.35000610351562],[210.77000427246094],[212.02000427246094],[211.4600067138672],[209.92999267578125],[209.3800048828125],[211.86000061035156],[211.88999938964844],[210.6300048828125],[211.22000122070312],[212.32000732421875],[212.61000061035156],[213.39999389648438],[213.57000732421875],[213.77999877929688],[213.75],[213.5399932861328],[212.91000366210938],[212.97999572753906],[212.58999633789062],[212.42999267578125],[212.33999633789062],[212.19000244140625],[212.6699981689453],[211.86000061035156],[210.5800018310547],[209.82000732421875],[209.10000610351562],[211.41000366210938],[212.08999633789062],[211.47999572753906],[209.4499969482422],[210.35000610351562],[211.32000732421875],[213.33999633789062],[211.5500030517578],[212.58999633789062],[212.44000244140625],[212.1699981689453],[211.25],[210.5800018310547],[209.8300018310547],[207.32000732421875],[208.02999877929688],[208.27000427246094],[207.64999389648438],[208.1699981689453],[206.75999450683594],[207.35000610351562],[207.97999572753906],[209.89999389648438],[211.0500030517578],[211.27999877929688],[212.3000030517578],[212.5500030517578],[213.17999267578125],[212.74000549316406],[211.77000427246094],[211.64999389648438],[210.3699951171875],[207.5500030517578],[209.5],[211.0399932861328],[211.02000427246094],[211.4499969482422],[210.52999877929688],[210.25],[211.30999755859375],[210.4199981689453],[208.33999633789062],[210.6699981689453],[209.47000122070312],[209.13999938964844],[209.5500030517578],[209.50999450683594],[210.58999633789062],[210.67999267578125],[210.00999450683594],[208.2899932861328],[203.94000244140625],[197.47999572753906],[195.4499969482422],[194.7899932861328],[199.4199981689453],[199.83999633789062],[199.1300048828125],[194.77000427246094],[195.4600067138672],[198.0500030517578],[193.86000061035156],[197.61000061035156],[199.47000122070312],[197.22000122070312],[196.82000732421875],[197.00999450683594],[198.99000549316406],[200.41000366210938],[202.88999938964844],[198.67999267578125],[197.67999267578125],[194.4600067138672],[194.6699981689453],[193.4499969482422],[195.0],[191.91000366210938],[189.74000549316406],[191.8300018310547],[192.49000549316406],[195.02999877929688],[198.74000549316406],[198.97999572753906],[199.8300018310547],[201.5500030517578],[201.89999389648438],[201.75999450683594],[202.16000366210938],[200.8699951171875],[202.36000061035156],[203.2899932861328],[203.3699951171875],[203.83999633789062],[203.7899932861328],[205.50999450683594],[207.9499969482422],[207.3699951171875],[207.0],[208.97999572753906],[209.27000427246094],[209.44000244140625],[210.6199951171875],[211.66000366210938],[211.5],[210.97999572753906],[210.32000732421875],[209.49000549316406],[208.60000610351562],[208.94000244140625],[207.05999755859375],[204.6699981689453],[205.69000244140625],[207.0399932861328],[208.89999389648438],[209.0500030517578],[210.1199951171875],[209.97999572753906],[209.8300018310547],[209.74000549316406],[209.8000030517578],[209.88999938964844],[210.82000732421875],[211.0],[209.14999389648438],[209.97000122070312],[209.72999572753906],[208.2899932861328],[208.67999267578125],[207.42999267578125],[204.13999938964844],[203.0500030517578],[206.11000061035156],[208.38999938964844],[208.47999572753906],[202.92999267578125],[201.8800048828125],[203.85000610351562],[206.07000732421875],[206.3300018310547],[205.25999450683594],[207.7899932861328],[207.2100067138672],[205.88999938964844],[201.02999877929688],[201.89999389648438],[200.05999755859375],[197.44000244140625],[195.85000610351562],[193.41000366210938],[194.5500030517578],[194.86000061035156],[193.25999450683594],[188.75999450683594],[190.11000061035156],[187.5],[188.8699951171875],[190.75999450683594],[190.14999389648438],[190.52999877929688],[191.55999755859375],[190.1999969482422],[193.8800048828125],[194.5800018310547],[191.97000122070312],[191.77999877929688],[192.75],[191.6699981689453],[186.1199951171875],[186.94000244140625],[188.33999633789062],[184.10000610351562],[186.64999389648438],[189.80999755859375],[193.32000732421875],[193.27000427246094],[192.17999267578125],[194.9499969482422],[194.32000732421875],[193.52999877929688],[195.5500030517578],[196.67999267578125],[196.22999572753906],[198.2100067138672],[199.05999755859375],[199.8000030517578],[201.35000610351562],[201.07000732421875],[199.9199981689453],[199.7899932861328],[201.07000732421875],[202.80999755859375],[203.0399932861328],[202.52999877929688],[203.82000732421875],[205.22999572753906],[204.77999877929688],[204.94000244140625],[205.22999572753906],[204.3300018310547],[203.16000366210938],[203.86000061035156],[205.25],[206.8699951171875],[206.41000366210938],[207.13999938964844],[207.07000732421875],[206.25999450683594],[206.49000549316406],[205.55999755859375],[205.85000610351562],[206.07000732421875],[206.25],[208.10000610351562],[208.60000610351562],[208.1699981689453],[209.27999877929688],[210.1999969482422],[210.9199981689453],[210.25],[209.2899932861328],[208.66000366210938],[209.52000427246094],[209.80999755859375],[209.75999450683594],[207.1300048828125],[208.17999267578125],[206.8000030517578],[205.85000610351562],[205.97999572753906],[205.77000427246094],[206.39999389648438],[208.47000122070312],[208.5399932861328],[207.49000549316406],[206.86000061035156],[207.33999633789062],[206.8000030517578],[206.3000030517578],[204.5399932861328],[206.10000610351562],[205.83999633789062],[208.24000549316406],[209.77000427246094],[209.7100067138672],[210.25],[210.69000244140625],[210.47999572753906],[210.92999267578125],[210.69000244140625],[211.77000427246094],[212.33999633789062],[212.52000427246094],[212.22000122070312],[210.86000061035156],[210.3699951171875],[208.74000549316406],[209.36000061035156],[208.57000732421875],[207.1999969482422],[209.61000061035156],[208.9199981689453],[209.5],[210.8699951171875],[210.85000610351562],[201.60000610351562],[203.22999572753906],[206.92999267578125],[209.5399932861328],[210.49000549316406],[209.0800018310547],[209.8000030517578],[210.64999389648438],[212.94000244140625],[214.07000732421875],[215.3000030517578],[215.4499969482422],[216.6699981689453],[217.00999450683594],[216.60000610351562],[216.22999572753906],[217.3699951171875],[217.22000122070312],[217.3000030517578],[217.05999755859375],[217.1699981689453],[217.27000427246094],[217.11000061035156],[217.5399932861328],[217.64999389648438],[216.8300018310547],[216.25],[216.77999877929688],[218.22999572753906],[218.52000427246094],[218.75999450683594],[218.39999389648438],[218.94000244140625],[218.7100067138672],[219.5],[218.67999267578125],[218.52999877929688],[218.89999389648438],[218.75],[218.8000030517578],[219.60000610351562],[218.91000366210938],[218.19000244140625],[219.1199951171875],[218.6699981689453],[218.58999633789062],[217.75],[217.72999572753906],[218.8699951171875],[219.1199951171875],[219.22000122070312],[218.94000244140625],[217.02999877929688],[216.80999755859375],[215.14999389648438],[214.6999969482422],[215.72999572753906],[213.69000244140625],[214.8800048828125],[214.58999633789062],[216.02999877929688],[217.52999877929688],[216.8800048828125],[215.22999572753906],[215.67999267578125],[216.82000732421875],[216.8699951171875],[217.1199951171875],[216.0399932861328],[216.1699981689453],[216.1300048828125],[216.0399932861328],[216.3000030517578],[216.6999969482422],[215.74000549316406],[214.32000732421875],[213.58999633789062],[214.69000244140625],[213.38999938964844],[214.30999755859375],[214.63999938964844],[214.52999877929688],[214.0800018310547],[215.32000732421875],[214.97999572753906],[214.4199981689453],[214.6199951171875],[213.92999267578125],[213.19000244140625],[212.99000549316406],[211.10000610351562],[210.24000549316406],[209.88999938964844],[213.19000244140625],[214.77000427246094],[217.10000610351562],[218.30999755859375],[216.6999969482422],[217.27000427246094],[218.27999877929688],[218.13999938964844],[219.05999755859375],[219.27000427246094],[220.17999267578125],[220.7899932861328],[220.75999450683594],[221.55999755859375],[221.47999572753906],[221.44000244140625],[221.82000732421875],[220.72999572753906],[220.25],[221.39999389648438],[221.74000549316406],[224.6699981689453],[225.6999969482422],[226.52999877929688],[226.9600067138672],[228.33999633789062],[228.22999572753906],[227.80999755859375],[226.0800018310547],[226.02000427246094],[226.57000732421875],[226.4499969482422],[225.74000549316406],[225.72000122070312],[226.72999572753906],[226.58999633789062],[224.88999938964844],[224.8300018310547],[225.8300018310547],[226.75],[226.5800018310547],[227.75],[227.07000732421875],[227.4499969482422],[227.10000610351562],[226.75],[227.39999389648438],[226.77999877929688],[226.8000030517578],[227.0],[227.30999755859375],[226.80999755859375],[228.0800018310547],[229.57000732421875],[229.7100067138672],[229.58999633789062],[228.1999969482422],[227.60000610351562],[228.58999633789062],[228.10000610351562],[229.5500030517578],[229.3300018310547],[229.66000366210938],[229.38999938964844],[230.9499969482422],[231.77000427246094],[233.07000732421875],[233.7100067138672],[235.13999938964844],[235.16000366210938],[235.08999633789062],[236.69000244140625],[236.5399932861328],[236.89999389648438],[236.7899932861328],[237.30999755859375],[236.9499969482422],[240.32000732421875],[239.57000732421875],[238.61000061035156],[238.1199951171875],[237.77000427246094],[237.63999938964844],[237.24000549316406],[238.02000427246094],[237.86000061035156],[237.24000549316406],[239.44000244140625],[239.1999969482422],[237.97000122070312],[237.36000061035156],[237.61000061035156],[234.61000061035156],[235.33999633789062],[235.0399932861328],[233.9199981689453],[235.80999755859375],[235.80999755859375],[236.52000427246094],[236.50999450683594],[236.02999877929688],[235.5800018310547],[237.38999938964844],[236.0399932861328],[236.0],[236.25999450683594],[235.17999267578125],[234.9600067138672],[234.49000549316406],[234.57000732421875],[234.49000549316406],[234.9499969482422],[235.85000610351562],[235.30999755859375],[237.41000366210938],[238.9499969482422],[239.52999877929688],[238.9499969482422],[238.92999267578125],[239.1699981689453],[238.97999572753906],[238.8800048828125],[238.9199981689453],[239.72000122070312],[239.9199981689453],[240.19000244140625],[239.8699951171875],[239.57000732421875],[239.42999267578125],[240.44000244140625],[240.6699981689453],[240.0800018310547],[237.75],[239.0800018310547],[239.7100067138672],[240.24000549316406],[240.72999572753906],[242.0800018310547],[241.89999389648438],[241.7899932861328],[241.8800048828125],[243.3800048828125],[244.35000610351562],[244.3000030517578],[243.97999572753906],[243.9199981689453],[244.3300018310547],[245.00999450683594],[243.4199981689453],[244.61000061035156],[244.8699951171875],[243.91000366210938],[242.8300018310547],[244.72999572753906],[244.25999450683594],[243.58999633789062],[243.52999877929688],[243.50999450683594],[244.3800048828125],[243.3800048828125],[243.72000122070312],[243.72000122070312],[242.7100067138672],[243.3800048828125],[243.00999450683594],[242.02999877929688],[242.27999877929688],[242.8000030517578],[242.5500030517578],[244.1999969482422],[244.5500030517578],[245.97000122070312],[245.91000366210938],[245.72000122070312],[247.0],[247.4199981689453],[246.91000366210938],[246.97999572753906],[247.8000030517578],[247.7899932861328],[248.0],[247.05999755859375],[247.47999572753906],[247.5],[247.60000610351562],[247.33999633789062],[247.7899932861328],[247.8699951171875],[248.91000366210938],[247.30999755859375],[246.44000244140625],[244.8000030517578],[246.7899932861328],[247.0],[247.57000732421875],[246.60000610351562],[244.19000244140625],[243.1999969482422],[245.6199951171875],[245.0500030517578],[245.17999267578125],[245.61000061035156],[245.1999969482422],[245.14999389648438],[246.32000732421875],[247.77000427246094],[248.3300018310547],[247.52000427246094],[247.27999877929688],[247.27000427246094],[247.11000061035156],[249.3000030517578],[250.08999633789062],[250.2100067138672],[250.32000732421875],[249.2899932861328],[250.1199951171875],[250.07000732421875],[250.19000244140625],[249.97999572753906],[249.6300048828125],[249.5500030517578],[249.6999969482422],[250.49000549316406],[250.44000244140625],[251.32000732421875],[252.32000732421875],[252.88999938964844],[253.44000244140625],[254.67999267578125],[254.6999969482422],[254.6999969482422],[255.0500030517578],[255.02000427246094],[255.05999755859375],[255.27000427246094],[255.50999450683594],[255.52000427246094],[255.9499969482422],[255.8300018310547],[257.1400146484375],[257.510009765625],[256.8299865722656],[256.30999755859375],[256.29998779296875],[257.8900146484375],[257.6000061035156],[257.44000244140625],[258.42999267578125],[257.75],[258.5],[259.0],[259.3500061035156],[259.2200012207031],[258.3900146484375],[258.2900085449219],[258.5899963378906],[257.8500061035156],[257.2200012207031],[259.0400085449219],[258.5899963378906],[258.5199890136719],[260.20001220703125],[260.1499938964844],[260.4800109863281],[260.75],[262.8999938964844],[263.6300048828125],[266.04998779296875],[265.30999755859375],[266.79998779296875],[265.1499938964844],[263.7300109863281],[264.42999267578125],[265.5199890136719],[266.3800048828125],[267.32000732421875],[267.55999755859375],[267.2200012207031],[267.0400085449219],[268.6000061035156],[268.5299987792969],[268.3299865722656],[268.3900146484375],[267.6400146484375],[267.44000244140625],[267.7300109863281],[267.9200134277344],[268.54998779296875]],\"low\":[[182.47999572753906],[182.6300048828125],[182.0800018310547],[182.9499969482422],[182.88999938964844],[182.8000030517578],[183.00999450683594],[181.33999633789062],[181.9499969482422],[183.7100067138672],[183.8300018310547],[183.32000732421875],[183.0500030517578],[183.91000366210938],[181.82000732421875],[178.8300018310547],[177.1199951171875],[178.1199951171875],[176.8800048828125],[178.25999450683594],[176.9199981689453],[173.8300018310547],[174.11000061035156],[173.7100067138672],[175.22000122070312],[177.72999572753906],[179.2100067138672],[180.0399932861328],[181.7100067138672],[180.8300018310547],[182.6699981689453],[183.64999389648438],[182.8699951171875],[182.60000610351562],[183.8000030517578],[184.1999969482422],[184.22999572753906],[184.3300018310547],[184.3699951171875],[185.0500030517578],[183.75],[186.75],[187.4499969482422],[187.77999877929688],[187.42999267578125],[187.0800018310547],[186.8000030517578],[185.89999389648438],[184.66000366210938],[184.44000244140625],[185.50999450683594],[186.50999450683594],[185.47000122070312],[185.9199981689453],[186.02999877929688],[184.6199951171875],[185.27000427246094],[184.9199981689453],[183.89999389648438],[185.0],[185.52000427246094],[187.0],[188.13999938964844],[188.0500030517578],[186.10000610351562],[183.9600067138672],[183.58999633789062],[185.05999755859375],[182.92999267578125],[181.30999755859375],[181.44000244140625],[181.50999450683594],[184.64999389648438],[185.55999755859375],[186.2100067138672],[187.1300048828125],[187.3000030517578],[186.92999267578125],[185.8699951171875],[184.9600067138672],[187.0800018310547],[187.17999267578125],[187.72999572753906],[187.77999877929688],[186.6199951171875],[186.74000549316406],[186.00999450683594],[187.0800018310547],[186.8300018310547],[188.0],[189.77000427246094],[188.7899932861328],[186.47999572753906],[186.72000122070312],[187.52000427246094],[187.07000732421875],[188.05999755859375],[188.86000061035156],[189.58999633789062],[190.9499969482422],[191.05999755859375],[191.3300018310547],[192.02999877929688],[191.97000122070312],[192.25],[192.27000427246094],[192.6999969482422],[194.77999877929688],[195.1699981689453],[194.9199981689453],[194.47999572753906],[193.11000061035156],[193.3000030517578],[193.66000366210938],[193.80999755859375],[194.39999389648438],[195.8000030517578],[195.6999969482422],[195.52000427246094],[194.47999572753906],[194.25],[194.1300048828125],[194.88999938964844],[195.52999877929688],[196.1300048828125],[196.9600067138672],[197.63999938964844],[197.22000122070312],[195.75999450683594],[196.30999755859375],[195.05999755859375],[195.77999877929688],[197.44000244140625],[196.36000061035156],[197.4199981689453],[195.42999267578125],[196.24000549316406],[196.42999267578125],[197.8699951171875],[198.10000610351562],[198.4499969482422],[197.3300018310547],[196.6199951171875],[196.9199981689453],[196.16000366210938],[192.97000122070312],[191.57000732421875],[192.0500030517578],[191.30999755859375],[191.0800018310547],[190.5500030517578],[190.9499969482422],[193.7100067138672],[192.94000244140625],[193.9600067138672],[194.97999572753906],[194.30999755859375],[196.69000244140625],[197.44000244140625],[198.0800018310547],[198.92999267578125],[198.74000549316406],[199.14999389648438],[200.27999877929688],[199.94000244140625],[199.38999938964844],[199.82000732421875],[199.86000061035156],[200.22000122070312],[199.66000366210938],[199.41000366210938],[200.0],[198.91000366210938],[198.77000427246094],[199.1199951171875],[198.55999755859375],[198.3800048828125],[198.5],[199.75],[201.10000610351562],[200.2899932861328],[198.72999572753906],[197.9499969482422],[197.52000427246094],[196.27000427246094],[196.4199981689453],[196.0500030517578],[196.61000061035156],[193.91000366210938],[192.35000610351562],[195.0800018310547],[195.5800018310547],[193.22000122070312],[192.36000061035156],[192.5800018310547],[190.49000549316406],[187.3000030517578],[187.0399932861328],[181.9199981689453],[182.88999938964844],[187.6199951171875],[188.07000732421875],[191.47999572753906],[192.61000061035156],[194.25999450683594],[194.49000549316406],[195.02999877929688],[196.72999572753906],[196.8000030517578],[197.39999389648438],[200.77000427246094],[201.30999755859375],[200.05999755859375],[201.4499969482422],[201.63999938964844],[202.61000061035156],[203.1300048828125],[203.64999389648438],[203.30999755859375],[203.2100067138672],[203.72000122070312],[203.64999389648438],[204.44000244140625],[204.3000030517578],[204.17999267578125],[205.97999572753906],[206.91000366210938],[206.8000030517578],[207.02999877929688],[206.91000366210938],[205.3800048828125],[205.77999877929688],[207.10000610351562],[206.6999969482422],[207.5500030517578],[205.92999267578125],[203.91000366210938],[202.92999267578125],[203.7100067138672],[200.85000610351562],[198.77999877929688],[197.86000061035156],[198.2899932861328],[203.9199981689453],[205.61000061035156],[206.4600067138672],[207.39999389648438],[207.72000122070312],[208.25],[208.13999938964844],[207.50999450683594],[205.38999938964844],[204.17999267578125],[201.35000610351562],[198.86000061035156],[200.8800048828125],[203.99000549316406],[203.50999450683594],[201.9199981689453],[200.50999450683594],[198.57000732421875],[198.8800048828125],[198.5500030517578],[200.1699981689453],[200.94000244140625],[202.3300018310547],[204.80999755859375],[203.85000610351562],[201.74000549316406],[199.91000366210938],[198.67999267578125],[199.1300048828125],[197.86000061035156],[202.5500030517578],[203.50999450683594],[204.77000427246094],[204.9199981689453],[204.13999938964844],[204.67999267578125],[205.8300018310547],[206.97000122070312],[208.75999450683594],[209.10000610351562],[209.33999633789062],[209.24000549316406],[208.72999572753906],[210.47999572753906],[210.75999450683594],[211.22000122070312],[210.64999389648438],[210.60000610351562],[210.72000122070312],[210.0800018310547],[209.05999755859375],[209.85000610351562],[207.10000610351562],[207.5500030517578],[204.92999267578125],[204.39999389648438],[205.1999969482422],[204.5800018310547],[205.86000061035156],[206.97999572753906],[206.6199951171875],[209.02999877929688],[209.49000549316406],[210.0],[208.74000549316406],[205.7100067138672],[204.1199951171875],[204.89999389648438],[206.9600067138672],[206.36000061035156],[204.50999450683594],[205.39999389648438],[205.2100067138672],[207.24000549316406],[207.0800018310547],[207.19000244140625],[208.9600067138672],[209.02999877929688],[208.10000610351562],[209.9499969482422],[209.7899932861328],[207.00999450683594],[208.9600067138672],[209.24000549316406],[208.89999389648438],[210.00999450683594],[211.11000061035156],[210.5399932861328],[209.3300018310547],[209.60000610351562],[207.6199951171875],[209.27999877929688],[211.10000610351562],[208.72999572753906],[206.75999450683594],[207.52000427246094],[210.77999877929688],[210.52000427246094],[208.6199951171875],[209.74000549316406],[210.91000366210938],[211.86000061035156],[212.16000366210938],[212.69000244140625],[212.5],[212.50999450683594],[212.91000366210938],[210.1999969482422],[210.75999450683594],[211.6300048828125],[210.82000732421875],[210.6199951171875],[210.27000427246094],[211.3300018310547],[209.75],[208.97999572753906],[208.38999938964844],[207.69000244140625],[209.3000030517578],[211.1999969482422],[209.67999267578125],[207.7899932861328],[208.72000122070312],[209.36000061035156],[210.6300048828125],[210.36000061035156],[211.63999938964844],[211.57000732421875],[210.47000122070312],[209.77000427246094],[209.16000366210938],[205.3300018310547],[205.27999877929688],[206.55999755859375],[206.80999755859375],[205.52999877929688],[204.11000061035156],[204.25],[204.77000427246094],[204.9499969482422],[208.94000244140625],[209.64999389648438],[210.0399932861328],[211.5800018310547],[211.8000030517578],[212.2100067138672],[211.38999938964844],[210.88999938964844],[209.75],[207.60000610351562],[206.25999450683594],[206.8000030517578],[209.30999755859375],[209.4199981689453],[210.16000366210938],[208.64999389648438],[208.8000030517578],[209.72999572753906],[207.64999389648438],[206.8699951171875],[209.27999877929688],[207.75999450683594],[205.36000061035156],[208.00999450683594],[208.25999450683594],[208.16000366210938],[209.6999969482422],[207.35000610351562],[203.89999389648438],[197.52000427246094],[182.39999389648438],[186.9199981689453],[188.3699951171875],[195.2100067138672],[197.9199981689453],[197.00999450683594],[190.72999572753906],[192.4199981689453],[194.9600067138672],[191.61000061035156],[195.1699981689453],[194.35000610351562],[194.25],[194.52999877929688],[195.42999267578125],[195.9600067138672],[198.41000366210938],[199.27999877929688],[194.9600067138672],[195.2100067138672],[192.55999755859375],[192.91000366210938],[190.55999755859375],[191.80999755859375],[187.63999938964844],[186.92999267578125],[189.44000244140625],[189.82000732421875],[189.1199951171875],[196.3300018310547],[197.0],[197.47999572753906],[198.58999633789062],[200.5800018310547],[200.91000366210938],[200.0500030517578],[198.94000244140625],[199.63999938964844],[201.9199981689453],[202.1300048828125],[202.5500030517578],[201.64999389648438],[201.85000610351562],[206.3000030517578],[206.55999755859375],[205.7899932861328],[206.2100067138672],[208.2100067138672],[207.74000549316406],[208.1699981689453],[209.6999969482422],[209.72000122070312],[209.08999633789062],[208.4600067138672],[206.9499969482422],[207.19000244140625],[207.66000366210938],[204.82000732421875],[202.44000244140625],[202.17999267578125],[204.8800048828125],[205.99000549316406],[208.1999969482422],[208.86000061035156],[208.52000427246094],[207.41000366210938],[209.00999450683594],[208.86000061035156],[208.55999755859375],[209.11000061035156],[208.22999572753906],[204.75],[205.61000061035156],[207.1999969482422],[205.77999877929688],[204.17999267578125],[205.13999938964844],[201.50999450683594],[199.9499969482422],[202.8699951171875],[204.8000030517578],[204.83999633789062],[199.8300018310547],[200.08999633789062],[201.5500030517578],[204.5800018310547],[205.4199981689453],[203.94000244140625],[206.47000122070312],[205.75999450683594],[203.8699951171875],[198.58999633789062],[200.0500030517578],[197.60000610351562],[193.58999633789062],[191.5800018310547],[189.82000732421875],[191.13999938964844],[188.3800048828125],[187.66000366210938],[185.52000427246094],[186.1999969482422],[181.02000427246094],[184.63999938964844],[188.8800048828125],[187.41000366210938],[188.02000427246094],[187.05999755859375],[187.16000366210938],[189.8800048828125],[191.83999633789062],[189.5399932861328],[187.10000610351562],[189.9600067138672],[187.1999969482422],[182.8000030517578],[183.1999969482422],[185.1199951171875],[181.08999633789062],[183.9600067138672],[187.6300048828125],[191.00999450683594],[191.72000122070312],[190.4499969482422],[193.7899932861328],[192.17999267578125],[189.32000732421875],[192.8300018310547],[194.89999389648438],[193.3300018310547],[194.4499969482422],[197.25],[198.11000061035156],[199.02999877929688],[199.25],[198.2100067138672],[198.42999267578125],[197.3800048828125],[199.52000427246094],[201.77000427246094],[201.0500030517578],[201.5500030517578],[202.77000427246094],[203.8000030517578],[203.8000030517578],[203.57000732421875],[203.00999450683594],[201.74000549316406],[202.7100067138672],[202.39999389648438],[205.58999633789062],[205.3300018310547],[203.97999572753906],[205.88999938964844],[203.88999938964844],[203.97999572753906],[203.08999633789062],[203.8699951171875],[203.91000366210938],[203.6999969482422],[206.83999633789062],[207.60000610351562],[207.39999389648438],[207.0],[208.94000244140625],[209.38999938964844],[208.64999389648438],[207.91000366210938],[207.5399932861328],[208.36000061035156],[208.0500030517578],[206.9600067138672],[205.02999877929688],[206.41000366210938],[205.27999877929688],[204.4199981689453],[204.47000122070312],[203.8800048828125],[205.36000061035156],[206.63999938964844],[206.5],[205.3699951171875],[204.3800048828125],[204.88999938964844],[204.22999572753906],[203.6300048828125],[202.77999877929688],[204.86000061035156],[204.99000549316406],[206.13999938964844],[207.8699951171875],[208.97000122070312],[209.47000122070312],[209.17999267578125],[208.88999938964844],[209.24000549316406],[208.86000061035156],[210.50999450683594],[211.5],[211.69000244140625],[211.19000244140625],[209.42999267578125],[208.35000610351562],[206.9199981689453],[207.52999877929688],[205.58999633789062],[205.75],[207.75],[207.77999877929688],[207.92999267578125],[209.27000427246094],[202.72000122070312],[198.64999389648438],[201.1199951171875],[204.72000122070312],[206.55999755859375],[209.2899932861328],[207.7100067138672],[207.05999755859375],[208.6300048828125],[210.77999877929688],[212.9499969482422],[213.42999267578125],[214.35000610351562],[215.66000366210938],[215.30999755859375],[215.6699981689453],[215.6300048828125],[216.19000244140625],[215.75],[216.10000610351562],[215.97000122070312],[215.75999450683594],[215.6199951171875],[215.75],[216.1300048828125],[216.41000366210938],[214.57000732421875],[215.1300048828125],[214.25],[216.41000366210938],[217.74000549316406],[217.8000030517578],[217.22999572753906],[217.9499969482422],[217.99000549316406],[218.8800048828125],[217.9600067138672],[217.02000427246094],[218.2100067138672],[217.74000549316406],[217.8300018310547],[218.89999389648438],[217.36000061035156],[217.22000122070312],[216.25],[217.39999389648438],[217.35000610351562],[216.47000122070312],[216.02999877929688],[217.6999969482422],[217.86000061035156],[218.3000030517578],[218.14999389648438],[213.25],[212.30999755859375],[212.5],[212.5],[212.75],[212.57000732421875],[213.02999877929688],[213.3800048828125],[213.44000244140625],[216.7100067138672],[215.8800048828125],[214.00999450683594],[213.6199951171875],[214.7100067138672],[214.0399932861328],[215.36000061035156],[215.0399932861328],[213.99000549316406],[215.3300018310547],[214.74000549316406],[214.19000244140625],[215.99000549316406],[212.5800018310547],[213.00999450683594],[211.2100067138672],[213.02999877929688],[212.1699981689453],[213.27000427246094],[213.60000610351562],[213.11000061035156],[212.75999450683594],[214.47999572753906],[213.97999572753906],[212.92999267578125],[213.0800018310547],[211.7100067138672],[212.36000061035156],[209.60000610351562],[209.22999572753906],[208.4600067138672],[208.3800048828125],[208.5500030517578],[212.3800048828125],[212.33999633789062],[215.22000122070312],[215.32000732421875],[215.72000122070312],[216.8000030517578],[217.4199981689453],[217.9199981689453],[218.2899932861328],[219.0],[219.72999572753906],[219.75],[221.00999450683594],[220.36000061035156],[220.1699981689453],[220.30999755859375],[219.14999389648438],[219.25999450683594],[220.4199981689453],[220.66000366210938],[221.3800048828125],[224.25999450683594],[225.3699951171875],[225.75999450683594],[227.0],[225.3699951171875],[225.88999938964844],[224.6699981689453],[225.0800018310547],[225.8800048828125],[225.77000427246094],[224.9199981689453],[225.2100067138672],[226.0],[224.27000427246094],[223.83999633789062],[222.72999572753906],[223.8800048828125],[225.61000061035156],[225.47999572753906],[225.89999389648438],[226.4199981689453],[226.00999450683594],[225.58999633789062],[224.9600067138672],[226.69000244140625],[225.8000030517578],[225.89999389648438],[225.41000366210938],[225.97000122070312],[225.27000427246094],[226.27000427246094],[228.50999450683594],[229.00999450683594],[228.75999450683594],[226.41000366210938],[226.32000732421875],[226.94000244140625],[226.82000732421875],[228.4600067138672],[228.5399932861328],[228.72000122070312],[228.30999755859375],[229.24000549316406],[230.6199951171875],[232.0500030517578],[232.16000366210938],[233.38999938964844],[233.85000610351562],[233.92999267578125],[235.50999450683594],[235.8300018310547],[235.55999755859375],[235.41000366210938],[236.35000610351562],[236.02000427246094],[238.3699951171875],[238.2100067138672],[237.72999572753906],[237.00999450683594],[236.75999450683594],[236.39999389648438],[235.74000549316406],[236.58999633789062],[237.24000549316406],[236.19000244140625],[237.2899932861328],[238.10000610351562],[237.02999877929688],[236.32000732421875],[233.5800018310547],[233.0500030517578],[233.60000610351562],[232.9600067138672],[231.61000061035156],[233.13999938964844],[234.72999572753906],[235.27000427246094],[235.67999267578125],[233.91000366210938],[234.55999755859375],[234.5399932861328],[234.42999267578125],[234.63999938964844],[234.72999572753906],[233.33999633789062],[233.77000427246094],[232.50999450683594],[232.8800048828125],[233.0800018310547],[233.17999267578125],[233.77999877929688],[234.1300048828125],[234.55999755859375],[237.80999755859375],[238.35000610351562],[237.97999572753906],[237.92999267578125],[238.1999969482422],[238.3000030517578],[237.6999969482422],[237.77999877929688],[238.67999267578125],[239.1699981689453],[239.0399932861328],[239.14999389648438],[238.1300048828125],[238.6699981689453],[239.4499969482422],[239.6300048828125],[235.75],[235.42999267578125],[237.27000427246094],[238.82000732421875],[239.50999450683594],[239.92999267578125],[240.9600067138672],[241.4499969482422],[241.16000366210938],[240.63999938964844],[241.63999938964844],[243.0800018310547],[243.75999450683594],[243.1199951171875],[242.8300018310547],[243.1699981689453],[241.9499969482422],[242.3800048828125],[243.5800018310547],[243.2899932861328],[242.36000061035156],[241.6300048828125],[243.47999572753906],[242.99000549316406],[242.41000366210938],[242.63999938964844],[242.47000122070312],[243.0500030517578],[241.30999755859375],[242.22999572753906],[239.9600067138672],[241.5800018310547],[242.2100067138672],[241.6999969482422],[240.33999633789062],[240.55999755859375],[241.75999450683594],[240.85000610351562],[243.3000030517578],[243.75999450683594],[244.30999755859375],[245.3300018310547],[244.6699981689453],[246.00999450683594],[246.47000122070312],[246.17999267578125],[246.27999877929688],[247.16000366210938],[247.1300048828125],[245.67999267578125],[246.1300048828125],[246.52999877929688],[246.72000122070312],[246.3699951171875],[246.63999938964844],[246.97000122070312],[247.3699951171875],[246.8300018310547],[246.05999755859375],[243.6999969482422],[243.75],[245.5500030517578],[246.16000366210938],[246.4499969482422],[243.08999633789062],[242.1999969482422],[241.8300018310547],[243.5500030517578],[244.16000366210938],[243.75],[244.38999938964844],[244.08999633789062],[242.92999267578125],[244.6199951171875],[246.0500030517578],[247.6699981689453],[244.9499969482422],[246.22999572753906],[246.39999389648438],[246.3000030517578],[248.02000427246094],[249.4199981689453],[249.58999633789062],[249.60000610351562],[248.57000732421875],[249.27999877929688],[249.60000610351562],[248.9199981689453],[249.19000244140625],[249.02000427246094],[248.0800018310547],[248.80999755859375],[248.8699951171875],[249.6300048828125],[250.1300048828125],[251.2899932861328],[252.22999572753906],[252.55999755859375],[253.1999969482422],[253.85000610351562],[253.64999389648438],[253.97999572753906],[254.32000732421875],[254.3699951171875],[254.63999938964844],[254.82000732421875],[254.97999572753906],[255.5],[254.35000610351562],[255.77000427246094],[256.0199890136719],[256.1499938964844],[254.0],[255.47999572753906],[255.6300048828125],[256.4100036621094],[256.80999755859375],[257.07000732421875],[256.19000244140625],[257.29998779296875],[258.2200012207031],[258.0899963378906],[258.1499938964844],[256.3599853515625],[257.3699951171875],[257.2699890136719],[256.5199890136719],[255.6300048828125],[257.4700012207031],[257.7699890136719],[257.8599853515625],[258.260009765625],[259.57000732421875],[260.1600036621094],[260.0],[260.6499938964844],[262.20001220703125],[263.6700134277344],[260.760009765625],[264.0799865722656],[263.0400085449219],[262.7099914550781],[262.94000244140625],[264.0299987792969],[265.4800109863281],[266.3500061035156],[266.6499938964844],[265.6000061035156],[265.3900146484375],[267.9800109863281],[267.0899963378906],[266.69000244140625],[267.29998779296875],[266.8999938964844],[266.8900146484375],[267.010009765625],[267.45001220703125],[266.6400146484375]],\"name\":\"OHLC\",\"open\":[[183.97999572753906],[183.22999572753906],[183.49000549316406],[183.08999633789062],[183.4499969482422],[184.11000061035156],[183.9499969482422],[183.6699981689453],[182.2899932861328],[184.10000610351562],[184.27999877929688],[184.10000610351562],[184.6999969482422],[184.49000549316406],[183.3699951171875],[181.60000610351562],[179.05999755859375],[178.13999938964844],[177.5800018310547],[178.8300018310547],[177.00999450683594],[177.97000122070312],[174.9499969482422],[174.77999877929688],[175.5800018310547],[178.30999755859375],[179.6999969482422],[180.16000366210938],[182.25],[180.83999633789062],[182.83999633789062],[184.17999267578125],[183.75999450683594],[183.27000427246094],[184.4499969482422],[184.27999877929688],[185.05999755859375],[185.11000061035156],[184.5800018310547],[185.7899932861328],[184.64999389648438],[186.7899932861328],[187.74000549316406],[188.2100067138672],[188.9600067138672],[187.97000122070312],[188.44000244140625],[186.32000732421875],[187.83999633789062],[184.85000610351562],[185.58999633789062],[186.7100067138672],[187.67999267578125],[186.25],[187.7100067138672],[186.83999633789062],[186.3699951171875],[187.0399932861328],[184.75],[185.11000061035156],[186.6699981689453],[187.6199951171875],[188.49000549316406],[189.1699981689453],[189.66000366210938],[185.9499969482422],[184.25999450683594],[185.60000610351562],[187.0800018310547],[182.13999938964844],[182.92999267578125],[183.32000732421875],[185.47000122070312],[185.8800048828125],[186.44000244140625],[187.22999572753906],[187.82000732421875],[188.3699951171875],[187.22000122070312],[187.0500030517578],[187.47999572753906],[187.44000244140625],[188.22000122070312],[188.30999755859375],[187.13999938964844],[188.0],[187.41000366210938],[187.7100067138672],[187.7100067138672],[188.8000030517578],[190.0399932861328],[189.7899932861328],[188.67999267578125],[187.50999450683594],[187.69000244140625],[188.64999389648438],[188.08999633789062],[189.17999267578125],[189.75999450683594],[191.05999755859375],[191.52000427246094],[191.82000732421875],[192.19000244140625],[192.9499969482422],[192.42999267578125],[192.47000122070312],[193.41000366210938],[194.8699951171875],[195.35000610351562],[195.33999633789062],[194.89999389648438],[194.69000244140625],[193.9199981689453],[193.88999938964844],[194.02000427246094],[194.8300018310547],[196.42999267578125],[196.02999877929688],[195.99000549316406],[195.52999877929688],[194.2899932861328],[195.61000061035156],[194.97999572753906],[195.6999969482422],[196.1999969482422],[197.0500030517578],[197.7899932861328],[197.82000732421875],[197.14999389648438],[196.72999572753906],[195.22000122070312],[196.22000122070312],[197.61000061035156],[197.72000122070312],[198.11000061035156],[197.35000610351562],[196.35000610351562],[197.08999633789062],[198.00999450683594],[198.5],[198.8300018310547],[198.08999633789062],[197.75999450683594],[198.1699981689453],[197.64999389648438],[195.61000061035156],[192.55999755859375],[192.8699951171875],[193.10000610351562],[191.11000061035156],[192.94000244140625],[191.4600067138672],[193.97000122070312],[193.61000061035156],[194.2899932861328],[195.16000366210938],[196.47000122070312],[196.8000030517578],[197.83999633789062],[198.1199951171875],[199.08999633789062],[199.33999633789062],[200.13999938964844],[200.3300018310547],[200.42999267578125],[199.58999633789062],[200.4499969482422],[200.97000122070312],[201.3800048828125],[200.83999633789062],[200.1699981689453],[200.9199981689453],[200.41000366210938],[199.42999267578125],[199.27000427246094],[200.10000610351562],[199.16000366210938],[198.61000061035156],[200.77000427246094],[201.36000061035156],[201.52000427246094],[200.35000610351562],[198.42999267578125],[198.0399932861328],[199.0399932861328],[196.6999969482422],[196.1999969482422],[197.69000244140625],[196.6999969482422],[194.17999267578125],[195.67999267578125],[197.33999633789062],[195.27999877929688],[193.3699951171875],[196.3300018310547],[192.69000244140625],[190.4600067138672],[188.4199981689453],[185.16000366210938],[183.05999755859375],[188.4199981689453],[188.1300048828125],[191.67999267578125],[194.41000366210938],[194.6199951171875],[195.25],[195.72999572753906],[196.82000732421875],[198.5500030517578],[197.5800018310547],[201.77999877929688],[201.9199981689453],[201.22999572753906],[202.5399932861328],[202.38999938964844],[203.1699981689453],[203.3800048828125],[204.05999755859375],[203.35000610351562],[204.16000366210938],[204.10000610351562],[203.85000610351562],[204.44000244140625],[205.30999755859375],[204.25999450683594],[207.63999938964844],[207.1699981689453],[207.5399932861328],[207.2899932861328],[207.49000549316406],[206.39999389648438],[205.80999755859375],[207.3000030517578],[207.5399932861328],[207.8699951171875],[207.52000427246094],[204.3699951171875],[205.91000366210938],[203.8800048828125],[202.63999938964844],[201.97999572753906],[198.5800018310547],[198.44000244140625],[204.74000549316406],[206.42999267578125],[206.75],[208.1699981689453],[208.02000427246094],[208.30999755859375],[208.22000122070312],[208.2100067138672],[207.99000549316406],[206.3800048828125],[204.1699981689453],[202.08999633789062],[201.4199981689453],[204.00999450683594],[206.39999389648438],[204.41000366210938],[204.1199951171875],[199.64999389648438],[201.6300048828125],[198.77000427246094],[202.39999389648438],[201.5],[203.99000549316406],[205.7899932861328],[204.7100067138672],[202.97000122070312],[204.1699981689453],[200.3800048828125],[200.57000732421875],[200.0500030517578],[203.0],[203.9199981689453],[204.86000061035156],[206.55999755859375],[204.77000427246094],[205.8800048828125],[206.61000061035156],[207.88999938964844],[209.07000732421875],[209.39999389648438],[209.66000366210938],[209.41000366210938],[209.47999572753906],[210.94000244140625],[211.1199951171875],[211.66000366210938],[211.52000427246094],[211.25999450683594],[210.77999877929688],[211.47000122070312],[210.39999389648438],[210.6199951171875],[209.4199981689453],[207.74000549316406],[206.7100067138672],[205.2899932861328],[205.25999450683594],[206.77000427246094],[206.7100067138672],[207.69000244140625],[207.38999938964844],[209.9600067138672],[209.7100067138672],[210.4199981689453],[209.85000610351562],[209.07000732421875],[204.9600067138672],[205.1300048828125],[206.97999572753906],[207.25999450683594],[206.38999938964844],[205.6199951171875],[205.3699951171875],[207.86000061035156],[207.5500030517578],[207.77999877929688],[209.1999969482422],[209.8699951171875],[208.85000610351562],[210.0500030517578],[210.02999877929688],[208.94000244140625],[209.05999755859375],[210.6699981689453],[210.00999450683594],[210.14999389648438],[211.66000366210938],[212.3300018310547],[210.74000549316406],[210.3699951171875],[209.8800048828125],[209.39999389648438],[211.22999572753906],[211.02999877929688],[209.55999755859375],[207.9199981689453],[210.8800048828125],[211.57000732421875],[209.61000061035156],[210.47000122070312],[211.24000549316406],[212.44000244140625],[212.24000549316406],[213.24000549316406],[213.14999389648438],[212.7100067138672],[213.0399932861328],[212.39999389648438],[211.25],[212.3300018310547],[212.3800048828125],[211.94000244140625],[211.02000427246094],[212.0],[211.07000732421875],[209.9499969482422],[209.63999938964844],[208.4499969482422],[209.3699951171875],[211.47999572753906],[210.63999938964844],[208.63999938964844],[208.92999267578125],[210.58999633789062],[211.30999755859375],[211.4600067138672],[211.91000366210938],[212.13999938964844],[211.72000122070312],[211.10000610351562],[210.2899932861328],[208.0500030517578],[207.25999450683594],[207.72999572753906],[208.07000732421875],[205.77000427246094],[206.9600067138672],[206.4199981689453],[207.0399932861328],[207.2899932861328],[208.99000549316406],[209.72000122070312],[210.72999572753906],[211.8699951171875],[212.2899932861328],[212.75],[212.42999267578125],[210.92999267578125],[211.52999877929688],[210.3000030517578],[206.94000244140625],[207.7899932861328],[209.47999572753906],[210.16000366210938],[211.4199981689453],[210.4600067138672],[209.6999969482422],[210.4499969482422],[210.2899932861328],[208.16000366210938],[209.27999877929688],[208.97000122070312],[207.11000061035156],[208.72999572753906],[208.42999267578125],[208.7100067138672],[210.25999450683594],[209.08999633789062],[206.50999450683594],[201.72999572753906],[187.49000549316406],[195.42999267578125],[192.0800018310547],[197.02000427246094],[198.5],[198.11000061035156],[193.1199951171875],[194.6199951171875],[196.25999450683594],[192.85000610351562],[195.94000244140625],[199.32000732421875],[194.55999755859375],[195.3800048828125],[196.9499969482422],[196.61000061035156],[198.82000732421875],[200.02000427246094],[195.7100067138672],[196.44000244140625],[193.8800048828125],[194.11000061035156],[192.14999389648438],[194.63999938964844],[191.77999877929688],[188.27000427246094],[190.3699951171875],[192.0800018310547],[189.77000427246094],[196.4600067138672],[198.30999755859375],[198.89999389648438],[198.9499969482422],[201.3800048828125],[201.4199981689453],[200.64999389648438],[200.17999267578125],[200.0800018310547],[202.8300018310547],[202.5],[202.85000610351562],[203.61000061035156],[202.97999572753906],[207.25],[207.3000030517578],[206.1999969482422],[207.0],[208.35000610351562],[209.05999755859375],[208.32000732421875],[209.97000122070312],[211.35000610351562],[210.42999267578125],[209.74000549316406],[209.30999755859375],[207.50999450683594],[208.8800048828125],[206.5],[204.35000610351562],[202.32000732421875],[205.99000549316406],[206.0399932861328],[208.58999633789062],[209.4499969482422],[209.3800048828125],[207.8699951171875],[209.5],[209.42999267578125],[209.75],[209.44000244140625],[210.6199951171875],[208.8300018310547],[205.61000061035156],[209.22999572753906],[206.49000549316406],[206.19000244140625],[205.4199981689453],[203.35000610351562],[202.07000732421875],[204.6999969482422],[206.3699951171875],[208.39999389648438],[202.77000427246094],[201.41000366210938],[202.72000122070312],[204.69000244140625],[205.72000122070312],[204.86000061035156],[206.50999450683594],[207.11000061035156],[205.1300048828125],[200.49000549316406],[201.39999389648438],[198.33999633789062],[195.3300018310547],[195.19000244140625],[193.00999450683594],[193.82000732421875],[194.4499969482422],[189.5500030517578],[186.77000427246094],[189.9600067138672],[185.02999877929688],[186.2100067138672],[189.77999877929688],[189.9199981689453],[188.4199981689453],[189.5800018310547],[189.9600067138672],[190.02000427246094],[192.52999877929688],[191.9600067138672],[191.41000366210938],[190.7100067138672],[190.99000549316406],[185.77000427246094],[183.36000061035156],[186.41000366210938],[182.33999633789062],[184.9600067138672],[188.77000427246094],[191.16000366210938],[193.1999969482422],[191.1699981689453],[193.8699951171875],[194.0],[190.6300048828125],[193.72999572753906],[196.57000732421875],[195.11000061035156],[195.00999450683594],[197.74000549316406],[198.7899932861328],[200.00999450683594],[199.33999633789062],[199.32000732421875],[199.36000061035156],[199.9600067138672],[201.25999450683594],[202.16000366210938],[201.36000061035156],[201.60000610351562],[203.24000549316406],[204.1699981689453],[204.07000732421875],[203.75999450683594],[204.11000061035156],[202.0],[203.61000061035156],[202.75999450683594],[206.3000030517578],[205.91000366210938],[204.35000610351562],[206.8300018310547],[204.6699981689453],[204.19000244140625],[205.13999938964844],[205.33999633789062],[205.25],[204.22000122070312],[207.0],[208.07000732421875],[208.00999450683594],[207.77999877929688],[209.74000549316406],[209.9499969482422],[210.1199951171875],[208.5500030517578],[208.25999450683594],[209.0399932861328],[208.47000122070312],[208.4600067138672],[206.72000122070312],[206.9199981689453],[206.52000427246094],[204.99000549316406],[205.55999755859375],[204.05999755859375],[205.57000732421875],[206.72000122070312],[207.91000366210938],[207.2899932861328],[206.2100067138672],[204.9600067138672],[206.4600067138672],[204.44000244140625],[204.05999755859375],[204.9199981689453],[205.50999450683594],[206.1699981689453],[208.6699981689453],[209.44000244140625],[209.52999877929688],[210.55999755859375],[209.1199951171875],[209.8000030517578],[210.25],[210.6999969482422],[211.52999877929688],[211.83999633789062],[211.50999450683594],[210.4600067138672],[209.36000061035156],[208.0],[208.0399932861328],[207.75],[207.1699981689453],[208.82000732421875],[208.3000030517578],[208.64999389648438],[209.80999755859375],[203.6300048828125],[201.58999633789062],[201.47999572753906],[204.83999633789062],[207.2100067138672],[209.47999572753906],[208.9499969482422],[207.8300018310547],[209.8699951171875],[211.0500030517578],[213.19000244140625],[214.52999877929688],[215.44000244140625],[216.39999389648438],[216.77999877929688],[215.97000122070312],[215.9199981689453],[216.19000244140625],[216.9600067138672],[216.41000366210938],[217.0],[216.52999877929688],[217.19000244140625],[216.2899932861328],[216.4600067138672],[217.19000244140625],[216.64999389648438],[215.47999572753906],[216.30999755859375],[216.41000366210938],[218.39999389648438],[218.1300048828125],[218.30999755859375],[218.25999450683594],[218.2899932861328],[218.88999938964844],[218.60000610351562],[218.0],[218.33999633789062],[218.30999755859375],[218.25999450683594],[219.25],[218.8000030517578],[217.39999389648438],[217.9199981689453],[217.44000244140625],[218.25999450683594],[217.61000061035156],[217.3699951171875],[218.38999938964844],[218.6999969482422],[218.83999633789062],[218.6199951171875],[216.97000122070312],[212.38999938964844],[214.83999633789062],[213.2899932861328],[212.9600067138672],[213.47999572753906],[214.1300048828125],[214.41000366210938],[214.24000549316406],[217.0],[216.72000122070312],[215.02000427246094],[214.0500030517578],[215.8300018310547],[216.39999389648438],[215.64999389648438],[215.82000732421875],[215.91000366210938],[215.41000366210938],[215.3699951171875],[216.10000610351562],[216.16000366210938],[215.66000366210938],[213.58999633789062],[212.16000366210938],[214.14999389648438],[213.08999633789062],[214.24000549316406],[214.02000427246094],[213.8699951171875],[213.8800048828125],[215.0],[214.67999267578125],[213.2100067138672],[214.5800018310547],[213.13999938964844],[212.92999267578125],[212.92999267578125],[210.64999389648438],[209.99000549316406],[208.91000366210938],[208.5500030517578],[212.69000244140625],[212.3699951171875],[217.3000030517578],[216.0800018310547],[217.02999877929688],[217.0399932861328],[217.55999755859375],[218.0500030517578],[219.07000732421875],[219.1699981689453],[220.50999450683594],[219.97999572753906],[221.10000610351562],[221.16000366210938],[220.52000427246094],[221.6300048828125],[220.72999572753906],[219.6699981689453],[220.64999389648438],[221.22000122070312],[221.52000427246094],[224.57000732421875],[225.41000366210938],[226.39999389648438],[227.02000427246094],[227.41000366210938],[226.16000366210938],[226.00999450683594],[225.25],[226.14999389648438],[226.25],[225.60000610351562],[225.42999267578125],[226.02000427246094],[226.57000732421875],[224.47999572753906],[224.72999572753906],[225.0399932861328],[225.6199951171875],[226.27000427246094],[226.52999877929688],[226.91000366210938],[226.47999572753906],[226.36000061035156],[226.5],[226.72999572753906],[226.30999755859375],[226.5399932861328],[226.83999633789062],[226.6999969482422],[226.74000549316406],[226.39999389648438],[228.6999969482422],[229.39999389648438],[229.4199981689453],[228.1699981689453],[226.97999572753906],[227.52999877929688],[227.6199951171875],[228.82000732421875],[228.8699951171875],[229.3800048828125],[228.94000244140625],[229.24000549316406],[231.0],[232.0800018310547],[232.55999755859375],[233.4499969482422],[234.9499969482422],[233.9499969482422],[235.52000427246094],[236.02000427246094],[236.8800048828125],[235.4600067138672],[236.63999938964844],[236.6699981689453],[238.38999938964844],[239.55999755859375],[238.1699981689453],[237.5],[237.36000061035156],[237.33999633789062],[236.6999969482422],[237.97000122070312],[237.6199951171875],[237.17999267578125],[237.55999755859375],[239.11000061035156],[237.75],[237.02999877929688],[237.47000122070312],[233.77000427246094],[234.27999877929688],[234.3800048828125],[231.92999267578125],[233.27000427246094],[234.99000549316406],[235.47000122070312],[235.89999389648438],[235.8000030517578],[235.0],[236.25999450683594],[234.94000244140625],[235.14999389648438],[235.36000061035156],[234.89999389648438],[234.74000549316406],[233.63999938964844],[233.11000061035156],[233.72000122070312],[234.52000427246094],[234.14999389648438],[235.25],[237.17999267578125],[237.91000366210938],[238.50999450683594],[238.77000427246094],[238.89999389648438],[238.67999267578125],[238.83999633789062],[238.77000427246094],[238.8300018310547],[239.19000244140625],[239.75],[239.9600067138672],[239.38999938964844],[239.35000610351562],[239.08999633789062],[239.47000122070312],[240.63999938964844],[240.0800018310547],[235.72999572753906],[237.3300018310547],[238.89999389648438],[239.9499969482422],[240.32000732421875],[241.1999969482422],[241.5399932861328],[241.33999633789062],[241.83999633789062],[241.97000122070312],[243.4199981689453],[243.97000122070312],[243.33999633789062],[243.60000610351562],[243.77000427246094],[244.08999633789062],[243.1300048828125],[243.97999572753906],[244.86000061035156],[242.67999267578125],[242.77000427246094],[243.58999633789062],[244.25],[243.4600067138672],[242.9600067138672],[242.91000366210938],[243.89999389648438],[243.0399932861328],[242.5],[243.66000366210938],[242.27999877929688],[242.8800048828125],[242.6300048828125],[241.88999938964844],[241.2100067138672],[242.11000061035156],[242.3699951171875],[243.3000030517578],[244.02000427246094],[244.4199981689453],[245.47000122070312],[245.05999755859375],[246.02000427246094],[247.27999877929688],[246.44000244140625],[246.7899932861328],[247.67999267578125],[247.75],[247.9600067138672],[246.64999389648438],[247.3699951171875],[247.4600067138672],[247.47000122070312],[247.30999755859375],[247.52000427246094],[247.49000549316406],[247.50999450683594],[246.47000122070312],[246.2899932861328],[244.02000427246094],[245.58999633789062],[246.97999572753906],[247.11000061035156],[246.24000549316406],[242.89999389648438],[242.63999938964844],[243.57000732421875],[244.3300018310547],[245.0],[244.89999389648438],[245.1699981689453],[243.05999755859375],[244.8300018310547],[246.72000122070312],[247.9199981689453],[247.25999450683594],[246.83999633789062],[247.25],[246.5399932861328],[248.0399932861328],[249.6300048828125],[249.72000122070312],[249.8000030517578],[248.69000244140625],[249.61000061035156],[250.0],[250.07000732421875],[249.8800048828125],[249.0500030517578],[249.14999389648438],[249.4199981689453],[249.8800048828125],[249.72999572753906],[250.33999633789062],[251.49000549316406],[252.32000732421875],[252.69000244140625],[253.5399932861328],[254.14999389648438],[254.6300048828125],[254.60000610351562],[254.50999450683594],[254.66000366210938],[255.13999938964844],[255.2100067138672],[255.22999572753906],[255.89999389648438],[254.8300018310547],[256.70001220703125],[257.4800109863281],[256.6000061035156],[256.17999267578125],[255.99000549316406],[256.4700012207031],[256.4700012207031],[257.17999267578125],[258.0400085449219],[257.4100036621094],[257.7699890136719],[258.29998779296875],[258.9700012207031],[258.4700012207031],[257.7300109863281],[257.7300109863281],[257.30999755859375],[257.4100036621094],[256.6199951171875],[257.5199890136719],[258.2200012207031],[258.1400146484375],[259.17999267578125],[260.0],[260.32000732421875],[260.4100036621094],[260.760009765625],[263.0199890136719],[263.760009765625],[264.760009765625],[266.30999755859375],[263.19000244140625],[263.29998779296875],[264.07000732421875],[265.1600036621094],[266.30999755859375],[267.2099914550781],[267.05999755859375],[267.0899963378906],[265.45001220703125],[268.1000061035156],[268.4800109863281],[268.2699890136719],[267.739990234375],[267.6000061035156],[267.04998779296875],[267.3800048828125],[267.8900146484375],[268.5299987792969]],\"x\":[\"2014-01-02T00:00:00\",\"2014-01-03T00:00:00\",\"2014-01-06T00:00:00\",\"2014-01-07T00:00:00\",\"2014-01-08T00:00:00\",\"2014-01-09T00:00:00\",\"2014-01-10T00:00:00\",\"2014-01-13T00:00:00\",\"2014-01-14T00:00:00\",\"2014-01-15T00:00:00\",\"2014-01-16T00:00:00\",\"2014-01-17T00:00:00\",\"2014-01-21T00:00:00\",\"2014-01-22T00:00:00\",\"2014-01-23T00:00:00\",\"2014-01-24T00:00:00\",\"2014-01-27T00:00:00\",\"2014-01-28T00:00:00\",\"2014-01-29T00:00:00\",\"2014-01-30T00:00:00\",\"2014-01-31T00:00:00\",\"2014-02-03T00:00:00\",\"2014-02-04T00:00:00\",\"2014-02-05T00:00:00\",\"2014-02-06T00:00:00\",\"2014-02-07T00:00:00\",\"2014-02-10T00:00:00\",\"2014-02-11T00:00:00\",\"2014-02-12T00:00:00\",\"2014-02-13T00:00:00\",\"2014-02-14T00:00:00\",\"2014-02-18T00:00:00\",\"2014-02-19T00:00:00\",\"2014-02-20T00:00:00\",\"2014-02-21T00:00:00\",\"2014-02-24T00:00:00\",\"2014-02-25T00:00:00\",\"2014-02-26T00:00:00\",\"2014-02-27T00:00:00\",\"2014-02-28T00:00:00\",\"2014-03-03T00:00:00\",\"2014-03-04T00:00:00\",\"2014-03-05T00:00:00\",\"2014-03-06T00:00:00\",\"2014-03-07T00:00:00\",\"2014-03-10T00:00:00\",\"2014-03-11T00:00:00\",\"2014-03-12T00:00:00\",\"2014-03-13T00:00:00\",\"2014-03-14T00:00:00\",\"2014-03-17T00:00:00\",\"2014-03-18T00:00:00\",\"2014-03-19T00:00:00\",\"2014-03-20T00:00:00\",\"2014-03-21T00:00:00\",\"2014-03-24T00:00:00\",\"2014-03-25T00:00:00\",\"2014-03-26T00:00:00\",\"2014-03-27T00:00:00\",\"2014-03-28T00:00:00\",\"2014-03-31T00:00:00\",\"2014-04-01T00:00:00\",\"2014-04-02T00:00:00\",\"2014-04-03T00:00:00\",\"2014-04-04T00:00:00\",\"2014-04-07T00:00:00\",\"2014-04-08T00:00:00\",\"2014-04-09T00:00:00\",\"2014-04-10T00:00:00\",\"2014-04-11T00:00:00\",\"2014-04-14T00:00:00\",\"2014-04-15T00:00:00\",\"2014-04-16T00:00:00\",\"2014-04-17T00:00:00\",\"2014-04-21T00:00:00\",\"2014-04-22T00:00:00\",\"2014-04-23T00:00:00\",\"2014-04-24T00:00:00\",\"2014-04-25T00:00:00\",\"2014-04-28T00:00:00\",\"2014-04-29T00:00:00\",\"2014-04-30T00:00:00\",\"2014-05-01T00:00:00\",\"2014-05-02T00:00:00\",\"2014-05-05T00:00:00\",\"2014-05-06T00:00:00\",\"2014-05-07T00:00:00\",\"2014-05-08T00:00:00\",\"2014-05-09T00:00:00\",\"2014-05-12T00:00:00\",\"2014-05-13T00:00:00\",\"2014-05-14T00:00:00\",\"2014-05-15T00:00:00\",\"2014-05-16T00:00:00\",\"2014-05-19T00:00:00\",\"2014-05-20T00:00:00\",\"2014-05-21T00:00:00\",\"2014-05-22T00:00:00\",\"2014-05-23T00:00:00\",\"2014-05-27T00:00:00\",\"2014-05-28T00:00:00\",\"2014-05-29T00:00:00\",\"2014-05-30T00:00:00\",\"2014-06-02T00:00:00\",\"2014-06-03T00:00:00\",\"2014-06-04T00:00:00\",\"2014-06-05T00:00:00\",\"2014-06-06T00:00:00\",\"2014-06-09T00:00:00\",\"2014-06-10T00:00:00\",\"2014-06-11T00:00:00\",\"2014-06-12T00:00:00\",\"2014-06-13T00:00:00\",\"2014-06-16T00:00:00\",\"2014-06-17T00:00:00\",\"2014-06-18T00:00:00\",\"2014-06-19T00:00:00\",\"2014-06-20T00:00:00\",\"2014-06-23T00:00:00\",\"2014-06-24T00:00:00\",\"2014-06-25T00:00:00\",\"2014-06-26T00:00:00\",\"2014-06-27T00:00:00\",\"2014-06-30T00:00:00\",\"2014-07-01T00:00:00\",\"2014-07-02T00:00:00\",\"2014-07-03T00:00:00\",\"2014-07-07T00:00:00\",\"2014-07-08T00:00:00\",\"2014-07-09T00:00:00\",\"2014-07-10T00:00:00\",\"2014-07-11T00:00:00\",\"2014-07-14T00:00:00\",\"2014-07-15T00:00:00\",\"2014-07-16T00:00:00\",\"2014-07-17T00:00:00\",\"2014-07-18T00:00:00\",\"2014-07-21T00:00:00\",\"2014-07-22T00:00:00\",\"2014-07-23T00:00:00\",\"2014-07-24T00:00:00\",\"2014-07-25T00:00:00\",\"2014-07-28T00:00:00\",\"2014-07-29T00:00:00\",\"2014-07-30T00:00:00\",\"2014-07-31T00:00:00\",\"2014-08-01T00:00:00\",\"2014-08-04T00:00:00\",\"2014-08-05T00:00:00\",\"2014-08-06T00:00:00\",\"2014-08-07T00:00:00\",\"2014-08-08T00:00:00\",\"2014-08-11T00:00:00\",\"2014-08-12T00:00:00\",\"2014-08-13T00:00:00\",\"2014-08-14T00:00:00\",\"2014-08-15T00:00:00\",\"2014-08-18T00:00:00\",\"2014-08-19T00:00:00\",\"2014-08-20T00:00:00\",\"2014-08-21T00:00:00\",\"2014-08-22T00:00:00\",\"2014-08-25T00:00:00\",\"2014-08-26T00:00:00\",\"2014-08-27T00:00:00\",\"2014-08-28T00:00:00\",\"2014-08-29T00:00:00\",\"2014-09-02T00:00:00\",\"2014-09-03T00:00:00\",\"2014-09-04T00:00:00\",\"2014-09-05T00:00:00\",\"2014-09-08T00:00:00\",\"2014-09-09T00:00:00\",\"2014-09-10T00:00:00\",\"2014-09-11T00:00:00\",\"2014-09-12T00:00:00\",\"2014-09-15T00:00:00\",\"2014-09-16T00:00:00\",\"2014-09-17T00:00:00\",\"2014-09-18T00:00:00\",\"2014-09-19T00:00:00\",\"2014-09-22T00:00:00\",\"2014-09-23T00:00:00\",\"2014-09-24T00:00:00\",\"2014-09-25T00:00:00\",\"2014-09-26T00:00:00\",\"2014-09-29T00:00:00\",\"2014-09-30T00:00:00\",\"2014-10-01T00:00:00\",\"2014-10-02T00:00:00\",\"2014-10-03T00:00:00\",\"2014-10-06T00:00:00\",\"2014-10-07T00:00:00\",\"2014-10-08T00:00:00\",\"2014-10-09T00:00:00\",\"2014-10-10T00:00:00\",\"2014-10-13T00:00:00\",\"2014-10-14T00:00:00\",\"2014-10-15T00:00:00\",\"2014-10-16T00:00:00\",\"2014-10-17T00:00:00\",\"2014-10-20T00:00:00\",\"2014-10-21T00:00:00\",\"2014-10-22T00:00:00\",\"2014-10-23T00:00:00\",\"2014-10-24T00:00:00\",\"2014-10-27T00:00:00\",\"2014-10-28T00:00:00\",\"2014-10-29T00:00:00\",\"2014-10-30T00:00:00\",\"2014-10-31T00:00:00\",\"2014-11-03T00:00:00\",\"2014-11-04T00:00:00\",\"2014-11-05T00:00:00\",\"2014-11-06T00:00:00\",\"2014-11-07T00:00:00\",\"2014-11-10T00:00:00\",\"2014-11-11T00:00:00\",\"2014-11-12T00:00:00\",\"2014-11-13T00:00:00\",\"2014-11-14T00:00:00\",\"2014-11-17T00:00:00\",\"2014-11-18T00:00:00\",\"2014-11-19T00:00:00\",\"2014-11-20T00:00:00\",\"2014-11-21T00:00:00\",\"2014-11-24T00:00:00\",\"2014-11-25T00:00:00\",\"2014-11-26T00:00:00\",\"2014-11-28T00:00:00\",\"2014-12-01T00:00:00\",\"2014-12-02T00:00:00\",\"2014-12-03T00:00:00\",\"2014-12-04T00:00:00\",\"2014-12-05T00:00:00\",\"2014-12-08T00:00:00\",\"2014-12-09T00:00:00\",\"2014-12-10T00:00:00\",\"2014-12-11T00:00:00\",\"2014-12-12T00:00:00\",\"2014-12-15T00:00:00\",\"2014-12-16T00:00:00\",\"2014-12-17T00:00:00\",\"2014-12-18T00:00:00\",\"2014-12-19T00:00:00\",\"2014-12-22T00:00:00\",\"2014-12-23T00:00:00\",\"2014-12-24T00:00:00\",\"2014-12-26T00:00:00\",\"2014-12-29T00:00:00\",\"2014-12-30T00:00:00\",\"2014-12-31T00:00:00\",\"2015-01-02T00:00:00\",\"2015-01-05T00:00:00\",\"2015-01-06T00:00:00\",\"2015-01-07T00:00:00\",\"2015-01-08T00:00:00\",\"2015-01-09T00:00:00\",\"2015-01-12T00:00:00\",\"2015-01-13T00:00:00\",\"2015-01-14T00:00:00\",\"2015-01-15T00:00:00\",\"2015-01-16T00:00:00\",\"2015-01-20T00:00:00\",\"2015-01-21T00:00:00\",\"2015-01-22T00:00:00\",\"2015-01-23T00:00:00\",\"2015-01-26T00:00:00\",\"2015-01-27T00:00:00\",\"2015-01-28T00:00:00\",\"2015-01-29T00:00:00\",\"2015-01-30T00:00:00\",\"2015-02-02T00:00:00\",\"2015-02-03T00:00:00\",\"2015-02-04T00:00:00\",\"2015-02-05T00:00:00\",\"2015-02-06T00:00:00\",\"2015-02-09T00:00:00\",\"2015-02-10T00:00:00\",\"2015-02-11T00:00:00\",\"2015-02-12T00:00:00\",\"2015-02-13T00:00:00\",\"2015-02-17T00:00:00\",\"2015-02-18T00:00:00\",\"2015-02-19T00:00:00\",\"2015-02-20T00:00:00\",\"2015-02-23T00:00:00\",\"2015-02-24T00:00:00\",\"2015-02-25T00:00:00\",\"2015-02-26T00:00:00\",\"2015-02-27T00:00:00\",\"2015-03-02T00:00:00\",\"2015-03-03T00:00:00\",\"2015-03-04T00:00:00\",\"2015-03-05T00:00:00\",\"2015-03-06T00:00:00\",\"2015-03-09T00:00:00\",\"2015-03-10T00:00:00\",\"2015-03-11T00:00:00\",\"2015-03-12T00:00:00\",\"2015-03-13T00:00:00\",\"2015-03-16T00:00:00\",\"2015-03-17T00:00:00\",\"2015-03-18T00:00:00\",\"2015-03-19T00:00:00\",\"2015-03-20T00:00:00\",\"2015-03-23T00:00:00\",\"2015-03-24T00:00:00\",\"2015-03-25T00:00:00\",\"2015-03-26T00:00:00\",\"2015-03-27T00:00:00\",\"2015-03-30T00:00:00\",\"2015-03-31T00:00:00\",\"2015-04-01T00:00:00\",\"2015-04-02T00:00:00\",\"2015-04-06T00:00:00\",\"2015-04-07T00:00:00\",\"2015-04-08T00:00:00\",\"2015-04-09T00:00:00\",\"2015-04-10T00:00:00\",\"2015-04-13T00:00:00\",\"2015-04-14T00:00:00\",\"2015-04-15T00:00:00\",\"2015-04-16T00:00:00\",\"2015-04-17T00:00:00\",\"2015-04-20T00:00:00\",\"2015-04-21T00:00:00\",\"2015-04-22T00:00:00\",\"2015-04-23T00:00:00\",\"2015-04-24T00:00:00\",\"2015-04-27T00:00:00\",\"2015-04-28T00:00:00\",\"2015-04-29T00:00:00\",\"2015-04-30T00:00:00\",\"2015-05-01T00:00:00\",\"2015-05-04T00:00:00\",\"2015-05-05T00:00:00\",\"2015-05-06T00:00:00\",\"2015-05-07T00:00:00\",\"2015-05-08T00:00:00\",\"2015-05-11T00:00:00\",\"2015-05-12T00:00:00\",\"2015-05-13T00:00:00\",\"2015-05-14T00:00:00\",\"2015-05-15T00:00:00\",\"2015-05-18T00:00:00\",\"2015-05-19T00:00:00\",\"2015-05-20T00:00:00\",\"2015-05-21T00:00:00\",\"2015-05-22T00:00:00\",\"2015-05-26T00:00:00\",\"2015-05-27T00:00:00\",\"2015-05-28T00:00:00\",\"2015-05-29T00:00:00\",\"2015-06-01T00:00:00\",\"2015-06-02T00:00:00\",\"2015-06-03T00:00:00\",\"2015-06-04T00:00:00\",\"2015-06-05T00:00:00\",\"2015-06-08T00:00:00\",\"2015-06-09T00:00:00\",\"2015-06-10T00:00:00\",\"2015-06-11T00:00:00\",\"2015-06-12T00:00:00\",\"2015-06-15T00:00:00\",\"2015-06-16T00:00:00\",\"2015-06-17T00:00:00\",\"2015-06-18T00:00:00\",\"2015-06-19T00:00:00\",\"2015-06-22T00:00:00\",\"2015-06-23T00:00:00\",\"2015-06-24T00:00:00\",\"2015-06-25T00:00:00\",\"2015-06-26T00:00:00\",\"2015-06-29T00:00:00\",\"2015-06-30T00:00:00\",\"2015-07-01T00:00:00\",\"2015-07-02T00:00:00\",\"2015-07-06T00:00:00\",\"2015-07-07T00:00:00\",\"2015-07-08T00:00:00\",\"2015-07-09T00:00:00\",\"2015-07-10T00:00:00\",\"2015-07-13T00:00:00\",\"2015-07-14T00:00:00\",\"2015-07-15T00:00:00\",\"2015-07-16T00:00:00\",\"2015-07-17T00:00:00\",\"2015-07-20T00:00:00\",\"2015-07-21T00:00:00\",\"2015-07-22T00:00:00\",\"2015-07-23T00:00:00\",\"2015-07-24T00:00:00\",\"2015-07-27T00:00:00\",\"2015-07-28T00:00:00\",\"2015-07-29T00:00:00\",\"2015-07-30T00:00:00\",\"2015-07-31T00:00:00\",\"2015-08-03T00:00:00\",\"2015-08-04T00:00:00\",\"2015-08-05T00:00:00\",\"2015-08-06T00:00:00\",\"2015-08-07T00:00:00\",\"2015-08-10T00:00:00\",\"2015-08-11T00:00:00\",\"2015-08-12T00:00:00\",\"2015-08-13T00:00:00\",\"2015-08-14T00:00:00\",\"2015-08-17T00:00:00\",\"2015-08-18T00:00:00\",\"2015-08-19T00:00:00\",\"2015-08-20T00:00:00\",\"2015-08-21T00:00:00\",\"2015-08-24T00:00:00\",\"2015-08-25T00:00:00\",\"2015-08-26T00:00:00\",\"2015-08-27T00:00:00\",\"2015-08-28T00:00:00\",\"2015-08-31T00:00:00\",\"2015-09-01T00:00:00\",\"2015-09-02T00:00:00\",\"2015-09-03T00:00:00\",\"2015-09-04T00:00:00\",\"2015-09-08T00:00:00\",\"2015-09-09T00:00:00\",\"2015-09-10T00:00:00\",\"2015-09-11T00:00:00\",\"2015-09-14T00:00:00\",\"2015-09-15T00:00:00\",\"2015-09-16T00:00:00\",\"2015-09-17T00:00:00\",\"2015-09-18T00:00:00\",\"2015-09-21T00:00:00\",\"2015-09-22T00:00:00\",\"2015-09-23T00:00:00\",\"2015-09-24T00:00:00\",\"2015-09-25T00:00:00\",\"2015-09-28T00:00:00\",\"2015-09-29T00:00:00\",\"2015-09-30T00:00:00\",\"2015-10-01T00:00:00\",\"2015-10-02T00:00:00\",\"2015-10-05T00:00:00\",\"2015-10-06T00:00:00\",\"2015-10-07T00:00:00\",\"2015-10-08T00:00:00\",\"2015-10-09T00:00:00\",\"2015-10-12T00:00:00\",\"2015-10-13T00:00:00\",\"2015-10-14T00:00:00\",\"2015-10-15T00:00:00\",\"2015-10-16T00:00:00\",\"2015-10-19T00:00:00\",\"2015-10-20T00:00:00\",\"2015-10-21T00:00:00\",\"2015-10-22T00:00:00\",\"2015-10-23T00:00:00\",\"2015-10-26T00:00:00\",\"2015-10-27T00:00:00\",\"2015-10-28T00:00:00\",\"2015-10-29T00:00:00\",\"2015-10-30T00:00:00\",\"2015-11-02T00:00:00\",\"2015-11-03T00:00:00\",\"2015-11-04T00:00:00\",\"2015-11-05T00:00:00\",\"2015-11-06T00:00:00\",\"2015-11-09T00:00:00\",\"2015-11-10T00:00:00\",\"2015-11-11T00:00:00\",\"2015-11-12T00:00:00\",\"2015-11-13T00:00:00\",\"2015-11-16T00:00:00\",\"2015-11-17T00:00:00\",\"2015-11-18T00:00:00\",\"2015-11-19T00:00:00\",\"2015-11-20T00:00:00\",\"2015-11-23T00:00:00\",\"2015-11-24T00:00:00\",\"2015-11-25T00:00:00\",\"2015-11-27T00:00:00\",\"2015-11-30T00:00:00\",\"2015-12-01T00:00:00\",\"2015-12-02T00:00:00\",\"2015-12-03T00:00:00\",\"2015-12-04T00:00:00\",\"2015-12-07T00:00:00\",\"2015-12-08T00:00:00\",\"2015-12-09T00:00:00\",\"2015-12-10T00:00:00\",\"2015-12-11T00:00:00\",\"2015-12-14T00:00:00\",\"2015-12-15T00:00:00\",\"2015-12-16T00:00:00\",\"2015-12-17T00:00:00\",\"2015-12-18T00:00:00\",\"2015-12-21T00:00:00\",\"2015-12-22T00:00:00\",\"2015-12-23T00:00:00\",\"2015-12-24T00:00:00\",\"2015-12-28T00:00:00\",\"2015-12-29T00:00:00\",\"2015-12-30T00:00:00\",\"2015-12-31T00:00:00\",\"2016-01-04T00:00:00\",\"2016-01-05T00:00:00\",\"2016-01-06T00:00:00\",\"2016-01-07T00:00:00\",\"2016-01-08T00:00:00\",\"2016-01-11T00:00:00\",\"2016-01-12T00:00:00\",\"2016-01-13T00:00:00\",\"2016-01-14T00:00:00\",\"2016-01-15T00:00:00\",\"2016-01-19T00:00:00\",\"2016-01-20T00:00:00\",\"2016-01-21T00:00:00\",\"2016-01-22T00:00:00\",\"2016-01-25T00:00:00\",\"2016-01-26T00:00:00\",\"2016-01-27T00:00:00\",\"2016-01-28T00:00:00\",\"2016-01-29T00:00:00\",\"2016-02-01T00:00:00\",\"2016-02-02T00:00:00\",\"2016-02-03T00:00:00\",\"2016-02-04T00:00:00\",\"2016-02-05T00:00:00\",\"2016-02-08T00:00:00\",\"2016-02-09T00:00:00\",\"2016-02-10T00:00:00\",\"2016-02-11T00:00:00\",\"2016-02-12T00:00:00\",\"2016-02-16T00:00:00\",\"2016-02-17T00:00:00\",\"2016-02-18T00:00:00\",\"2016-02-19T00:00:00\",\"2016-02-22T00:00:00\",\"2016-02-23T00:00:00\",\"2016-02-24T00:00:00\",\"2016-02-25T00:00:00\",\"2016-02-26T00:00:00\",\"2016-02-29T00:00:00\",\"2016-03-01T00:00:00\",\"2016-03-02T00:00:00\",\"2016-03-03T00:00:00\",\"2016-03-04T00:00:00\",\"2016-03-07T00:00:00\",\"2016-03-08T00:00:00\",\"2016-03-09T00:00:00\",\"2016-03-10T00:00:00\",\"2016-03-11T00:00:00\",\"2016-03-14T00:00:00\",\"2016-03-15T00:00:00\",\"2016-03-16T00:00:00\",\"2016-03-17T00:00:00\",\"2016-03-18T00:00:00\",\"2016-03-21T00:00:00\",\"2016-03-22T00:00:00\",\"2016-03-23T00:00:00\",\"2016-03-24T00:00:00\",\"2016-03-28T00:00:00\",\"2016-03-29T00:00:00\",\"2016-03-30T00:00:00\",\"2016-03-31T00:00:00\",\"2016-04-01T00:00:00\",\"2016-04-04T00:00:00\",\"2016-04-05T00:00:00\",\"2016-04-06T00:00:00\",\"2016-04-07T00:00:00\",\"2016-04-08T00:00:00\",\"2016-04-11T00:00:00\",\"2016-04-12T00:00:00\",\"2016-04-13T00:00:00\",\"2016-04-14T00:00:00\",\"2016-04-15T00:00:00\",\"2016-04-18T00:00:00\",\"2016-04-19T00:00:00\",\"2016-04-20T00:00:00\",\"2016-04-21T00:00:00\",\"2016-04-22T00:00:00\",\"2016-04-25T00:00:00\",\"2016-04-26T00:00:00\",\"2016-04-27T00:00:00\",\"2016-04-28T00:00:00\",\"2016-04-29T00:00:00\",\"2016-05-02T00:00:00\",\"2016-05-03T00:00:00\",\"2016-05-04T00:00:00\",\"2016-05-05T00:00:00\",\"2016-05-06T00:00:00\",\"2016-05-09T00:00:00\",\"2016-05-10T00:00:00\",\"2016-05-11T00:00:00\",\"2016-05-12T00:00:00\",\"2016-05-13T00:00:00\",\"2016-05-16T00:00:00\",\"2016-05-17T00:00:00\",\"2016-05-18T00:00:00\",\"2016-05-19T00:00:00\",\"2016-05-20T00:00:00\",\"2016-05-23T00:00:00\",\"2016-05-24T00:00:00\",\"2016-05-25T00:00:00\",\"2016-05-26T00:00:00\",\"2016-05-27T00:00:00\",\"2016-05-31T00:00:00\",\"2016-06-01T00:00:00\",\"2016-06-02T00:00:00\",\"2016-06-03T00:00:00\",\"2016-06-06T00:00:00\",\"2016-06-07T00:00:00\",\"2016-06-08T00:00:00\",\"2016-06-09T00:00:00\",\"2016-06-10T00:00:00\",\"2016-06-13T00:00:00\",\"2016-06-14T00:00:00\",\"2016-06-15T00:00:00\",\"2016-06-16T00:00:00\",\"2016-06-17T00:00:00\",\"2016-06-20T00:00:00\",\"2016-06-21T00:00:00\",\"2016-06-22T00:00:00\",\"2016-06-23T00:00:00\",\"2016-06-24T00:00:00\",\"2016-06-27T00:00:00\",\"2016-06-28T00:00:00\",\"2016-06-29T00:00:00\",\"2016-06-30T00:00:00\",\"2016-07-01T00:00:00\",\"2016-07-05T00:00:00\",\"2016-07-06T00:00:00\",\"2016-07-07T00:00:00\",\"2016-07-08T00:00:00\",\"2016-07-11T00:00:00\",\"2016-07-12T00:00:00\",\"2016-07-13T00:00:00\",\"2016-07-14T00:00:00\",\"2016-07-15T00:00:00\",\"2016-07-18T00:00:00\",\"2016-07-19T00:00:00\",\"2016-07-20T00:00:00\",\"2016-07-21T00:00:00\",\"2016-07-22T00:00:00\",\"2016-07-25T00:00:00\",\"2016-07-26T00:00:00\",\"2016-07-27T00:00:00\",\"2016-07-28T00:00:00\",\"2016-07-29T00:00:00\",\"2016-08-01T00:00:00\",\"2016-08-02T00:00:00\",\"2016-08-03T00:00:00\",\"2016-08-04T00:00:00\",\"2016-08-05T00:00:00\",\"2016-08-08T00:00:00\",\"2016-08-09T00:00:00\",\"2016-08-10T00:00:00\",\"2016-08-11T00:00:00\",\"2016-08-12T00:00:00\",\"2016-08-15T00:00:00\",\"2016-08-16T00:00:00\",\"2016-08-17T00:00:00\",\"2016-08-18T00:00:00\",\"2016-08-19T00:00:00\",\"2016-08-22T00:00:00\",\"2016-08-23T00:00:00\",\"2016-08-24T00:00:00\",\"2016-08-25T00:00:00\",\"2016-08-26T00:00:00\",\"2016-08-29T00:00:00\",\"2016-08-30T00:00:00\",\"2016-08-31T00:00:00\",\"2016-09-01T00:00:00\",\"2016-09-02T00:00:00\",\"2016-09-06T00:00:00\",\"2016-09-07T00:00:00\",\"2016-09-08T00:00:00\",\"2016-09-09T00:00:00\",\"2016-09-12T00:00:00\",\"2016-09-13T00:00:00\",\"2016-09-14T00:00:00\",\"2016-09-15T00:00:00\",\"2016-09-16T00:00:00\",\"2016-09-19T00:00:00\",\"2016-09-20T00:00:00\",\"2016-09-21T00:00:00\",\"2016-09-22T00:00:00\",\"2016-09-23T00:00:00\",\"2016-09-26T00:00:00\",\"2016-09-27T00:00:00\",\"2016-09-28T00:00:00\",\"2016-09-29T00:00:00\",\"2016-09-30T00:00:00\",\"2016-10-03T00:00:00\",\"2016-10-04T00:00:00\",\"2016-10-05T00:00:00\",\"2016-10-06T00:00:00\",\"2016-10-07T00:00:00\",\"2016-10-10T00:00:00\",\"2016-10-11T00:00:00\",\"2016-10-12T00:00:00\",\"2016-10-13T00:00:00\",\"2016-10-14T00:00:00\",\"2016-10-17T00:00:00\",\"2016-10-18T00:00:00\",\"2016-10-19T00:00:00\",\"2016-10-20T00:00:00\",\"2016-10-21T00:00:00\",\"2016-10-24T00:00:00\",\"2016-10-25T00:00:00\",\"2016-10-26T00:00:00\",\"2016-10-27T00:00:00\",\"2016-10-28T00:00:00\",\"2016-10-31T00:00:00\",\"2016-11-01T00:00:00\",\"2016-11-02T00:00:00\",\"2016-11-03T00:00:00\",\"2016-11-04T00:00:00\",\"2016-11-07T00:00:00\",\"2016-11-08T00:00:00\",\"2016-11-09T00:00:00\",\"2016-11-10T00:00:00\",\"2016-11-11T00:00:00\",\"2016-11-14T00:00:00\",\"2016-11-15T00:00:00\",\"2016-11-16T00:00:00\",\"2016-11-17T00:00:00\",\"2016-11-18T00:00:00\",\"2016-11-21T00:00:00\",\"2016-11-22T00:00:00\",\"2016-11-23T00:00:00\",\"2016-11-25T00:00:00\",\"2016-11-28T00:00:00\",\"2016-11-29T00:00:00\",\"2016-11-30T00:00:00\",\"2016-12-01T00:00:00\",\"2016-12-02T00:00:00\",\"2016-12-05T00:00:00\",\"2016-12-06T00:00:00\",\"2016-12-07T00:00:00\",\"2016-12-08T00:00:00\",\"2016-12-09T00:00:00\",\"2016-12-12T00:00:00\",\"2016-12-13T00:00:00\",\"2016-12-14T00:00:00\",\"2016-12-15T00:00:00\",\"2016-12-16T00:00:00\",\"2016-12-19T00:00:00\",\"2016-12-20T00:00:00\",\"2016-12-21T00:00:00\",\"2016-12-22T00:00:00\",\"2016-12-23T00:00:00\",\"2016-12-27T00:00:00\",\"2016-12-28T00:00:00\",\"2016-12-29T00:00:00\",\"2016-12-30T00:00:00\",\"2017-01-03T00:00:00\",\"2017-01-04T00:00:00\",\"2017-01-05T00:00:00\",\"2017-01-06T00:00:00\",\"2017-01-09T00:00:00\",\"2017-01-10T00:00:00\",\"2017-01-11T00:00:00\",\"2017-01-12T00:00:00\",\"2017-01-13T00:00:00\",\"2017-01-17T00:00:00\",\"2017-01-18T00:00:00\",\"2017-01-19T00:00:00\",\"2017-01-20T00:00:00\",\"2017-01-23T00:00:00\",\"2017-01-24T00:00:00\",\"2017-01-25T00:00:00\",\"2017-01-26T00:00:00\",\"2017-01-27T00:00:00\",\"2017-01-30T00:00:00\",\"2017-01-31T00:00:00\",\"2017-02-01T00:00:00\",\"2017-02-02T00:00:00\",\"2017-02-03T00:00:00\",\"2017-02-06T00:00:00\",\"2017-02-07T00:00:00\",\"2017-02-08T00:00:00\",\"2017-02-09T00:00:00\",\"2017-02-10T00:00:00\",\"2017-02-13T00:00:00\",\"2017-02-14T00:00:00\",\"2017-02-15T00:00:00\",\"2017-02-16T00:00:00\",\"2017-02-17T00:00:00\",\"2017-02-21T00:00:00\",\"2017-02-22T00:00:00\",\"2017-02-23T00:00:00\",\"2017-02-24T00:00:00\",\"2017-02-27T00:00:00\",\"2017-02-28T00:00:00\",\"2017-03-01T00:00:00\",\"2017-03-02T00:00:00\",\"2017-03-03T00:00:00\",\"2017-03-06T00:00:00\",\"2017-03-07T00:00:00\",\"2017-03-08T00:00:00\",\"2017-03-09T00:00:00\",\"2017-03-10T00:00:00\",\"2017-03-13T00:00:00\",\"2017-03-14T00:00:00\",\"2017-03-15T00:00:00\",\"2017-03-16T00:00:00\",\"2017-03-17T00:00:00\",\"2017-03-20T00:00:00\",\"2017-03-21T00:00:00\",\"2017-03-22T00:00:00\",\"2017-03-23T00:00:00\",\"2017-03-24T00:00:00\",\"2017-03-27T00:00:00\",\"2017-03-28T00:00:00\",\"2017-03-29T00:00:00\",\"2017-03-30T00:00:00\",\"2017-03-31T00:00:00\",\"2017-04-03T00:00:00\",\"2017-04-04T00:00:00\",\"2017-04-05T00:00:00\",\"2017-04-06T00:00:00\",\"2017-04-07T00:00:00\",\"2017-04-10T00:00:00\",\"2017-04-11T00:00:00\",\"2017-04-12T00:00:00\",\"2017-04-13T00:00:00\",\"2017-04-17T00:00:00\",\"2017-04-18T00:00:00\",\"2017-04-19T00:00:00\",\"2017-04-20T00:00:00\",\"2017-04-21T00:00:00\",\"2017-04-24T00:00:00\",\"2017-04-25T00:00:00\",\"2017-04-26T00:00:00\",\"2017-04-27T00:00:00\",\"2017-04-28T00:00:00\",\"2017-05-01T00:00:00\",\"2017-05-02T00:00:00\",\"2017-05-03T00:00:00\",\"2017-05-04T00:00:00\",\"2017-05-05T00:00:00\",\"2017-05-08T00:00:00\",\"2017-05-09T00:00:00\",\"2017-05-10T00:00:00\",\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"type\":\"candlestick\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"rgba(100, 100, 100, 0.3)\"},\"name\":\"Volume\",\"x\":[\"2014-01-02T00:00:00\",\"2014-01-03T00:00:00\",\"2014-01-06T00:00:00\",\"2014-01-07T00:00:00\",\"2014-01-08T00:00:00\",\"2014-01-09T00:00:00\",\"2014-01-10T00:00:00\",\"2014-01-13T00:00:00\",\"2014-01-14T00:00:00\",\"2014-01-15T00:00:00\",\"2014-01-16T00:00:00\",\"2014-01-17T00:00:00\",\"2014-01-21T00:00:00\",\"2014-01-22T00:00:00\",\"2014-01-23T00:00:00\",\"2014-01-24T00:00:00\",\"2014-01-27T00:00:00\",\"2014-01-28T00:00:00\",\"2014-01-29T00:00:00\",\"2014-01-30T00:00:00\",\"2014-01-31T00:00:00\",\"2014-02-03T00:00:00\",\"2014-02-04T00:00:00\",\"2014-02-05T00:00:00\",\"2014-02-06T00:00:00\",\"2014-02-07T00:00:00\",\"2014-02-10T00:00:00\",\"2014-02-11T00:00:00\",\"2014-02-12T00:00:00\",\"2014-02-13T00:00:00\",\"2014-02-14T00:00:00\",\"2014-02-18T00:00:00\",\"2014-02-19T00:00:00\",\"2014-02-20T00:00:00\",\"2014-02-21T00:00:00\",\"2014-02-24T00:00:00\",\"2014-02-25T00:00:00\",\"2014-02-26T00:00:00\",\"2014-02-27T00:00:00\",\"2014-02-28T00:00:00\",\"2014-03-03T00:00:00\",\"2014-03-04T00:00:00\",\"2014-03-05T00:00:00\",\"2014-03-06T00:00:00\",\"2014-03-07T00:00:00\",\"2014-03-10T00:00:00\",\"2014-03-11T00:00:00\",\"2014-03-12T00:00:00\",\"2014-03-13T00:00:00\",\"2014-03-14T00:00:00\",\"2014-03-17T00:00:00\",\"2014-03-18T00:00:00\",\"2014-03-19T00:00:00\",\"2014-03-20T00:00:00\",\"2014-03-21T00:00:00\",\"2014-03-24T00:00:00\",\"2014-03-25T00:00:00\",\"2014-03-26T00:00:00\",\"2014-03-27T00:00:00\",\"2014-03-28T00:00:00\",\"2014-03-31T00:00:00\",\"2014-04-01T00:00:00\",\"2014-04-02T00:00:00\",\"2014-04-03T00:00:00\",\"2014-04-04T00:00:00\",\"2014-04-07T00:00:00\",\"2014-04-08T00:00:00\",\"2014-04-09T00:00:00\",\"2014-04-10T00:00:00\",\"2014-04-11T00:00:00\",\"2014-04-14T00:00:00\",\"2014-04-15T00:00:00\",\"2014-04-16T00:00:00\",\"2014-04-17T00:00:00\",\"2014-04-21T00:00:00\",\"2014-04-22T00:00:00\",\"2014-04-23T00:00:00\",\"2014-04-24T00:00:00\",\"2014-04-25T00:00:00\",\"2014-04-28T00:00:00\",\"2014-04-29T00:00:00\",\"2014-04-30T00:00:00\",\"2014-05-01T00:00:00\",\"2014-05-02T00:00:00\",\"2014-05-05T00:00:00\",\"2014-05-06T00:00:00\",\"2014-05-07T00:00:00\",\"2014-05-08T00:00:00\",\"2014-05-09T00:00:00\",\"2014-05-12T00:00:00\",\"2014-05-13T00:00:00\",\"2014-05-14T00:00:00\",\"2014-05-15T00:00:00\",\"2014-05-16T00:00:00\",\"2014-05-19T00:00:00\",\"2014-05-20T00:00:00\",\"2014-05-21T00:00:00\",\"2014-05-22T00:00:00\",\"2014-05-23T00:00:00\",\"2014-05-27T00:00:00\",\"2014-05-28T00:00:00\",\"2014-05-29T00:00:00\",\"2014-05-30T00:00:00\",\"2014-06-02T00:00:00\",\"2014-06-03T00:00:00\",\"2014-06-04T00:00:00\",\"2014-06-05T00:00:00\",\"2014-06-06T00:00:00\",\"2014-06-09T00:00:00\",\"2014-06-10T00:00:00\",\"2014-06-11T00:00:00\",\"2014-06-12T00:00:00\",\"2014-06-13T00:00:00\",\"2014-06-16T00:00:00\",\"2014-06-17T00:00:00\",\"2014-06-18T00:00:00\",\"2014-06-19T00:00:00\",\"2014-06-20T00:00:00\",\"2014-06-23T00:00:00\",\"2014-06-24T00:00:00\",\"2014-06-25T00:00:00\",\"2014-06-26T00:00:00\",\"2014-06-27T00:00:00\",\"2014-06-30T00:00:00\",\"2014-07-01T00:00:00\",\"2014-07-02T00:00:00\",\"2014-07-03T00:00:00\",\"2014-07-07T00:00:00\",\"2014-07-08T00:00:00\",\"2014-07-09T00:00:00\",\"2014-07-10T00:00:00\",\"2014-07-11T00:00:00\",\"2014-07-14T00:00:00\",\"2014-07-15T00:00:00\",\"2014-07-16T00:00:00\",\"2014-07-17T00:00:00\",\"2014-07-18T00:00:00\",\"2014-07-21T00:00:00\",\"2014-07-22T00:00:00\",\"2014-07-23T00:00:00\",\"2014-07-24T00:00:00\",\"2014-07-25T00:00:00\",\"2014-07-28T00:00:00\",\"2014-07-29T00:00:00\",\"2014-07-30T00:00:00\",\"2014-07-31T00:00:00\",\"2014-08-01T00:00:00\",\"2014-08-04T00:00:00\",\"2014-08-05T00:00:00\",\"2014-08-06T00:00:00\",\"2014-08-07T00:00:00\",\"2014-08-08T00:00:00\",\"2014-08-11T00:00:00\",\"2014-08-12T00:00:00\",\"2014-08-13T00:00:00\",\"2014-08-14T00:00:00\",\"2014-08-15T00:00:00\",\"2014-08-18T00:00:00\",\"2014-08-19T00:00:00\",\"2014-08-20T00:00:00\",\"2014-08-21T00:00:00\",\"2014-08-22T00:00:00\",\"2014-08-25T00:00:00\",\"2014-08-26T00:00:00\",\"2014-08-27T00:00:00\",\"2014-08-28T00:00:00\",\"2014-08-29T00:00:00\",\"2014-09-02T00:00:00\",\"2014-09-03T00:00:00\",\"2014-09-04T00:00:00\",\"2014-09-05T00:00:00\",\"2014-09-08T00:00:00\",\"2014-09-09T00:00:00\",\"2014-09-10T00:00:00\",\"2014-09-11T00:00:00\",\"2014-09-12T00:00:00\",\"2014-09-15T00:00:00\",\"2014-09-16T00:00:00\",\"2014-09-17T00:00:00\",\"2014-09-18T00:00:00\",\"2014-09-19T00:00:00\",\"2014-09-22T00:00:00\",\"2014-09-23T00:00:00\",\"2014-09-24T00:00:00\",\"2014-09-25T00:00:00\",\"2014-09-26T00:00:00\",\"2014-09-29T00:00:00\",\"2014-09-30T00:00:00\",\"2014-10-01T00:00:00\",\"2014-10-02T00:00:00\",\"2014-10-03T00:00:00\",\"2014-10-06T00:00:00\",\"2014-10-07T00:00:00\",\"2014-10-08T00:00:00\",\"2014-10-09T00:00:00\",\"2014-10-10T00:00:00\",\"2014-10-13T00:00:00\",\"2014-10-14T00:00:00\",\"2014-10-15T00:00:00\",\"2014-10-16T00:00:00\",\"2014-10-17T00:00:00\",\"2014-10-20T00:00:00\",\"2014-10-21T00:00:00\",\"2014-10-22T00:00:00\",\"2014-10-23T00:00:00\",\"2014-10-24T00:00:00\",\"2014-10-27T00:00:00\",\"2014-10-28T00:00:00\",\"2014-10-29T00:00:00\",\"2014-10-30T00:00:00\",\"2014-10-31T00:00:00\",\"2014-11-03T00:00:00\",\"2014-11-04T00:00:00\",\"2014-11-05T00:00:00\",\"2014-11-06T00:00:00\",\"2014-11-07T00:00:00\",\"2014-11-10T00:00:00\",\"2014-11-11T00:00:00\",\"2014-11-12T00:00:00\",\"2014-11-13T00:00:00\",\"2014-11-14T00:00:00\",\"2014-11-17T00:00:00\",\"2014-11-18T00:00:00\",\"2014-11-19T00:00:00\",\"2014-11-20T00:00:00\",\"2014-11-21T00:00:00\",\"2014-11-24T00:00:00\",\"2014-11-25T00:00:00\",\"2014-11-26T00:00:00\",\"2014-11-28T00:00:00\",\"2014-12-01T00:00:00\",\"2014-12-02T00:00:00\",\"2014-12-03T00:00:00\",\"2014-12-04T00:00:00\",\"2014-12-05T00:00:00\",\"2014-12-08T00:00:00\",\"2014-12-09T00:00:00\",\"2014-12-10T00:00:00\",\"2014-12-11T00:00:00\",\"2014-12-12T00:00:00\",\"2014-12-15T00:00:00\",\"2014-12-16T00:00:00\",\"2014-12-17T00:00:00\",\"2014-12-18T00:00:00\",\"2014-12-19T00:00:00\",\"2014-12-22T00:00:00\",\"2014-12-23T00:00:00\",\"2014-12-24T00:00:00\",\"2014-12-26T00:00:00\",\"2014-12-29T00:00:00\",\"2014-12-30T00:00:00\",\"2014-12-31T00:00:00\",\"2015-01-02T00:00:00\",\"2015-01-05T00:00:00\",\"2015-01-06T00:00:00\",\"2015-01-07T00:00:00\",\"2015-01-08T00:00:00\",\"2015-01-09T00:00:00\",\"2015-01-12T00:00:00\",\"2015-01-13T00:00:00\",\"2015-01-14T00:00:00\",\"2015-01-15T00:00:00\",\"2015-01-16T00:00:00\",\"2015-01-20T00:00:00\",\"2015-01-21T00:00:00\",\"2015-01-22T00:00:00\",\"2015-01-23T00:00:00\",\"2015-01-26T00:00:00\",\"2015-01-27T00:00:00\",\"2015-01-28T00:00:00\",\"2015-01-29T00:00:00\",\"2015-01-30T00:00:00\",\"2015-02-02T00:00:00\",\"2015-02-03T00:00:00\",\"2015-02-04T00:00:00\",\"2015-02-05T00:00:00\",\"2015-02-06T00:00:00\",\"2015-02-09T00:00:00\",\"2015-02-10T00:00:00\",\"2015-02-11T00:00:00\",\"2015-02-12T00:00:00\",\"2015-02-13T00:00:00\",\"2015-02-17T00:00:00\",\"2015-02-18T00:00:00\",\"2015-02-19T00:00:00\",\"2015-02-20T00:00:00\",\"2015-02-23T00:00:00\",\"2015-02-24T00:00:00\",\"2015-02-25T00:00:00\",\"2015-02-26T00:00:00\",\"2015-02-27T00:00:00\",\"2015-03-02T00:00:00\",\"2015-03-03T00:00:00\",\"2015-03-04T00:00:00\",\"2015-03-05T00:00:00\",\"2015-03-06T00:00:00\",\"2015-03-09T00:00:00\",\"2015-03-10T00:00:00\",\"2015-03-11T00:00:00\",\"2015-03-12T00:00:00\",\"2015-03-13T00:00:00\",\"2015-03-16T00:00:00\",\"2015-03-17T00:00:00\",\"2015-03-18T00:00:00\",\"2015-03-19T00:00:00\",\"2015-03-20T00:00:00\",\"2015-03-23T00:00:00\",\"2015-03-24T00:00:00\",\"2015-03-25T00:00:00\",\"2015-03-26T00:00:00\",\"2015-03-27T00:00:00\",\"2015-03-30T00:00:00\",\"2015-03-31T00:00:00\",\"2015-04-01T00:00:00\",\"2015-04-02T00:00:00\",\"2015-04-06T00:00:00\",\"2015-04-07T00:00:00\",\"2015-04-08T00:00:00\",\"2015-04-09T00:00:00\",\"2015-04-10T00:00:00\",\"2015-04-13T00:00:00\",\"2015-04-14T00:00:00\",\"2015-04-15T00:00:00\",\"2015-04-16T00:00:00\",\"2015-04-17T00:00:00\",\"2015-04-20T00:00:00\",\"2015-04-21T00:00:00\",\"2015-04-22T00:00:00\",\"2015-04-23T00:00:00\",\"2015-04-24T00:00:00\",\"2015-04-27T00:00:00\",\"2015-04-28T00:00:00\",\"2015-04-29T00:00:00\",\"2015-04-30T00:00:00\",\"2015-05-01T00:00:00\",\"2015-05-04T00:00:00\",\"2015-05-05T00:00:00\",\"2015-05-06T00:00:00\",\"2015-05-07T00:00:00\",\"2015-05-08T00:00:00\",\"2015-05-11T00:00:00\",\"2015-05-12T00:00:00\",\"2015-05-13T00:00:00\",\"2015-05-14T00:00:00\",\"2015-05-15T00:00:00\",\"2015-05-18T00:00:00\",\"2015-05-19T00:00:00\",\"2015-05-20T00:00:00\",\"2015-05-21T00:00:00\",\"2015-05-22T00:00:00\",\"2015-05-26T00:00:00\",\"2015-05-27T00:00:00\",\"2015-05-28T00:00:00\",\"2015-05-29T00:00:00\",\"2015-06-01T00:00:00\",\"2015-06-02T00:00:00\",\"2015-06-03T00:00:00\",\"2015-06-04T00:00:00\",\"2015-06-05T00:00:00\",\"2015-06-08T00:00:00\",\"2015-06-09T00:00:00\",\"2015-06-10T00:00:00\",\"2015-06-11T00:00:00\",\"2015-06-12T00:00:00\",\"2015-06-15T00:00:00\",\"2015-06-16T00:00:00\",\"2015-06-17T00:00:00\",\"2015-06-18T00:00:00\",\"2015-06-19T00:00:00\",\"2015-06-22T00:00:00\",\"2015-06-23T00:00:00\",\"2015-06-24T00:00:00\",\"2015-06-25T00:00:00\",\"2015-06-26T00:00:00\",\"2015-06-29T00:00:00\",\"2015-06-30T00:00:00\",\"2015-07-01T00:00:00\",\"2015-07-02T00:00:00\",\"2015-07-06T00:00:00\",\"2015-07-07T00:00:00\",\"2015-07-08T00:00:00\",\"2015-07-09T00:00:00\",\"2015-07-10T00:00:00\",\"2015-07-13T00:00:00\",\"2015-07-14T00:00:00\",\"2015-07-15T00:00:00\",\"2015-07-16T00:00:00\",\"2015-07-17T00:00:00\",\"2015-07-20T00:00:00\",\"2015-07-21T00:00:00\",\"2015-07-22T00:00:00\",\"2015-07-23T00:00:00\",\"2015-07-24T00:00:00\",\"2015-07-27T00:00:00\",\"2015-07-28T00:00:00\",\"2015-07-29T00:00:00\",\"2015-07-30T00:00:00\",\"2015-07-31T00:00:00\",\"2015-08-03T00:00:00\",\"2015-08-04T00:00:00\",\"2015-08-05T00:00:00\",\"2015-08-06T00:00:00\",\"2015-08-07T00:00:00\",\"2015-08-10T00:00:00\",\"2015-08-11T00:00:00\",\"2015-08-12T00:00:00\",\"2015-08-13T00:00:00\",\"2015-08-14T00:00:00\",\"2015-08-17T00:00:00\",\"2015-08-18T00:00:00\",\"2015-08-19T00:00:00\",\"2015-08-20T00:00:00\",\"2015-08-21T00:00:00\",\"2015-08-24T00:00:00\",\"2015-08-25T00:00:00\",\"2015-08-26T00:00:00\",\"2015-08-27T00:00:00\",\"2015-08-28T00:00:00\",\"2015-08-31T00:00:00\",\"2015-09-01T00:00:00\",\"2015-09-02T00:00:00\",\"2015-09-03T00:00:00\",\"2015-09-04T00:00:00\",\"2015-09-08T00:00:00\",\"2015-09-09T00:00:00\",\"2015-09-10T00:00:00\",\"2015-09-11T00:00:00\",\"2015-09-14T00:00:00\",\"2015-09-15T00:00:00\",\"2015-09-16T00:00:00\",\"2015-09-17T00:00:00\",\"2015-09-18T00:00:00\",\"2015-09-21T00:00:00\",\"2015-09-22T00:00:00\",\"2015-09-23T00:00:00\",\"2015-09-24T00:00:00\",\"2015-09-25T00:00:00\",\"2015-09-28T00:00:00\",\"2015-09-29T00:00:00\",\"2015-09-30T00:00:00\",\"2015-10-01T00:00:00\",\"2015-10-02T00:00:00\",\"2015-10-05T00:00:00\",\"2015-10-06T00:00:00\",\"2015-10-07T00:00:00\",\"2015-10-08T00:00:00\",\"2015-10-09T00:00:00\",\"2015-10-12T00:00:00\",\"2015-10-13T00:00:00\",\"2015-10-14T00:00:00\",\"2015-10-15T00:00:00\",\"2015-10-16T00:00:00\",\"2015-10-19T00:00:00\",\"2015-10-20T00:00:00\",\"2015-10-21T00:00:00\",\"2015-10-22T00:00:00\",\"2015-10-23T00:00:00\",\"2015-10-26T00:00:00\",\"2015-10-27T00:00:00\",\"2015-10-28T00:00:00\",\"2015-10-29T00:00:00\",\"2015-10-30T00:00:00\",\"2015-11-02T00:00:00\",\"2015-11-03T00:00:00\",\"2015-11-04T00:00:00\",\"2015-11-05T00:00:00\",\"2015-11-06T00:00:00\",\"2015-11-09T00:00:00\",\"2015-11-10T00:00:00\",\"2015-11-11T00:00:00\",\"2015-11-12T00:00:00\",\"2015-11-13T00:00:00\",\"2015-11-16T00:00:00\",\"2015-11-17T00:00:00\",\"2015-11-18T00:00:00\",\"2015-11-19T00:00:00\",\"2015-11-20T00:00:00\",\"2015-11-23T00:00:00\",\"2015-11-24T00:00:00\",\"2015-11-25T00:00:00\",\"2015-11-27T00:00:00\",\"2015-11-30T00:00:00\",\"2015-12-01T00:00:00\",\"2015-12-02T00:00:00\",\"2015-12-03T00:00:00\",\"2015-12-04T00:00:00\",\"2015-12-07T00:00:00\",\"2015-12-08T00:00:00\",\"2015-12-09T00:00:00\",\"2015-12-10T00:00:00\",\"2015-12-11T00:00:00\",\"2015-12-14T00:00:00\",\"2015-12-15T00:00:00\",\"2015-12-16T00:00:00\",\"2015-12-17T00:00:00\",\"2015-12-18T00:00:00\",\"2015-12-21T00:00:00\",\"2015-12-22T00:00:00\",\"2015-12-23T00:00:00\",\"2015-12-24T00:00:00\",\"2015-12-28T00:00:00\",\"2015-12-29T00:00:00\",\"2015-12-30T00:00:00\",\"2015-12-31T00:00:00\",\"2016-01-04T00:00:00\",\"2016-01-05T00:00:00\",\"2016-01-06T00:00:00\",\"2016-01-07T00:00:00\",\"2016-01-08T00:00:00\",\"2016-01-11T00:00:00\",\"2016-01-12T00:00:00\",\"2016-01-13T00:00:00\",\"2016-01-14T00:00:00\",\"2016-01-15T00:00:00\",\"2016-01-19T00:00:00\",\"2016-01-20T00:00:00\",\"2016-01-21T00:00:00\",\"2016-01-22T00:00:00\",\"2016-01-25T00:00:00\",\"2016-01-26T00:00:00\",\"2016-01-27T00:00:00\",\"2016-01-28T00:00:00\",\"2016-01-29T00:00:00\",\"2016-02-01T00:00:00\",\"2016-02-02T00:00:00\",\"2016-02-03T00:00:00\",\"2016-02-04T00:00:00\",\"2016-02-05T00:00:00\",\"2016-02-08T00:00:00\",\"2016-02-09T00:00:00\",\"2016-02-10T00:00:00\",\"2016-02-11T00:00:00\",\"2016-02-12T00:00:00\",\"2016-02-16T00:00:00\",\"2016-02-17T00:00:00\",\"2016-02-18T00:00:00\",\"2016-02-19T00:00:00\",\"2016-02-22T00:00:00\",\"2016-02-23T00:00:00\",\"2016-02-24T00:00:00\",\"2016-02-25T00:00:00\",\"2016-02-26T00:00:00\",\"2016-02-29T00:00:00\",\"2016-03-01T00:00:00\",\"2016-03-02T00:00:00\",\"2016-03-03T00:00:00\",\"2016-03-04T00:00:00\",\"2016-03-07T00:00:00\",\"2016-03-08T00:00:00\",\"2016-03-09T00:00:00\",\"2016-03-10T00:00:00\",\"2016-03-11T00:00:00\",\"2016-03-14T00:00:00\",\"2016-03-15T00:00:00\",\"2016-03-16T00:00:00\",\"2016-03-17T00:00:00\",\"2016-03-18T00:00:00\",\"2016-03-21T00:00:00\",\"2016-03-22T00:00:00\",\"2016-03-23T00:00:00\",\"2016-03-24T00:00:00\",\"2016-03-28T00:00:00\",\"2016-03-29T00:00:00\",\"2016-03-30T00:00:00\",\"2016-03-31T00:00:00\",\"2016-04-01T00:00:00\",\"2016-04-04T00:00:00\",\"2016-04-05T00:00:00\",\"2016-04-06T00:00:00\",\"2016-04-07T00:00:00\",\"2016-04-08T00:00:00\",\"2016-04-11T00:00:00\",\"2016-04-12T00:00:00\",\"2016-04-13T00:00:00\",\"2016-04-14T00:00:00\",\"2016-04-15T00:00:00\",\"2016-04-18T00:00:00\",\"2016-04-19T00:00:00\",\"2016-04-20T00:00:00\",\"2016-04-21T00:00:00\",\"2016-04-22T00:00:00\",\"2016-04-25T00:00:00\",\"2016-04-26T00:00:00\",\"2016-04-27T00:00:00\",\"2016-04-28T00:00:00\",\"2016-04-29T00:00:00\",\"2016-05-02T00:00:00\",\"2016-05-03T00:00:00\",\"2016-05-04T00:00:00\",\"2016-05-05T00:00:00\",\"2016-05-06T00:00:00\",\"2016-05-09T00:00:00\",\"2016-05-10T00:00:00\",\"2016-05-11T00:00:00\",\"2016-05-12T00:00:00\",\"2016-05-13T00:00:00\",\"2016-05-16T00:00:00\",\"2016-05-17T00:00:00\",\"2016-05-18T00:00:00\",\"2016-05-19T00:00:00\",\"2016-05-20T00:00:00\",\"2016-05-23T00:00:00\",\"2016-05-24T00:00:00\",\"2016-05-25T00:00:00\",\"2016-05-26T00:00:00\",\"2016-05-27T00:00:00\",\"2016-05-31T00:00:00\",\"2016-06-01T00:00:00\",\"2016-06-02T00:00:00\",\"2016-06-03T00:00:00\",\"2016-06-06T00:00:00\",\"2016-06-07T00:00:00\",\"2016-06-08T00:00:00\",\"2016-06-09T00:00:00\",\"2016-06-10T00:00:00\",\"2016-06-13T00:00:00\",\"2016-06-14T00:00:00\",\"2016-06-15T00:00:00\",\"2016-06-16T00:00:00\",\"2016-06-17T00:00:00\",\"2016-06-20T00:00:00\",\"2016-06-21T00:00:00\",\"2016-06-22T00:00:00\",\"2016-06-23T00:00:00\",\"2016-06-24T00:00:00\",\"2016-06-27T00:00:00\",\"2016-06-28T00:00:00\",\"2016-06-29T00:00:00\",\"2016-06-30T00:00:00\",\"2016-07-01T00:00:00\",\"2016-07-05T00:00:00\",\"2016-07-06T00:00:00\",\"2016-07-07T00:00:00\",\"2016-07-08T00:00:00\",\"2016-07-11T00:00:00\",\"2016-07-12T00:00:00\",\"2016-07-13T00:00:00\",\"2016-07-14T00:00:00\",\"2016-07-15T00:00:00\",\"2016-07-18T00:00:00\",\"2016-07-19T00:00:00\",\"2016-07-20T00:00:00\",\"2016-07-21T00:00:00\",\"2016-07-22T00:00:00\",\"2016-07-25T00:00:00\",\"2016-07-26T00:00:00\",\"2016-07-27T00:00:00\",\"2016-07-28T00:00:00\",\"2016-07-29T00:00:00\",\"2016-08-01T00:00:00\",\"2016-08-02T00:00:00\",\"2016-08-03T00:00:00\",\"2016-08-04T00:00:00\",\"2016-08-05T00:00:00\",\"2016-08-08T00:00:00\",\"2016-08-09T00:00:00\",\"2016-08-10T00:00:00\",\"2016-08-11T00:00:00\",\"2016-08-12T00:00:00\",\"2016-08-15T00:00:00\",\"2016-08-16T00:00:00\",\"2016-08-17T00:00:00\",\"2016-08-18T00:00:00\",\"2016-08-19T00:00:00\",\"2016-08-22T00:00:00\",\"2016-08-23T00:00:00\",\"2016-08-24T00:00:00\",\"2016-08-25T00:00:00\",\"2016-08-26T00:00:00\",\"2016-08-29T00:00:00\",\"2016-08-30T00:00:00\",\"2016-08-31T00:00:00\",\"2016-09-01T00:00:00\",\"2016-09-02T00:00:00\",\"2016-09-06T00:00:00\",\"2016-09-07T00:00:00\",\"2016-09-08T00:00:00\",\"2016-09-09T00:00:00\",\"2016-09-12T00:00:00\",\"2016-09-13T00:00:00\",\"2016-09-14T00:00:00\",\"2016-09-15T00:00:00\",\"2016-09-16T00:00:00\",\"2016-09-19T00:00:00\",\"2016-09-20T00:00:00\",\"2016-09-21T00:00:00\",\"2016-09-22T00:00:00\",\"2016-09-23T00:00:00\",\"2016-09-26T00:00:00\",\"2016-09-27T00:00:00\",\"2016-09-28T00:00:00\",\"2016-09-29T00:00:00\",\"2016-09-30T00:00:00\",\"2016-10-03T00:00:00\",\"2016-10-04T00:00:00\",\"2016-10-05T00:00:00\",\"2016-10-06T00:00:00\",\"2016-10-07T00:00:00\",\"2016-10-10T00:00:00\",\"2016-10-11T00:00:00\",\"2016-10-12T00:00:00\",\"2016-10-13T00:00:00\",\"2016-10-14T00:00:00\",\"2016-10-17T00:00:00\",\"2016-10-18T00:00:00\",\"2016-10-19T00:00:00\",\"2016-10-20T00:00:00\",\"2016-10-21T00:00:00\",\"2016-10-24T00:00:00\",\"2016-10-25T00:00:00\",\"2016-10-26T00:00:00\",\"2016-10-27T00:00:00\",\"2016-10-28T00:00:00\",\"2016-10-31T00:00:00\",\"2016-11-01T00:00:00\",\"2016-11-02T00:00:00\",\"2016-11-03T00:00:00\",\"2016-11-04T00:00:00\",\"2016-11-07T00:00:00\",\"2016-11-08T00:00:00\",\"2016-11-09T00:00:00\",\"2016-11-10T00:00:00\",\"2016-11-11T00:00:00\",\"2016-11-14T00:00:00\",\"2016-11-15T00:00:00\",\"2016-11-16T00:00:00\",\"2016-11-17T00:00:00\",\"2016-11-18T00:00:00\",\"2016-11-21T00:00:00\",\"2016-11-22T00:00:00\",\"2016-11-23T00:00:00\",\"2016-11-25T00:00:00\",\"2016-11-28T00:00:00\",\"2016-11-29T00:00:00\",\"2016-11-30T00:00:00\",\"2016-12-01T00:00:00\",\"2016-12-02T00:00:00\",\"2016-12-05T00:00:00\",\"2016-12-06T00:00:00\",\"2016-12-07T00:00:00\",\"2016-12-08T00:00:00\",\"2016-12-09T00:00:00\",\"2016-12-12T00:00:00\",\"2016-12-13T00:00:00\",\"2016-12-14T00:00:00\",\"2016-12-15T00:00:00\",\"2016-12-16T00:00:00\",\"2016-12-19T00:00:00\",\"2016-12-20T00:00:00\",\"2016-12-21T00:00:00\",\"2016-12-22T00:00:00\",\"2016-12-23T00:00:00\",\"2016-12-27T00:00:00\",\"2016-12-28T00:00:00\",\"2016-12-29T00:00:00\",\"2016-12-30T00:00:00\",\"2017-01-03T00:00:00\",\"2017-01-04T00:00:00\",\"2017-01-05T00:00:00\",\"2017-01-06T00:00:00\",\"2017-01-09T00:00:00\",\"2017-01-10T00:00:00\",\"2017-01-11T00:00:00\",\"2017-01-12T00:00:00\",\"2017-01-13T00:00:00\",\"2017-01-17T00:00:00\",\"2017-01-18T00:00:00\",\"2017-01-19T00:00:00\",\"2017-01-20T00:00:00\",\"2017-01-23T00:00:00\",\"2017-01-24T00:00:00\",\"2017-01-25T00:00:00\",\"2017-01-26T00:00:00\",\"2017-01-27T00:00:00\",\"2017-01-30T00:00:00\",\"2017-01-31T00:00:00\",\"2017-02-01T00:00:00\",\"2017-02-02T00:00:00\",\"2017-02-03T00:00:00\",\"2017-02-06T00:00:00\",\"2017-02-07T00:00:00\",\"2017-02-08T00:00:00\",\"2017-02-09T00:00:00\",\"2017-02-10T00:00:00\",\"2017-02-13T00:00:00\",\"2017-02-14T00:00:00\",\"2017-02-15T00:00:00\",\"2017-02-16T00:00:00\",\"2017-02-17T00:00:00\",\"2017-02-21T00:00:00\",\"2017-02-22T00:00:00\",\"2017-02-23T00:00:00\",\"2017-02-24T00:00:00\",\"2017-02-27T00:00:00\",\"2017-02-28T00:00:00\",\"2017-03-01T00:00:00\",\"2017-03-02T00:00:00\",\"2017-03-03T00:00:00\",\"2017-03-06T00:00:00\",\"2017-03-07T00:00:00\",\"2017-03-08T00:00:00\",\"2017-03-09T00:00:00\",\"2017-03-10T00:00:00\",\"2017-03-13T00:00:00\",\"2017-03-14T00:00:00\",\"2017-03-15T00:00:00\",\"2017-03-16T00:00:00\",\"2017-03-17T00:00:00\",\"2017-03-20T00:00:00\",\"2017-03-21T00:00:00\",\"2017-03-22T00:00:00\",\"2017-03-23T00:00:00\",\"2017-03-24T00:00:00\",\"2017-03-27T00:00:00\",\"2017-03-28T00:00:00\",\"2017-03-29T00:00:00\",\"2017-03-30T00:00:00\",\"2017-03-31T00:00:00\",\"2017-04-03T00:00:00\",\"2017-04-04T00:00:00\",\"2017-04-05T00:00:00\",\"2017-04-06T00:00:00\",\"2017-04-07T00:00:00\",\"2017-04-10T00:00:00\",\"2017-04-11T00:00:00\",\"2017-04-12T00:00:00\",\"2017-04-13T00:00:00\",\"2017-04-17T00:00:00\",\"2017-04-18T00:00:00\",\"2017-04-19T00:00:00\",\"2017-04-20T00:00:00\",\"2017-04-21T00:00:00\",\"2017-04-24T00:00:00\",\"2017-04-25T00:00:00\",\"2017-04-26T00:00:00\",\"2017-04-27T00:00:00\",\"2017-04-28T00:00:00\",\"2017-05-01T00:00:00\",\"2017-05-02T00:00:00\",\"2017-05-03T00:00:00\",\"2017-05-04T00:00:00\",\"2017-05-05T00:00:00\",\"2017-05-08T00:00:00\",\"2017-05-09T00:00:00\",\"2017-05-10T00:00:00\",\"2017-05-11T00:00:00\",\"2017-05-12T00:00:00\",\"2017-05-15T00:00:00\",\"2017-05-16T00:00:00\",\"2017-05-17T00:00:00\",\"2017-05-18T00:00:00\",\"2017-05-19T00:00:00\",\"2017-05-22T00:00:00\",\"2017-05-23T00:00:00\",\"2017-05-24T00:00:00\",\"2017-05-25T00:00:00\",\"2017-05-26T00:00:00\",\"2017-05-30T00:00:00\",\"2017-05-31T00:00:00\",\"2017-06-01T00:00:00\",\"2017-06-02T00:00:00\",\"2017-06-05T00:00:00\",\"2017-06-06T00:00:00\",\"2017-06-07T00:00:00\",\"2017-06-08T00:00:00\",\"2017-06-09T00:00:00\",\"2017-06-12T00:00:00\",\"2017-06-13T00:00:00\",\"2017-06-14T00:00:00\",\"2017-06-15T00:00:00\",\"2017-06-16T00:00:00\",\"2017-06-19T00:00:00\",\"2017-06-20T00:00:00\",\"2017-06-21T00:00:00\",\"2017-06-22T00:00:00\",\"2017-06-23T00:00:00\",\"2017-06-26T00:00:00\",\"2017-06-27T00:00:00\",\"2017-06-28T00:00:00\",\"2017-06-29T00:00:00\",\"2017-06-30T00:00:00\",\"2017-07-03T00:00:00\",\"2017-07-05T00:00:00\",\"2017-07-06T00:00:00\",\"2017-07-07T00:00:00\",\"2017-07-10T00:00:00\",\"2017-07-11T00:00:00\",\"2017-07-12T00:00:00\",\"2017-07-13T00:00:00\",\"2017-07-14T00:00:00\",\"2017-07-17T00:00:00\",\"2017-07-18T00:00:00\",\"2017-07-19T00:00:00\",\"2017-07-20T00:00:00\",\"2017-07-21T00:00:00\",\"2017-07-24T00:00:00\",\"2017-07-25T00:00:00\",\"2017-07-26T00:00:00\",\"2017-07-27T00:00:00\",\"2017-07-28T00:00:00\",\"2017-07-31T00:00:00\",\"2017-08-01T00:00:00\",\"2017-08-02T00:00:00\",\"2017-08-03T00:00:00\",\"2017-08-04T00:00:00\",\"2017-08-07T00:00:00\",\"2017-08-08T00:00:00\",\"2017-08-09T00:00:00\",\"2017-08-10T00:00:00\",\"2017-08-11T00:00:00\",\"2017-08-14T00:00:00\",\"2017-08-15T00:00:00\",\"2017-08-16T00:00:00\",\"2017-08-17T00:00:00\",\"2017-08-18T00:00:00\",\"2017-08-21T00:00:00\",\"2017-08-22T00:00:00\",\"2017-08-23T00:00:00\",\"2017-08-24T00:00:00\",\"2017-08-25T00:00:00\",\"2017-08-28T00:00:00\",\"2017-08-29T00:00:00\",\"2017-08-30T00:00:00\",\"2017-08-31T00:00:00\",\"2017-09-01T00:00:00\",\"2017-09-05T00:00:00\",\"2017-09-06T00:00:00\",\"2017-09-07T00:00:00\",\"2017-09-08T00:00:00\",\"2017-09-11T00:00:00\",\"2017-09-12T00:00:00\",\"2017-09-13T00:00:00\",\"2017-09-14T00:00:00\",\"2017-09-15T00:00:00\",\"2017-09-18T00:00:00\",\"2017-09-19T00:00:00\",\"2017-09-20T00:00:00\",\"2017-09-21T00:00:00\",\"2017-09-22T00:00:00\",\"2017-09-25T00:00:00\",\"2017-09-26T00:00:00\",\"2017-09-27T00:00:00\",\"2017-09-28T00:00:00\",\"2017-09-29T00:00:00\",\"2017-10-02T00:00:00\",\"2017-10-03T00:00:00\",\"2017-10-04T00:00:00\",\"2017-10-05T00:00:00\",\"2017-10-06T00:00:00\",\"2017-10-09T00:00:00\",\"2017-10-10T00:00:00\",\"2017-10-11T00:00:00\",\"2017-10-12T00:00:00\",\"2017-10-13T00:00:00\",\"2017-10-16T00:00:00\",\"2017-10-17T00:00:00\",\"2017-10-18T00:00:00\",\"2017-10-19T00:00:00\",\"2017-10-20T00:00:00\",\"2017-10-23T00:00:00\",\"2017-10-24T00:00:00\",\"2017-10-25T00:00:00\",\"2017-10-26T00:00:00\",\"2017-10-27T00:00:00\",\"2017-10-30T00:00:00\",\"2017-10-31T00:00:00\",\"2017-11-01T00:00:00\",\"2017-11-02T00:00:00\",\"2017-11-03T00:00:00\",\"2017-11-06T00:00:00\",\"2017-11-07T00:00:00\",\"2017-11-08T00:00:00\",\"2017-11-09T00:00:00\",\"2017-11-10T00:00:00\",\"2017-11-13T00:00:00\",\"2017-11-14T00:00:00\",\"2017-11-15T00:00:00\",\"2017-11-16T00:00:00\",\"2017-11-17T00:00:00\",\"2017-11-20T00:00:00\",\"2017-11-21T00:00:00\",\"2017-11-22T00:00:00\",\"2017-11-24T00:00:00\",\"2017-11-27T00:00:00\",\"2017-11-28T00:00:00\",\"2017-11-29T00:00:00\",\"2017-11-30T00:00:00\",\"2017-12-01T00:00:00\",\"2017-12-04T00:00:00\",\"2017-12-05T00:00:00\",\"2017-12-06T00:00:00\",\"2017-12-07T00:00:00\",\"2017-12-08T00:00:00\",\"2017-12-11T00:00:00\",\"2017-12-12T00:00:00\",\"2017-12-13T00:00:00\",\"2017-12-14T00:00:00\",\"2017-12-15T00:00:00\",\"2017-12-18T00:00:00\",\"2017-12-19T00:00:00\",\"2017-12-20T00:00:00\",\"2017-12-21T00:00:00\",\"2017-12-22T00:00:00\",\"2017-12-26T00:00:00\",\"2017-12-27T00:00:00\",\"2017-12-28T00:00:00\",\"2017-12-29T00:00:00\"],\"y\":[[119636900],[81390600],[108028200],[86144200],[96582300],[90683400],[102026400],[149892000],[105016100],[98525800],[72290600],[107848700],[88621200],[61270900],[132496900],[208677100],[180843100],[110463200],[216597300],[118938100],[194677900],[254837100],[165012400],[164230500],[132877600],[170787200],[92218800],[117814100],[94717700],[100542200],[96498400],[80460900],[126524300],[104998100],[118116400],[114063900],[117085000],[98677200],[93880800],[150842000],[167748500],[167545900],[88376900],[82516500],[114513500],[74939200],[99009100],[104824400],[155014300],[153919600],[98359500],[101804600],[176267300],[117241000],[163128000],[121411000],[103852000],[119843000],[142383000],[101642000],[99745000],[89193000],[78774000],[77435000],[169381000],[140803000],[112660000],[100254000],[172959000],[167251000],[132382000],[157093000],[105197000],[105255000],[68329000],[85790000],[73869000],[88170000],[100380000],[135121000],[84098000],[101508000],[93019000],[98122000],[75883000],[85454000],[106500000],[93618000],[83679000],[86940000],[66454000],[72367000],[154956000],[97458000],[63839000],[111644000],[89093000],[61549000],[61092800],[72010000],[66723000],[64377000],[76316000],[64656000],[65047000],[55529000],[92103000],[78696000],[65119000],[57129000],[68772000],[106350000],[82017000],[87424000],[84834000],[105267000],[85929000],[100587000],[70611000],[96237000],[82782000],[84312000],[71445100],[70201200],[90470000],[52475000],[52938800],[61696000],[108143000],[72992000],[99040000],[64243000],[58658000],[111307000],[79986400],[145398000],[124330000],[67592000],[67678000],[65612000],[56888000],[76837000],[69259000],[80466000],[104222000],[183479000],[189261000],[91340000],[152690000],[94818000],[135733000],[117014000],[74544000],[73632000],[69047000],[57371000],[139951000],[75424000],[59135000],[72763000],[67791000],[76107000],[63855000],[47298000],[47874000],[58330000],[65907000],[72426000],[57462000],[85236000],[102177000],[64146000],[88591000],[67251000],[66774400],[117409300],[76401000],[116201000],[151266000],[94990000],[121649000],[125553000],[111393000],[107276000],[150300000],[103547000],[95112000],[131302000],[177798000],[157285000],[121569000],[104778000],[147913000],[186461000],[210705000],[221909000],[230939000],[215847000],[380715000],[270391000],[214625000],[130011000],[154949000],[151822000],[154944000],[117927000],[82954000],[106736000],[142557000],[113330000],[146903000],[93600000],[93343000],[91709000],[107089000],[89540000],[66319000],[54499400],[90120300],[85357900],[80417500],[80441000],[76068100],[82373000],[72840300],[142327300],[65880800],[79108300],[62167800],[57890100],[103968400],[74507200],[68952000],[91316600],[91025500],[108588200],[125180100],[159856400],[159012800],[202330200],[189965800],[259543800],[253910100],[257633900],[245084600],[148318900],[122167900],[42963400],[57326700],[79643900],[73540800],[130333800],[121465900],[169632600],[209151400],[125346700],[147217800],[158567300],[144396100],[214553300],[192991100],[176613900],[211879600],[130991100],[122942700],[174356000],[117516800],[92009700],[134044600],[168514300],[173585400],[197729700],[163107000],[124212900],[134306700],[97953200],[125672000],[87219000],[96164200],[91087800],[97545900],[93670400],[76968200],[80652900],[91462500],[140896400],[74411100],[72472300],[73061700],[72697900],[108076000],[87491400],[110325800],[114497200],[76873000],[188128000],[89818900],[157121300],[110145700],[93993500],[162410900],[136099200],[94510400],[228808500],[117917300],[177715100],[71784500],[77805300],[159521700],[153067200],[118939000],[96180400],[126768700],[137303600],[86900900],[114368200],[81236300],[89351900],[85548900],[72722900],[74436600],[75099900],[99529300],[68934900],[191113200],[92189500],[72559800],[78264600],[102585900],[61327400],[79358100],[86863500],[125684900],[161304900],[103399700],[70927200],[113326200],[135060200],[88244900],[155877300],[75708100],[119727600],[94667900],[95934000],[76510100],[74549700],[72114600],[76857500],[64764600],[57433500],[124308600],[93214000],[74974600],[124919600],[93338800],[91531000],[87820900],[151882800],[121704700],[89063300],[105034700],[134551300],[73876400],[135382400],[124384200],[85308200],[126708600],[165867900],[130478700],[70696000],[68476800],[92307300],[97107400],[104174800],[202621300],[182925100],[135979900],[104373700],[117975400],[173820200],[164020100],[144113100],[129456900],[106069400],[81709600],[97914100],[106683300],[89030000],[70446800],[77965000],[88667900],[90509100],[117755000],[132361100],[123544800],[105791300],[91304400],[103266900],[113965700],[81820800],[85786800],[116030800],[117858000],[80270700],[126081400],[172123700],[89383300],[72786500],[79072600],[71692700],[172946000],[194327900],[346588500],[507244300],[369833100],[339257000],[274143900],[160414400],[163298800],[256000400],[160269300],[152087800],[207081000],[116025700],[149347700],[158611100],[119691200],[79452000],[113806200],[99581600],[276046600],[223657500],[105726200],[153890900],[92790600],[159378800],[155054800],[178515900],[159045600],[163452000],[131079000],[211003300],[126320800],[110274500],[124307300],[153055200],[107069200],[56395600],[88038700],[99106200],[134142200],[114580100],[76523900],[78448500],[102038000],[174911700],[144442300],[69033000],[77905800],[135906700],[90525500],[131076900],[86270800],[95246100],[96224500],[78408700],[110471500],[131008700],[75874600],[67846000],[121315200],[153577100],[117645200],[121123700],[121342500],[88220500],[94011500],[64931200],[98874400],[51980100],[37317800],[112822700],[97858400],[108441300],[166224200],[192913900],[102027100],[103372400],[162401500],[116128900],[211173300],[182385200],[154069600],[197017000],[173092500],[251393500],[99094300],[111026200],[110987200],[48539600],[65899900],[92640700],[63317700],[114877900],[222353500],[110845800],[152112600],[213436100],[209817200],[187941300],[172330500],[221168900],[240795600],[324846400],[195244400],[286547800],[195772900],[168319600],[130371700],[141036800],[185681700],[143798800],[210529300],[136061600],[182564900],[205054900],[139531800],[180788300],[191526700],[184513100],[148214100],[219058900],[127632400],[120250700],[136009500],[102343000],[114793000],[103640300],[111455300],[150812200],[110728300],[129833700],[125918100],[141799700],[102415000],[95172200],[129293600],[100219000],[123974900],[94801200],[156838700],[137964500],[73612000],[93169100],[129303200],[134278500],[138372400],[72926700],[97471900],[81052500],[84360900],[62408200],[92922900],[86365300],[94584100],[114423500],[63497000],[99662200],[91839800],[113859000],[95040600],[83757500],[115350600],[96336400],[65212900],[75761600],[82531000],[88316100],[81100300],[85695000],[99251700],[66166500],[75864200],[77329400],[97216200],[142424100],[62188000],[106422100],[92243800],[67619200],[89315000],[74374900],[77472200],[81727000],[89586300],[96474600],[77486800],[114924900],[120062100],[115430500],[104990400],[58682600],[93537800],[76621400],[55280700],[64211200],[109879400],[69936200],[63044700],[101757100],[64887000],[60974800],[66170900],[73786900],[113829200],[117751200],[125059300],[109124500],[149533100],[117055700],[82789600],[72461700],[95560500],[102731400],[333444400],[230775800],[159382400],[137328600],[165021900],[106055300],[109803700],[96021500],[85593800],[133971000],[73633900],[101275600],[87324100],[91230900],[107155400],[58725900],[54345700],[58159500],[67777300],[62787500],[55873100],[70080500],[84083900],[65035700],[79519400],[73311400],[92295500],[53993600],[46585500],[71892200],[39906500],[51251700],[57941100],[72504300],[61313500],[49813500],[53213600],[75134300],[52989300],[75443000],[61368800],[53399200],[71728900],[69224800],[122506300],[70502200],[58114500],[85269500],[97844200],[79293900],[56702100],[76554900],[74102900],[221589100],[168110900],[182828800],[134185500],[134427900],[155236400],[80250500],[69665300],[110284400],[76678700],[73630900],[89827300],[78494800],[87411000],[128070600],[117202900],[83512100],[119948100],[72816000],[62927400],[89788300],[51855000],[130367400],[73866100],[101357000],[93346200],[58275700],[76869700],[66519200],[73639800],[89089100],[60146600],[66542300],[75705500],[77220200],[140623200],[61272500],[122781800],[103330800],[88939300],[109122100],[109794900],[106772100],[258429000],[172113300],[100552700],[94580000],[91652600],[65617700],[69797200],[86265800],[72402600],[67429000],[56620200],[37872300],[76572500],[69886700],[113291800],[79040500],[74840300],[67837800],[59877400],[110738100],[99714400],[88005800],[102016100],[110477500],[142501800],[124972600],[156420200],[90341100],[89838800],[67909000],[56219100],[36697800],[42672500],[64095000],[48696100],[108998300],[91366500],[78744400],[78379000],[71559900],[46939700],[63771900],[74650000],[72113200],[62717900],[61240800],[54793300],[66608800],[129168600],[75061600],[95555300],[84437700],[59970700],[59711100],[79737300],[75880800],[79117700],[69657600],[80563200],[57790100],[57931200],[51566200],[65955200],[66015900],[55182100],[71109000],[86785800],[84722400],[77204100],[88946100],[62115200],[74615900],[82381600],[56515400],[96961900],[149158200],[70246000],[81974300],[55391500],[65103700],[78168800],[90683900],[81991700],[57256800],[59880800],[96081800],[78344000],[89002100],[52537000],[131809300],[97569200],[100410300],[112504900],[87454500],[93483900],[61950400],[56737900],[73733100],[85546500],[56466200],[108800600],[69135800],[74412300],[67615300],[88045300],[81864400],[92880400],[68405400],[83225800],[68699900],[92572200],[110389800],[119209900],[76698300],[84702500],[57410300],[63532800],[66882500],[57375700],[73137700],[61462700],[62001300],[48385700],[51363200],[54293800],[62358300],[53912700],[61918900],[51241800],[172174100],[107047700],[115011400],[61010600],[48341700],[46927700],[64071700],[46629900],[35201900],[91796000],[68962000],[88666100],[44698800],[50375400],[54144300],[65950700],[132256400],[86108100],[60067000],[78602300],[66464900],[84553100],[65123800],[56906400],[55977600],[44148100],[66986800],[56700500],[82247700],[70042600],[106949700],[86820700],[39153800],[54427600],[65400800],[57972300],[36663300],[50354600],[59610400],[39471600],[60262700],[33531900],[42742500],[51034300],[47135200],[82340800],[46622300],[54915600],[47575400],[70766600],[50088400],[65838700],[55050400],[47211200],[40856000],[60191800],[31995000],[61719400],[62632600],[120479500],[74869900],[73291900],[55242700],[56715500],[128490400],[136748000],[65469700],[63140100],[50203800],[50741700],[64445900],[40565600],[51135700],[62030800],[103803900],[62007000],[91398800],[57916900],[58034700],[63832800],[71364800],[56896000],[59228000],[95446300],[95432400],[46235200],[47108100],[59574100],[48211400],[51214000],[57064400],[54082000],[81001400],[44778800],[85578000],[59023000],[66810200],[55953600],[63522800],[80646000],[35803100],[43057400],[47674300],[47065100],[54800400],[38221700],[31561000],[40888300],[61903800],[89176400],[63915300],[66935900],[103715300],[69798000],[85562500],[54285700],[60304800],[54202700],[56449500],[59589700],[49652600],[57502200],[50469600],[95085500],[59984700],[50228600],[61315200],[80811500],[67777000],[75756800],[48075500],[69176800],[45033400],[27856500],[52274900],[98971700],[77512100],[127894400],[164390900],[94040600],[77994500],[75898600],[77218600],[76563900],[83077500],[85195800],[102905400],[100666700],[144610300],[83653600],[82382900],[76751500],[67032300],[78720900],[45244400],[57751000],[45116100],[96007400]],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"matches\":\"x2\",\"showticklabels\":false,\"rangeslider\":{\"visible\":false}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.33499999999999996,0.9999999999999999],\"title\":{\"text\":\"Price\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.285],\"title\":{\"text\":\"Volume\"}},\"title\":{\"text\":\"SPY Price Action\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('09c293f2-2290-4c13-88f8-cc01dbf58677');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing high_vol_uptrend...\n",
            "\n",
            "Preparing data for high_vol_uptrend...\n",
            "Using batch size: 32\n",
            "\n",
            "Training high_vol_uptrend model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.2456 - val_loss: 0.0537\n",
            "Epoch 2/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0287 - val_loss: 0.0153\n",
            "Epoch 3/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0101 - val_loss: 0.0132\n",
            "Epoch 4/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0058 - val_loss: 0.0150\n",
            "Epoch 5/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0130\n",
            "Epoch 6/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0053 - val_loss: 0.0139\n",
            "Epoch 7/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - val_loss: 0.0134\n",
            "Epoch 8/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0135\n",
            "Epoch 9/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0133\n",
            "Epoch 10/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0040 - val_loss: 0.0135\n",
            "Epoch 11/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0038 - val_loss: 0.0132\n",
            "Epoch 12/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0043 - val_loss: 0.0137\n",
            "Epoch 13/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0041 - val_loss: 0.0134\n",
            "Epoch 14/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0038 - val_loss: 0.0127\n",
            "Epoch 15/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0041 - val_loss: 0.0142\n",
            "Epoch 16/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0043 - val_loss: 0.0125\n",
            "Epoch 17/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0038 - val_loss: 0.0128\n",
            "Epoch 18/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0036 - val_loss: 0.0129\n",
            "Epoch 19/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0035 - val_loss: 0.0124\n",
            "Epoch 20/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034 - val_loss: 0.0127\n",
            "Epoch 21/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0037 - val_loss: 0.0121\n",
            "Epoch 22/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.0130\n",
            "Epoch 23/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0121\n",
            "Epoch 24/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0035 - val_loss: 0.0116\n",
            "Epoch 25/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0036 - val_loss: 0.0115\n",
            "Completed training for high_vol_uptrend\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"453d4235-a603-41cc-a719-1ea7c29b24b5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"453d4235-a603-41cc-a719-1ea7c29b24b5\")) {                    Plotly.newPlot(                        \"453d4235-a603-41cc-a719-1ea7c29b24b5\",                        [{\"marker\":{\"color\":[0.0,0.0,0.0,0.0,0.0024927290637915666,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000022869073979739145,0.000022869073979739145,0.00003430361096960872,0.00004573814795947829,0.00005717268494934786,0.00006860722193921744,0.00010291083290882615,0.0001257799068885653,0.000160083517858174,0.00021725620280752187,0.0002972979617366089,0.00040020879464543505,0.0005259887015340004,0.0006975067563820439,0.0009261974961794353,0.0012463645318957833,0.0016351387895513487,0.002161127491085349,0.002835765173487654,0.003681920910738002,0.004745332850795873,0.006128911826570091,0.007878395986020135,0.010085261625064961,0.026756816556294798,0.03809987725024542,0.041884708993892246,0.027694448589464103,0.049374330722256804,0.08367794169186553,0.07698873755279183,0.08527877687044727,0.10607819965502002,0.11815307071632228,0.1267175389217346,0.14146809163866633,0.15895149869617692,0.1663267750546428],\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"name\":\"Feature Importance\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.0,0.0,0.0,0.0,0.0024927290637915666,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000011434536989869572,0.000022869073979739145,0.000022869073979739145,0.00003430361096960872,0.00004573814795947829,0.00005717268494934786,0.00006860722193921744,0.00010291083290882615,0.0001257799068885653,0.000160083517858174,0.00021725620280752187,0.0002972979617366089,0.00040020879464543505,0.0005259887015340004,0.0006975067563820439,0.0009261974961794353,0.0012463645318957833,0.0016351387895513487,0.002161127491085349,0.002835765173487654,0.003681920910738002,0.004745332850795873,0.006128911826570091,0.007878395986020135,0.010085261625064961,0.026756816556294798,0.03809987725024542,0.041884708993892246,0.027694448589464103,0.049374330722256804,0.08367794169186553,0.07698873755279183,0.08527877687044727,0.10607819965502002,0.11815307071632228,0.1267175389217346,0.14146809163866633,0.15895149869617692,0.1663267750546428],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Feature Importance Analysis for high_vol_uptrend\"},\"xaxis\":{\"title\":{\"text\":\"Days Back\"}},\"yaxis\":{\"title\":{\"text\":\"Price Sensitivity (%)\"}},\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('453d4235-a603-41cc-a719-1ea7c29b24b5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing low_vol_sideways...\n",
            "\n",
            "Preparing data for low_vol_sideways...\n",
            "Using batch size: 32\n",
            "\n",
            "Training low_vol_sideways model...\n",
            "Training data shape: (450, 50, 1)\n",
            "Epoch 1/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.4017 - val_loss: 0.0402\n",
            "Epoch 2/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0336 - val_loss: 0.0207\n",
            "Epoch 3/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0152 - val_loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0086 - val_loss: 0.0225\n",
            "Epoch 5/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0084 - val_loss: 0.0180\n",
            "Epoch 6/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0070 - val_loss: 0.0198\n",
            "Epoch 7/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0066 - val_loss: 0.0181\n",
            "Epoch 8/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0059 - val_loss: 0.0191\n",
            "Epoch 9/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0064 - val_loss: 0.0182\n",
            "Epoch 10/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0062 - val_loss: 0.0185\n",
            "Epoch 11/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0056 - val_loss: 0.0183\n",
            "Epoch 12/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0057 - val_loss: 0.0181\n",
            "Epoch 13/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0056 - val_loss: 0.0182\n",
            "Epoch 14/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0054 - val_loss: 0.0183\n",
            "Epoch 15/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0057 - val_loss: 0.0175\n",
            "Epoch 16/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0060 - val_loss: 0.0183\n",
            "Epoch 17/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0054 - val_loss: 0.0169\n",
            "Epoch 18/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0055 - val_loss: 0.0174\n",
            "Epoch 19/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0052 - val_loss: 0.0164\n",
            "Epoch 20/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0051 - val_loss: 0.0174\n",
            "Epoch 21/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0050 - val_loss: 0.0158\n",
            "Epoch 22/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0047 - val_loss: 0.0175\n",
            "Epoch 23/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0157\n",
            "Epoch 24/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0046 - val_loss: 0.0153\n",
            "Epoch 25/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0147\n",
            "Completed training for low_vol_sideways\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"aaf51f27-25e1-46b2-acdc-24d5b88f867c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"aaf51f27-25e1-46b2-acdc-24d5b88f867c\")) {                    Plotly.newPlot(                        \"aaf51f27-25e1-46b2-acdc-24d5b88f867c\",                        [{\"marker\":{\"color\":[0.000034322543355378704,0.000045763391140504936,0.000045763391140504936,0.00006864508671075741,0.004931005395389407,0.00011440847785126235,0.00013729017342151481,0.0001716127167768935,0.00019449441234714596,0.0002402578034876509,0.00028602119462815584,0.0003317845857686608,0.00037754797690916575,0.00041187052026454444,0.0004576339114050494,0.0004805156069753018,0.0005033973025455543,0.0005148381503306805,0.0005148381503306805,0.0004805156069753018,0.00042331136804967066,0.0003546662813389133,0.0002402578034876509,0.00010296763006613611,0.000045763391140504936,0.00019449441234714596,0.000343225433553787,0.00046907475919017556,0.00046907475919017556,0.0003546662813389133,0.000045763391140504936,0.0007550959538183315,0.0019106215801160812,0.0036153079000998904,0.006063649326116904,0.009461581118299396,0.03749165819185867,0.056105917538259054,0.06242126551564873,0.03863574297037129,0.07423966127768412,0.12644424972121515,0.11464873565474999,0.12314928555909879,0.1475754955803433,0.1542111872957165,0.1495776439427404,0.14668310945310345,0.13818255954875466,0.07267226513112184],\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"name\":\"Feature Importance\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.000034322543355378704,0.000045763391140504936,0.000045763391140504936,0.00006864508671075741,0.004931005395389407,0.00011440847785126235,0.00013729017342151481,0.0001716127167768935,0.00019449441234714596,0.0002402578034876509,0.00028602119462815584,0.0003317845857686608,0.00037754797690916575,0.00041187052026454444,0.0004576339114050494,0.0004805156069753018,0.0005033973025455543,0.0005148381503306805,0.0005148381503306805,0.0004805156069753018,0.00042331136804967066,0.0003546662813389133,0.0002402578034876509,0.00010296763006613611,0.000045763391140504936,0.00019449441234714596,0.000343225433553787,0.00046907475919017556,0.00046907475919017556,0.0003546662813389133,0.000045763391140504936,0.0007550959538183315,0.0019106215801160812,0.0036153079000998904,0.006063649326116904,0.009461581118299396,0.03749165819185867,0.056105917538259054,0.06242126551564873,0.03863574297037129,0.07423966127768412,0.12644424972121515,0.11464873565474999,0.12314928555909879,0.1475754955803433,0.1542111872957165,0.1495776439427404,0.14668310945310345,0.13818255954875466,0.07267226513112184],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Feature Importance Analysis for low_vol_sideways\"},\"xaxis\":{\"title\":{\"text\":\"Days Back\"}},\"yaxis\":{\"title\":{\"text\":\"Price Sensitivity (%)\"}},\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('aaf51f27-25e1-46b2-acdc-24d5b88f867c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction Results:\n",
            "--------------------------------------------------\n",
            "\n",
            "high_vol_uptrend:\n",
            "Current Price: $266.86\n",
            "Predicted Price: $266.89\n",
            "Predicted Change: 0.01%\n",
            "\n",
            "low_vol_sideways:\n",
            "Current Price: $266.86\n",
            "Predicted Price: $266.74\n",
            "Predicted Change: -0.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-852cb51f7e75>:242: DeprecationWarning:\n",
            "\n",
            "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N2BeUsURDSqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}