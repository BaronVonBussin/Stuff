{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Eb1U7SNTgqp178QWCA/E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/Stuff/blob/main/SimpleTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Alammar - Simple Transformer Language Model"
      ],
      "metadata": {
        "id": "ljgFTzPq2TDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8LXxKK0Vz1",
        "outputId": "cdc31358-664a-446f-f9b4-4e991f2c2984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "_7BoPk3h1il1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", output_hidden_states=True)"
      ],
      "metadata": {
        "id": "0sP-OH-f0cVm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The Shawshank\"\n",
        "\n",
        "# Tokenize the input string\n",
        "input = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "# Run the model\n",
        "output = model.generate(input, max_length=5, do_sample=False)\n",
        "\n",
        "# Print the output\n",
        "print('\\n',tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urymns7R0fos",
        "outputId": "7ea38976-2ba9-4825-ae70-74e1c21e566a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " The Shawshank Redemption\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the token ides (of the input and output)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ1Xquj30h0V",
        "outputId": "01799680-04bf-4c81-bc7f-33cb6652df63"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  464, 18193,  1477,   962, 34433]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the input token ids\n",
        "text = \"The Shawshank\"\n",
        "input = tokenizer(text, return_tensors=\"pt\")['input_ids']\n",
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvRMkXra0jDO",
        "outputId": "4a9aee50-9018-4a08-a709-d028a7dbb85c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  464, 18193,  1477,   962]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WiktOKA0kLU",
        "outputId": "72eefe44-e91a-45b7-c084-50dd946f9ffc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'ĠShaw', 'sh', 'ank']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the embedding matrix of the model\n",
        "model.transformer.wte # Dimensions are: (Number of tokens in vocabulary, dimension of model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9owdpn-c0lY3",
        "outputId": "6dfe17ad-ae04-4383-fb6c-ab276d489179"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the embedding vector of token # 464 ('The')\n",
        "model.transformer.wte(torch.tensor(464))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qcste6m0mfW",
        "outputId": "2651e80a-7a4d-42e1-ad70-5cbfce5bca72"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-6.2649e-02, -4.4906e-02,  5.5888e-02, -5.4657e-02, -1.1713e-01,\n",
              "        -7.2870e-02, -2.2326e-01, -3.2198e-03,  6.8535e-03,  2.3608e-02,\n",
              "        -5.8700e-02,  4.4439e-02,  7.4774e-02, -1.3818e-02,  1.1873e-01,\n",
              "        -5.1842e-02,  5.4415e-02,  5.5382e-02, -3.3126e-02,  1.1923e-01,\n",
              "        -7.3283e-02,  2.6658e-02, -8.4261e-02,  5.7980e-02, -4.2860e-03,\n",
              "        -4.0704e-02,  6.5652e-02, -6.6221e-02, -1.0232e-01,  3.1356e-02,\n",
              "        -1.8873e-02,  2.7774e-02, -2.0423e-02,  1.1994e-01, -8.7572e-02,\n",
              "        -1.0579e-01, -3.1816e-01,  9.5807e-02,  1.1588e-01, -4.2873e-02,\n",
              "         1.3187e-01, -1.3457e-01, -1.0421e-01, -1.2150e-01,  9.2551e-02,\n",
              "        -2.7394e-02,  3.1406e-02,  6.4891e-03,  1.2296e-01, -2.0581e-01,\n",
              "        -6.3499e-02,  5.4726e-02,  6.0272e-02,  1.1968e-01,  6.4859e-02,\n",
              "        -3.4885e-01, -5.6065e-02, -2.4721e-03,  3.7549e-03, -1.2817e-02,\n",
              "        -8.4894e-02, -1.6269e-02,  8.2583e-02, -4.0134e-02, -2.1432e-01,\n",
              "        -2.6889e-03,  1.5291e-02,  5.2090e-02,  2.9089e-01,  7.6877e-02,\n",
              "         6.9082e-02,  7.3376e-02,  8.8179e-03,  9.6406e-02,  2.0432e-02,\n",
              "        -7.4213e-02, -4.1877e-02,  7.1981e-02, -4.8161e-02,  1.1771e-02,\n",
              "         1.0166e-01, -5.4755e-02,  8.7261e-02, -7.9654e-02,  5.2315e-01,\n",
              "        -9.9835e-02, -1.0481e-01, -2.8195e-01,  8.1683e-03, -4.4626e-02,\n",
              "        -6.5149e-02,  7.7208e-02, -9.7715e-02, -5.6882e-02,  1.0190e-01,\n",
              "         1.2256e-02, -2.2082e-02, -4.6576e-02,  8.7919e-02,  2.1517e-02,\n",
              "         1.6148e-01,  6.5791e-02, -8.3689e-02, -7.6088e-02, -8.4335e-02,\n",
              "        -9.1179e-02, -4.1727e-02, -1.1803e-01,  1.4415e-01, -7.8215e-02,\n",
              "        -5.9557e-03, -3.4881e-02, -5.6165e-02,  2.1938e-02, -8.0716e-02,\n",
              "         1.2922e-01,  1.5276e-01,  1.2612e-01,  1.0735e-01,  3.9891e-02,\n",
              "        -7.1642e-03,  7.1192e-02, -1.2086e-01, -6.3376e-02, -1.7415e-01,\n",
              "         1.1116e-01, -1.4673e-01, -6.5523e-03,  7.3890e-02, -4.9352e-02,\n",
              "         3.0207e-02, -1.0208e-01,  6.2928e-02,  1.8352e-01, -4.9800e-02,\n",
              "        -2.7031e-02,  1.4378e-03, -5.3656e-02,  6.2120e-01, -9.3976e-02,\n",
              "         5.1804e-02, -2.2970e-02,  6.7755e-02,  1.8769e-02,  2.6562e-02,\n",
              "        -1.0017e-01, -1.7162e-02, -2.6100e-03,  1.4294e-02,  4.4294e-02,\n",
              "         1.3903e-01, -1.4014e-02,  2.3181e-02, -1.4834e-01, -5.3028e-02,\n",
              "         9.6540e-02,  2.3293e-02, -7.7461e-02, -1.0504e-01, -3.5051e-01,\n",
              "        -3.7689e-02,  1.0662e-02, -1.2818e-01, -6.2468e-02,  4.2055e-02,\n",
              "         2.1855e-03, -1.4826e-01,  2.3176e-01,  3.3421e-02,  2.2398e-01,\n",
              "         1.1421e-01,  3.2895e-02, -3.0494e-02, -5.3284e-02,  1.0991e-01,\n",
              "         3.5463e-02,  2.7445e-01,  6.2911e-04,  7.8582e-02,  1.0000e-01,\n",
              "         2.4097e-02, -9.4483e-02,  9.1651e-02,  3.0298e-03,  1.4840e-01,\n",
              "        -1.7038e-02, -1.1124e-01,  4.0140e-03, -4.1108e-04, -1.1162e-01,\n",
              "         5.6105e-02,  1.8361e-01,  3.6446e-02,  9.7009e-02, -2.1477e-01,\n",
              "         9.2157e-02,  3.5488e-02,  1.6611e-02, -6.8011e-02,  1.6890e-01,\n",
              "         2.4187e-02, -9.6880e-02, -9.7266e-02, -6.0271e-02,  7.9955e-02,\n",
              "         9.8765e-04,  5.0787e-03,  7.2527e-02,  1.1458e-01,  1.8893e-02,\n",
              "         9.9052e-02, -6.2180e-02, -1.9884e-03, -5.9710e-02,  1.0698e-01,\n",
              "        -4.7192e-02, -9.0067e-02,  5.1061e-02,  6.7179e-03, -1.0657e-01,\n",
              "         1.1859e-01, -1.6188e-02, -8.5031e-02, -2.8055e-02, -4.9350e-02,\n",
              "        -1.0238e-01, -6.7360e-02, -1.0790e-01,  8.8089e-02, -1.2654e-01,\n",
              "         1.4105e-01,  1.3072e-01, -2.5147e-01,  3.3939e-02, -9.8332e-02,\n",
              "        -5.6578e-02,  1.2558e-02, -6.2258e-02, -2.6592e-02, -1.3017e-02,\n",
              "         1.0194e-01, -1.1762e-03,  7.7183e-02,  5.7278e-02,  7.7125e-02,\n",
              "        -3.6276e-02,  4.7724e-02, -2.0229e-02, -1.7146e-02,  9.1073e-02,\n",
              "         1.7726e-01, -9.0652e-02, -9.3985e-02, -6.0687e-02,  6.2885e-02,\n",
              "        -1.6106e-02,  1.2610e-02,  3.5395e-02,  9.8192e-02,  7.1861e-02,\n",
              "         7.1699e-02,  9.4895e-02,  3.8220e-02,  1.3879e-01,  3.7747e-02,\n",
              "        -8.2909e-02, -2.8665e-01,  2.2522e-02,  7.0700e-02, -1.2517e-01,\n",
              "         1.8129e-01, -1.1479e-01, -3.0415e-02, -4.4267e-02,  1.1545e-01,\n",
              "        -1.0746e-01, -4.6373e-02,  9.9404e-02, -8.4753e-02,  5.8346e-02,\n",
              "         7.6724e-04, -6.9820e-02, -1.2692e-01, -2.3300e-02, -2.1507e-01,\n",
              "         5.5366e-02,  4.4726e-02, -1.0376e-01, -3.2909e-01,  8.6371e-02,\n",
              "         4.2664e-03, -3.1455e-02,  1.6310e-01,  1.5648e-01, -4.2880e-02,\n",
              "        -1.8474e-02,  1.3106e-01,  1.1363e-01,  2.7173e-02,  1.2660e-01,\n",
              "        -5.9311e-02, -9.8891e-02, -4.2543e-02, -2.3191e-02,  6.0689e-02,\n",
              "         4.0283e-02, -6.9700e-04, -1.0824e-01,  2.1883e-01, -2.0839e-02,\n",
              "        -1.1635e-01,  1.1721e-01, -4.8828e-02, -2.2544e-02,  1.9957e-01,\n",
              "         4.6466e-02,  2.6236e-02, -1.5585e-01,  9.1094e-03, -2.1267e-01,\n",
              "         2.5769e-01, -7.3468e-02, -9.2528e-02,  2.4997e-02, -1.4215e-01,\n",
              "        -1.4417e-01, -3.3305e-01,  1.0021e-01, -5.8869e-02,  7.3044e-02,\n",
              "         6.0383e-02, -1.3503e-01,  2.7302e-02,  1.8703e-01, -1.2806e-02,\n",
              "         5.7073e-02,  9.0280e-02, -1.5143e-02, -5.4023e-02,  1.2399e-01,\n",
              "        -8.5139e-02,  6.4925e-02, -5.8222e-02, -7.2756e-02,  8.8541e-02,\n",
              "         6.0879e-02, -9.2811e-02,  4.9281e-02, -9.5763e-02, -7.7652e-02,\n",
              "        -4.0214e-02, -2.3958e-02, -1.6052e-01, -3.0753e-02, -1.1209e-01,\n",
              "        -7.4997e-03,  5.1728e-02,  1.8273e-02, -7.1002e-02, -7.7520e-02,\n",
              "         6.3680e-02,  4.9214e-02, -5.5259e-01, -6.9264e-02, -5.8530e-02,\n",
              "         1.5903e-01,  2.4740e-02, -1.7233e-01,  7.9766e-02,  8.7400e-02,\n",
              "         1.0187e-01,  2.8480e-02,  1.7869e-02, -2.1188e-01,  1.7296e-01,\n",
              "         2.1859e-01, -5.0978e-02, -1.9529e-01,  5.9238e-02,  8.6392e-02,\n",
              "        -1.0268e-01, -1.7420e-01,  8.2962e-02, -1.4705e-01, -5.6892e-02,\n",
              "         1.1193e-01, -1.1189e-02,  8.3530e-02,  1.0402e-02,  2.0608e-02,\n",
              "         3.3614e-02, -3.3329e-02, -1.1878e-02, -1.5145e-01, -1.0961e-01,\n",
              "        -1.3519e-01,  4.4461e-02, -2.4229e-03,  1.2559e-01, -7.7785e-02,\n",
              "        -7.7474e-02,  8.0846e-02, -1.1829e-01, -9.2990e-02, -1.6285e-01,\n",
              "         1.4514e-02, -6.7827e-02,  3.9259e-02, -3.3612e-01,  7.6199e-02,\n",
              "        -4.9862e-02, -1.6196e-01, -9.4633e-02, -3.6492e-02, -3.7328e-02,\n",
              "        -4.1201e-03,  9.9998e-03,  7.5270e-02, -5.7569e-02, -4.2786e-02,\n",
              "         8.6815e-02,  2.8800e-02,  3.1197e-02,  1.0185e-01,  9.4486e-02,\n",
              "         2.1282e-02,  6.0674e-02, -7.4639e-02,  1.8090e-01, -1.0450e-01,\n",
              "        -2.5522e-01, -5.6027e-02,  1.3828e-01,  1.1350e-01,  2.1448e-02,\n",
              "        -3.9067e-02, -1.3588e-01, -2.9345e-02, -5.5968e-02, -9.8969e-02,\n",
              "        -7.4646e-02,  1.0464e-01, -1.4783e-01, -3.1463e-02,  3.2958e-02,\n",
              "        -1.5104e-01, -6.4073e-02,  2.3301e-01, -5.4972e-02, -3.1530e-02,\n",
              "         7.5931e-02, -4.6505e-02,  1.4346e-01,  8.4920e-02, -3.2047e-02,\n",
              "        -2.1088e-01,  1.6876e-01,  3.3212e-02, -1.2510e-01, -1.2308e-01,\n",
              "        -1.9802e-02, -3.3015e-02, -2.0518e-01,  4.3430e-02, -3.7013e-02,\n",
              "         1.2003e-01, -3.7512e-02,  6.9324e-02, -9.7411e-02, -2.1957e-02,\n",
              "        -1.9214e-02, -1.3567e-01,  1.6970e-01, -3.1553e-02,  1.5147e-02,\n",
              "        -5.8446e-02,  2.7342e-02,  6.1681e-02,  1.3681e-02,  2.5004e-01,\n",
              "        -3.5267e-01,  1.6333e-01, -3.8555e-03, -1.3828e-01, -4.7451e-02,\n",
              "        -6.6291e-02, -7.0574e-02,  1.1679e-01, -1.3863e-01, -8.5180e-03,\n",
              "        -1.7836e-03, -7.6153e-02, -1.5434e-02, -8.4037e-02,  9.1066e-02,\n",
              "        -1.2908e-01, -2.0826e-01,  1.4944e-01, -9.1995e-02, -2.6867e-01,\n",
              "         2.3612e-02,  1.1319e-01, -6.1646e-02,  1.4786e-01, -5.1432e-02,\n",
              "        -1.1507e-01, -3.0265e-02, -1.5270e-01,  5.3833e-02,  9.9415e-02,\n",
              "        -1.3082e-01,  6.2575e-02, -8.8731e-02, -3.9710e-02, -1.2554e-01,\n",
              "         3.0715e-02,  6.9132e-02, -6.7005e-02, -2.5458e-02,  3.8869e-02,\n",
              "        -1.5923e-01,  2.7743e-02,  2.0169e-02, -4.5735e-02, -9.9385e-02,\n",
              "        -5.1417e-02,  7.3213e-02,  2.4986e-01, -5.2360e-03, -6.5376e-02,\n",
              "         7.0374e-02,  3.8748e-02, -2.0792e-02,  9.2837e-02, -1.0096e-01,\n",
              "        -3.0281e-02,  7.5467e-02, -8.1408e-02,  5.5916e-02,  1.0426e-01,\n",
              "        -6.8461e-02, -4.2714e-03, -1.5302e-01,  1.4000e-01,  8.2922e-02,\n",
              "        -3.5530e-02,  2.7031e-02, -1.3187e-02,  1.6040e-01,  4.0959e-01,\n",
              "         6.4632e-04, -3.4900e-02,  4.8370e-04, -4.7273e-02,  1.6765e-01,\n",
              "        -6.1726e-03,  9.9889e-02,  1.9799e-01,  7.6185e-02,  1.1998e-01,\n",
              "        -9.0053e-02,  1.1475e-02, -7.9212e-02,  5.0373e-02, -1.2276e-02,\n",
              "        -1.3934e-01, -2.6125e-01,  2.1754e-02, -1.0877e-01, -1.7861e-02,\n",
              "        -1.6668e-01, -9.2420e-02, -1.3878e-02, -8.8295e-03, -6.3030e-02,\n",
              "        -1.0543e-01,  4.8202e-02, -6.5044e-02,  1.1086e-01, -2.7024e-02,\n",
              "        -8.4654e-02, -5.4931e-02,  5.4255e-02,  6.8870e-02, -5.2517e-02,\n",
              "        -6.2799e-03,  6.2461e-02,  4.3790e-02, -1.5881e-01,  2.1251e-01,\n",
              "        -8.7122e-02,  2.6258e-02,  2.5049e-03, -1.5120e-01, -1.4632e-01,\n",
              "         4.5138e-03, -9.0443e-03, -2.6588e-02, -1.0465e-01, -4.1162e-02,\n",
              "         3.7104e-02, -2.6799e-02,  7.3106e-02,  1.5287e-02, -6.9980e-02,\n",
              "         4.1658e-02,  1.1324e-02,  1.0969e-01, -4.7242e-01,  3.8726e-02,\n",
              "        -5.8977e-02, -1.5502e-01,  1.1687e-01, -9.4594e-02,  8.0425e-02,\n",
              "         1.4174e-01, -2.3491e-01, -8.6311e-02,  1.7286e-01,  1.2864e-01,\n",
              "        -9.7945e-02,  8.4990e-03,  2.3695e-02,  1.6841e-02,  2.0246e-01,\n",
              "        -3.2752e-02,  2.2906e-02,  2.4480e-01, -1.5979e-01, -1.7827e-02,\n",
              "         8.6079e-03,  6.5474e-03, -9.0049e-03, -4.3515e-02, -5.6294e-02,\n",
              "         2.1401e-01,  1.5029e-01,  7.9673e-02,  5.4913e-02,  3.9160e-02,\n",
              "         1.2875e-01,  3.3008e-02, -5.5979e-02,  1.0740e-01, -3.5599e-02,\n",
              "         4.3530e-02,  1.3297e-01, -4.8124e-02,  9.8446e-03,  2.2264e-01,\n",
              "         3.4221e-02,  5.9539e-02,  6.7812e-02, -1.6882e-01, -9.7988e-02,\n",
              "        -9.7874e-02, -6.1450e-02, -6.6836e-02, -7.5918e-02, -3.2872e-01,\n",
              "         4.8814e-02,  1.1171e-01,  9.3693e-02, -1.3552e-01, -1.2159e-02,\n",
              "        -9.4724e-02, -7.4638e-02,  2.0551e-01, -6.7493e-02,  1.2942e-01,\n",
              "         8.2681e-02,  9.2897e-02, -1.4535e-01,  4.6495e-02,  1.5323e-02,\n",
              "         7.4460e-02, -6.0297e-02,  2.4888e-03, -1.1828e-01, -1.9603e-01,\n",
              "         7.5323e-03,  9.1524e-02, -6.6671e-02,  6.5601e-02,  7.5466e-02,\n",
              "         1.5524e-02,  1.4577e-02, -6.2519e-03,  4.5152e-02,  1.7786e-02,\n",
              "         1.4978e-01, -9.3021e-02,  1.3635e-02,  1.1171e-01,  1.6229e-03,\n",
              "        -1.3502e-01, -4.8030e-02,  1.9070e-01, -2.0233e-01, -6.8417e-03,\n",
              "        -2.5035e-01, -1.6159e-01,  6.2476e-03,  1.4825e-01,  1.0560e-01,\n",
              "        -4.0371e-02,  1.9100e-01,  4.2668e-02,  1.3999e-02,  2.9254e-01,\n",
              "         3.9176e-02,  1.3214e-01,  2.8551e-02,  4.5838e-02, -6.3797e-02,\n",
              "        -9.0351e-02, -2.0034e-01,  3.3103e-02, -2.2779e-01, -6.6089e-02,\n",
              "        -7.3375e-02,  2.8297e-01,  7.9907e-02, -1.0679e-02, -1.0524e-01,\n",
              "         9.3045e-02, -1.9267e-02, -5.3104e-02,  1.9750e-01,  9.3863e-02,\n",
              "         3.4340e-02, -1.1681e-01, -9.3470e-02, -7.6323e-02, -1.5271e-02,\n",
              "         1.0952e-01,  3.0217e-02, -2.1070e-03, -9.3585e-02,  3.0755e-01,\n",
              "        -1.4883e-01,  1.3984e-01, -2.3806e-02,  9.8132e-02, -6.3319e-02,\n",
              "         2.0151e-01,  7.7652e-02,  1.0479e-01, -5.5277e-02, -5.8733e-02,\n",
              "        -5.0263e-02,  3.6644e-02,  3.9631e-02, -2.1010e-02, -1.1201e-02,\n",
              "         7.8469e-02, -8.0196e-02, -3.4609e-02, -2.7329e-02,  5.6554e-02,\n",
              "         2.2118e-02, -5.9166e-02, -1.7367e-01,  2.7787e-02,  1.0721e-01,\n",
              "         7.8055e-02, -2.9740e-02, -2.4302e-02], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The chicken didn't cross the road because it was\"\n",
        "\n",
        "# Tokenize the input string\n",
        "input = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "# Run the model\n",
        "output = model.generate(input, max_length=20, do_sample=True)\n",
        "\n",
        "# Print the output\n",
        "print('\\n',tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KvyNJkW0nit",
        "outputId": "4f657ed0-ffb8-4aa3-a589-965e6967fa28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " The chicken didn't cross the road because it was frozen. They had to go to the store to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qs5QRZro0ov2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}